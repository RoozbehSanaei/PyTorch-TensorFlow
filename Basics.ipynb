{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYxcfABVJyOreM8cup7iEn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoozbehSanaei/PyTorch-TensorFlow/blob/gh-pages/Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hY3e16fJ8UX"
      },
      "source": [
        "# Introductory Course to PyTorch and TensorFlow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJMn4XFor2fZ"
      },
      "source": [
        "*Generating Data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kglEDEEwlgVE"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "def generate_data(n=2000):\n",
        "    x = np.random.uniform(-math.pi,math.pi, n)\n",
        "    noise = np.random.normal(0, 0.15, n)\n",
        "    y = np.sin(x) + noise\n",
        "    return x.astype(np.float32), y.astype(np.float32)\n",
        "\n",
        "x, y = generate_data()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBA_03nTXkdD"
      },
      "source": [
        "## Simple Linear Regression Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct_s6rgTNaVM"
      },
      "source": [
        "*Numpy*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzSxKyKdaFdl"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Create random input and output data\n",
        "\n",
        "def generate_data(n=2000):\n",
        "    x = np.random.uniform(-math.pi,math.pi, n)\n",
        "    noise = np.random.normal(0, 0.15, n)\n",
        "    y = np.sin(x) + noise\n",
        "    return x.astype(np.float32), y.astype(np.float32)\n",
        "\n",
        "x, y = generate_data()\n",
        "\n",
        "# Randomly initialize weights\n",
        "a = np.random.uniform()\n",
        "b = np.random.uniform()\n",
        "c = np.random.uniform()\n",
        "d = np.random.uniform()\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "    # Forward pass: compute predicted y\n",
        "    # y = a + b x + c x^2 + d x^3\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = np.mean(np.square(y_pred - y))\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "    \n",
        "    # Update weights\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d\n",
        "\n",
        "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbhYz33QXrj6"
      },
      "source": [
        "*TensorFlow*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRwHaoWjXrj8"
      },
      "source": [
        "import tensorflow as tf\n",
        "class LinearRegressionKeras(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.w3 = tf.Variable(tf.random.uniform(shape=[1]))\n",
        "        self.w2 = tf.Variable(tf.random.uniform(shape=[1]))\n",
        "        self.w1 = tf.Variable(tf.random.uniform(shape=[1]))\n",
        "        self.b = tf.Variable(tf.random.uniform(shape=[1]))\n",
        "\n",
        "    def __call__(self,x): \n",
        "        return  x * x * x * self.w3 + x * x * self.w2 + x * self.w1 + self.b"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXOqRJrdjghC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awe7V36JFB26"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "def generate_data(n=2000):\n",
        "    x = np.random.uniform(-math.pi,math.pi, n)\n",
        "    noise = np.random.normal(0, 0.15, n)\n",
        "    y = np.sin(x) + noise\n",
        "    return x.astype(np.float32), y.astype(np.float32)\n",
        "\n",
        "x, y = generate_data()\n",
        "\n",
        "tf_model = LinearRegressionKeras()\n",
        "[w3, w2, w1, b] = tf_model.trainable_variables\n",
        "\n",
        "def squared_error(y_pred, y_true):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y_true))\n",
        "\n",
        "learning_rate = 1e-6\n",
        "\n",
        "for t in range(2000):\n",
        "    # Forward pass: compute predicted y\n",
        "    # y = a + b x + c x^2 + d x^3\n",
        "    \n",
        "    y_pred = tf_model(x)    \n",
        "\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_b = tf.reduce_sum(grad_y_pred)\n",
        "    grad_w1 = tf.reduce_sum(grad_y_pred * x)\n",
        "    grad_w2 = tf.reduce_sum(grad_y_pred * x ** 2)\n",
        "    grad_w3 =  tf.reduce_sum(grad_y_pred * x ** 3)\n",
        "\n",
        "\n",
        "    # Update weights\n",
        "    b.assign(b-learning_rate * grad_b)\n",
        "    w1.assign(w1-learning_rate * grad_w1)\n",
        "    w2.assign(w2-learning_rate * grad_w2)\n",
        "    w3.assign(w3-learning_rate * grad_w3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiL2CLQT4Cjx"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "def generate_data(n=2000):\n",
        "    x = np.random.uniform(-math.pi,math.pi, n)\n",
        "    noise = np.random.normal(0, 0.15, n)\n",
        "    y = np.sin(x) + noise\n",
        "    return x.astype(np.float32), y.astype(np.float32)\n",
        "\n",
        "x, y = generate_data()\n",
        "\n",
        "tf_model = LinearRegressionKeras()\n",
        "[w3, w2, w1, b] = tf_model.trainable_variables\n",
        "\n",
        "def squared_error(y_pred, y_true):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y_true))\n",
        "\n",
        "learning_rate = 0.002\n",
        "\n",
        "for t in range(2000):\n",
        "    # Forward pass: compute predicted y\n",
        "    # y = a + b x + c x^2 + d x^3\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = tf_model(x)    \n",
        "        loss = squared_error(y_pred, y)\n",
        "    # Compute and print loss\n",
        "    print(loss)\n",
        "\n",
        "    grad_w3,grad_w2,grad_w1,grad_b  = tape.gradient(loss, tf_model.trainable_variables)\n",
        "\n",
        "\n",
        "    # Update weights\n",
        "    b.assign(b-learning_rate * grad_b)\n",
        "    w1.assign(w1-learning_rate * grad_w1)\n",
        "    w2.assign(w2-learning_rate * grad_w2)\n",
        "    w3.assign(w3-learning_rate * grad_w3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JamJWXYCJNAw",
        "outputId": "0a694111-545c-4178-f388-c08a1d09a52a"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "def generate_data(n=2000):\n",
        "    x = np.random.uniform(-math.pi,math.pi, n)\n",
        "    noise = np.random.normal(0, 0.15, n)\n",
        "    y = np.sin(x) + noise\n",
        "    return x.astype(np.float32), y.astype(np.float32)\n",
        "\n",
        "x, y = generate_data()\n",
        "\n",
        "learning_rate = 0.002\n",
        "\n",
        "tf_model = LinearRegressionKeras()\n",
        "[w3, w2, w1, b] = tf_model.trainable_variables\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "def squared_error(y_pred, y_true):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y_true))\n",
        "\n",
        "\n",
        "for t in range(2000):\n",
        "    # Forward pass: compute predicted y\n",
        "    # y = a + b x + c x^2 + d x^3\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = tf_model(x)    \n",
        "        loss = squared_error(y_pred, y)\n",
        "    # Compute and print loss\n",
        "    print(loss)\n",
        "\n",
        "    grads = tape.gradient(loss, tf_model.trainable_variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, tf_model.variables))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(21.673033, shape=(), dtype=float32)\n",
            "tf.Tensor(9.061057, shape=(), dtype=float32)\n",
            "tf.Tensor(5.950099, shape=(), dtype=float32)\n",
            "tf.Tensor(4.7749786, shape=(), dtype=float32)\n",
            "tf.Tensor(4.060745, shape=(), dtype=float32)\n",
            "tf.Tensor(3.5095546, shape=(), dtype=float32)\n",
            "tf.Tensor(3.0526454, shape=(), dtype=float32)\n",
            "tf.Tensor(2.6671674, shape=(), dtype=float32)\n",
            "tf.Tensor(2.34059, shape=(), dtype=float32)\n",
            "tf.Tensor(2.063611, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8286033, shape=(), dtype=float32)\n",
            "tf.Tensor(1.6291511, shape=(), dtype=float32)\n",
            "tf.Tensor(1.4598281, shape=(), dtype=float32)\n",
            "tf.Tensor(1.3160378, shape=(), dtype=float32)\n",
            "tf.Tensor(1.1938852, shape=(), dtype=float32)\n",
            "tf.Tensor(1.0900695, shape=(), dtype=float32)\n",
            "tf.Tensor(1.0017942, shape=(), dtype=float32)\n",
            "tf.Tensor(0.92668897, shape=(), dtype=float32)\n",
            "tf.Tensor(0.86274534, shape=(), dtype=float32)\n",
            "tf.Tensor(0.80826145, shape=(), dtype=float32)\n",
            "tf.Tensor(0.7617949, shape=(), dtype=float32)\n",
            "tf.Tensor(0.7221238, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6882119, shape=(), dtype=float32)\n",
            "tf.Tensor(0.659182, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6342902, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6129063, shape=(), dtype=float32)\n",
            "tf.Tensor(0.59449595, shape=(), dtype=float32)\n",
            "tf.Tensor(0.57860696, shape=(), dtype=float32)\n",
            "tf.Tensor(0.56485546, shape=(), dtype=float32)\n",
            "tf.Tensor(0.5529165, shape=(), dtype=float32)\n",
            "tf.Tensor(0.54251474, shape=(), dtype=float32)\n",
            "tf.Tensor(0.5334169, shape=(), dtype=float32)\n",
            "tf.Tensor(0.5254249, shape=(), dtype=float32)\n",
            "tf.Tensor(0.5183713, shape=(), dtype=float32)\n",
            "tf.Tensor(0.512114, shape=(), dtype=float32)\n",
            "tf.Tensor(0.5065326, shape=(), dtype=float32)\n",
            "tf.Tensor(0.50152516, shape=(), dtype=float32)\n",
            "tf.Tensor(0.49700522, shape=(), dtype=float32)\n",
            "tf.Tensor(0.49289942, shape=(), dtype=float32)\n",
            "tf.Tensor(0.48914576, shape=(), dtype=float32)\n",
            "tf.Tensor(0.48569167, shape=(), dtype=float32)\n",
            "tf.Tensor(0.48249242, shape=(), dtype=float32)\n",
            "tf.Tensor(0.47951037, shape=(), dtype=float32)\n",
            "tf.Tensor(0.47671345, shape=(), dtype=float32)\n",
            "tf.Tensor(0.47407433, shape=(), dtype=float32)\n",
            "tf.Tensor(0.47157022, shape=(), dtype=float32)\n",
            "tf.Tensor(0.4691816, shape=(), dtype=float32)\n",
            "tf.Tensor(0.4668918, shape=(), dtype=float32)\n",
            "tf.Tensor(0.4646869, shape=(), dtype=float32)\n",
            "tf.Tensor(0.46255505, shape=(), dtype=float32)\n",
            "tf.Tensor(0.4604861, shape=(), dtype=float32)\n",
            "tf.Tensor(0.45847163, shape=(), dtype=float32)\n",
            "tf.Tensor(0.45650426, shape=(), dtype=float32)\n",
            "tf.Tensor(0.45457792, shape=(), dtype=float32)\n",
            "tf.Tensor(0.45268735, shape=(), dtype=float32)\n",
            "tf.Tensor(0.45082828, shape=(), dtype=float32)\n",
            "tf.Tensor(0.44899678, shape=(), dtype=float32)\n",
            "tf.Tensor(0.44718975, shape=(), dtype=float32)\n",
            "tf.Tensor(0.44540453, shape=(), dtype=float32)\n",
            "tf.Tensor(0.4436388, shape=(), dtype=float32)\n",
            "tf.Tensor(0.4418906, shape=(), dtype=float32)\n",
            "tf.Tensor(0.44015828, shape=(), dtype=float32)\n",
            "tf.Tensor(0.43844044, shape=(), dtype=float32)\n",
            "tf.Tensor(0.43673587, shape=(), dtype=float32)\n",
            "tf.Tensor(0.43504357, shape=(), dtype=float32)\n",
            "tf.Tensor(0.43336266, shape=(), dtype=float32)\n",
            "tf.Tensor(0.43169248, shape=(), dtype=float32)\n",
            "tf.Tensor(0.43003228, shape=(), dtype=float32)\n",
            "tf.Tensor(0.42838156, shape=(), dtype=float32)\n",
            "tf.Tensor(0.42673993, shape=(), dtype=float32)\n",
            "tf.Tensor(0.42510697, shape=(), dtype=float32)\n",
            "tf.Tensor(0.42348224, shape=(), dtype=float32)\n",
            "tf.Tensor(0.42186558, shape=(), dtype=float32)\n",
            "tf.Tensor(0.4202567, shape=(), dtype=float32)\n",
            "tf.Tensor(0.41865534, shape=(), dtype=float32)\n",
            "tf.Tensor(0.41706136, shape=(), dtype=float32)\n",
            "tf.Tensor(0.41547462, shape=(), dtype=float32)\n",
            "tf.Tensor(0.4138949, shape=(), dtype=float32)\n",
            "tf.Tensor(0.41232213, shape=(), dtype=float32)\n",
            "tf.Tensor(0.41075623, shape=(), dtype=float32)\n",
            "tf.Tensor(0.40919703, shape=(), dtype=float32)\n",
            "tf.Tensor(0.40764448, shape=(), dtype=float32)\n",
            "tf.Tensor(0.4060985, shape=(), dtype=float32)\n",
            "tf.Tensor(0.40455908, shape=(), dtype=float32)\n",
            "tf.Tensor(0.40302607, shape=(), dtype=float32)\n",
            "tf.Tensor(0.40149945, shape=(), dtype=float32)\n",
            "tf.Tensor(0.39997917, shape=(), dtype=float32)\n",
            "tf.Tensor(0.39846516, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3969574, shape=(), dtype=float32)\n",
            "tf.Tensor(0.39545584, shape=(), dtype=float32)\n",
            "tf.Tensor(0.39396045, shape=(), dtype=float32)\n",
            "tf.Tensor(0.39247125, shape=(), dtype=float32)\n",
            "tf.Tensor(0.39098817, shape=(), dtype=float32)\n",
            "tf.Tensor(0.38951105, shape=(), dtype=float32)\n",
            "tf.Tensor(0.38803998, shape=(), dtype=float32)\n",
            "tf.Tensor(0.38657492, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3851159, shape=(), dtype=float32)\n",
            "tf.Tensor(0.38366273, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3822156, shape=(), dtype=float32)\n",
            "tf.Tensor(0.38077426, shape=(), dtype=float32)\n",
            "tf.Tensor(0.37933883, shape=(), dtype=float32)\n",
            "tf.Tensor(0.37790924, shape=(), dtype=float32)\n",
            "tf.Tensor(0.37648544, shape=(), dtype=float32)\n",
            "tf.Tensor(0.37506738, shape=(), dtype=float32)\n",
            "tf.Tensor(0.37365514, shape=(), dtype=float32)\n",
            "tf.Tensor(0.37224868, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3708479, shape=(), dtype=float32)\n",
            "tf.Tensor(0.36945277, shape=(), dtype=float32)\n",
            "tf.Tensor(0.36806336, shape=(), dtype=float32)\n",
            "tf.Tensor(0.36667958, shape=(), dtype=float32)\n",
            "tf.Tensor(0.36530143, shape=(), dtype=float32)\n",
            "tf.Tensor(0.36392882, shape=(), dtype=float32)\n",
            "tf.Tensor(0.36256182, shape=(), dtype=float32)\n",
            "tf.Tensor(0.36120036, shape=(), dtype=float32)\n",
            "tf.Tensor(0.35984448, shape=(), dtype=float32)\n",
            "tf.Tensor(0.35849404, shape=(), dtype=float32)\n",
            "tf.Tensor(0.35714915, shape=(), dtype=float32)\n",
            "tf.Tensor(0.35580963, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3544756, shape=(), dtype=float32)\n",
            "tf.Tensor(0.35314697, shape=(), dtype=float32)\n",
            "tf.Tensor(0.35182375, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3505059, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3491934, shape=(), dtype=float32)\n",
            "tf.Tensor(0.34788617, shape=(), dtype=float32)\n",
            "tf.Tensor(0.34658435, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3452877, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3439964, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3427103, shape=(), dtype=float32)\n",
            "tf.Tensor(0.34142944, shape=(), dtype=float32)\n",
            "tf.Tensor(0.34015375, shape=(), dtype=float32)\n",
            "tf.Tensor(0.33888328, shape=(), dtype=float32)\n",
            "tf.Tensor(0.33761793, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3363577, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3351026, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3338526, shape=(), dtype=float32)\n",
            "tf.Tensor(0.33260766, shape=(), dtype=float32)\n",
            "tf.Tensor(0.33136782, shape=(), dtype=float32)\n",
            "tf.Tensor(0.33013296, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3289031, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3276783, shape=(), dtype=float32)\n",
            "tf.Tensor(0.32645836, shape=(), dtype=float32)\n",
            "tf.Tensor(0.32524347, shape=(), dtype=float32)\n",
            "tf.Tensor(0.32403344, shape=(), dtype=float32)\n",
            "tf.Tensor(0.32282838, shape=(), dtype=float32)\n",
            "tf.Tensor(0.32162815, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3204328, shape=(), dtype=float32)\n",
            "tf.Tensor(0.31924233, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3180567, shape=(), dtype=float32)\n",
            "tf.Tensor(0.31687582, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3156998, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3145285, shape=(), dtype=float32)\n",
            "tf.Tensor(0.31336197, shape=(), dtype=float32)\n",
            "tf.Tensor(0.31220013, shape=(), dtype=float32)\n",
            "tf.Tensor(0.31104308, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3098907, shape=(), dtype=float32)\n",
            "tf.Tensor(0.30874297, shape=(), dtype=float32)\n",
            "tf.Tensor(0.30759987, shape=(), dtype=float32)\n",
            "tf.Tensor(0.30646142, shape=(), dtype=float32)\n",
            "tf.Tensor(0.30532765, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3041984, shape=(), dtype=float32)\n",
            "tf.Tensor(0.30307376, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3019537, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3008382, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2997272, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2986207, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2975187, shape=(), dtype=float32)\n",
            "tf.Tensor(0.29642114, shape=(), dtype=float32)\n",
            "tf.Tensor(0.29532805, shape=(), dtype=float32)\n",
            "tf.Tensor(0.29423943, shape=(), dtype=float32)\n",
            "tf.Tensor(0.29315522, shape=(), dtype=float32)\n",
            "tf.Tensor(0.29207537, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2909999, shape=(), dtype=float32)\n",
            "tf.Tensor(0.28992876, shape=(), dtype=float32)\n",
            "tf.Tensor(0.288862, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2877996, shape=(), dtype=float32)\n",
            "tf.Tensor(0.28674147, shape=(), dtype=float32)\n",
            "tf.Tensor(0.28568763, shape=(), dtype=float32)\n",
            "tf.Tensor(0.28463805, shape=(), dtype=float32)\n",
            "tf.Tensor(0.28359276, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2825517, shape=(), dtype=float32)\n",
            "tf.Tensor(0.28151482, shape=(), dtype=float32)\n",
            "tf.Tensor(0.28048217, shape=(), dtype=float32)\n",
            "tf.Tensor(0.27945375, shape=(), dtype=float32)\n",
            "tf.Tensor(0.27842945, shape=(), dtype=float32)\n",
            "tf.Tensor(0.27740934, shape=(), dtype=float32)\n",
            "tf.Tensor(0.27639332, shape=(), dtype=float32)\n",
            "tf.Tensor(0.27538145, shape=(), dtype=float32)\n",
            "tf.Tensor(0.27437365, shape=(), dtype=float32)\n",
            "tf.Tensor(0.27337, shape=(), dtype=float32)\n",
            "tf.Tensor(0.27237037, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2713748, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2703833, shape=(), dtype=float32)\n",
            "tf.Tensor(0.26939574, shape=(), dtype=float32)\n",
            "tf.Tensor(0.26841223, shape=(), dtype=float32)\n",
            "tf.Tensor(0.26743275, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2664572, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2654856, shape=(), dtype=float32)\n",
            "tf.Tensor(0.26451793, shape=(), dtype=float32)\n",
            "tf.Tensor(0.26355422, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2625944, shape=(), dtype=float32)\n",
            "tf.Tensor(0.26163846, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2606864, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2597382, shape=(), dtype=float32)\n",
            "tf.Tensor(0.25879383, shape=(), dtype=float32)\n",
            "tf.Tensor(0.25785327, shape=(), dtype=float32)\n",
            "tf.Tensor(0.25691655, shape=(), dtype=float32)\n",
            "tf.Tensor(0.25598368, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2550545, shape=(), dtype=float32)\n",
            "tf.Tensor(0.25412914, shape=(), dtype=float32)\n",
            "tf.Tensor(0.25320747, shape=(), dtype=float32)\n",
            "tf.Tensor(0.25228962, shape=(), dtype=float32)\n",
            "tf.Tensor(0.25137544, shape=(), dtype=float32)\n",
            "tf.Tensor(0.25046498, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24955821, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24865511, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24775566, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24685986, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24596769, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24507913, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24419418, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24331282, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24243502, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24156082, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24069007, shape=(), dtype=float32)\n",
            "tf.Tensor(0.23982292, shape=(), dtype=float32)\n",
            "tf.Tensor(0.23895928, shape=(), dtype=float32)\n",
            "tf.Tensor(0.23809913, shape=(), dtype=float32)\n",
            "tf.Tensor(0.23724246, shape=(), dtype=float32)\n",
            "tf.Tensor(0.23638926, shape=(), dtype=float32)\n",
            "tf.Tensor(0.23553953, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2346932, shape=(), dtype=float32)\n",
            "tf.Tensor(0.23385035, shape=(), dtype=float32)\n",
            "tf.Tensor(0.23301089, shape=(), dtype=float32)\n",
            "tf.Tensor(0.23217483, shape=(), dtype=float32)\n",
            "tf.Tensor(0.23134217, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2305129, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22968695, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22886439, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22804512, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2272292, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22641656, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22560725, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22480118, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22399838, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22319882, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22240254, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22160946, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22081958, shape=(), dtype=float32)\n",
            "tf.Tensor(0.22003293, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21924946, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21846914, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21769199, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21691802, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21614712, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21537939, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21461478, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21385324, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21309477, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21233939, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2115871, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21083781, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21009158, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20934835, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20860815, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20787095, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20713672, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20640546, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20567718, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20495184, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20422944, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20350994, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20279337, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20207974, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20136896, shape=(), dtype=float32)\n",
            "tf.Tensor(0.20066108, shape=(), dtype=float32)\n",
            "tf.Tensor(0.19995603, shape=(), dtype=float32)\n",
            "tf.Tensor(0.19925384, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1985545, shape=(), dtype=float32)\n",
            "tf.Tensor(0.197858, shape=(), dtype=float32)\n",
            "tf.Tensor(0.19716434, shape=(), dtype=float32)\n",
            "tf.Tensor(0.19647345, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1957854, shape=(), dtype=float32)\n",
            "tf.Tensor(0.19510008, shape=(), dtype=float32)\n",
            "tf.Tensor(0.19441755, shape=(), dtype=float32)\n",
            "tf.Tensor(0.19373783, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1930608, shape=(), dtype=float32)\n",
            "tf.Tensor(0.19238654, shape=(), dtype=float32)\n",
            "tf.Tensor(0.19171503, shape=(), dtype=float32)\n",
            "tf.Tensor(0.19104621, shape=(), dtype=float32)\n",
            "tf.Tensor(0.19038013, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18971671, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18905596, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1883979, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18774252, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18708979, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1864397, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18579224, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18514739, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18450518, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18386553, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18322848, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18259403, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18196213, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18133277, shape=(), dtype=float32)\n",
            "tf.Tensor(0.180706, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18008174, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17946002, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17884079, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1782241, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17760988, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17699814, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1763889, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17578211, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17517777, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17457588, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1739764, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17337942, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1727848, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17219263, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17160282, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17101538, shape=(), dtype=float32)\n",
            "tf.Tensor(0.17043033, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16984765, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16926733, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16868936, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16811371, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16754043, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16696942, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16640075, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16583437, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16527027, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16470847, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16414893, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16359165, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16303664, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16248389, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16193335, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16138504, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16083893, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16029507, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1597534, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1592139, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15867661, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15814145, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1576085, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15707767, shape=(), dtype=float32)\n",
            "tf.Tensor(0.156549, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15602249, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15549809, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1549758, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15445565, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15393756, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15342158, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15290771, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15239589, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15188615, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15137848, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15087286, shape=(), dtype=float32)\n",
            "tf.Tensor(0.15036929, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14986774, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14936823, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14887072, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14837524, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14788178, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14739029, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14690079, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14641328, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14592771, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14544415, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14496249, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14448284, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14400506, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14352927, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14305536, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14258339, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14211334, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14164515, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14117886, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14071451, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14025195, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13979134, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13933256, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13887562, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13842055, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1379673, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13751593, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1370663, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13661852, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1361726, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13572843, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13528608, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13484551, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13440672, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13396971, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13353446, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13310096, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13266923, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13223921, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13181095, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1313844, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13095963, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13053651, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13011514, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12969545, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12927747, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12886117, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12844658, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12803362, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12762238, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12721276, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12680481, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12639853, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12599385, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12559082, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12518942, shape=(), dtype=float32)\n",
            "tf.Tensor(0.124789655, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12439148, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12399493, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12359998, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12320662, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12281484, shape=(), dtype=float32)\n",
            "tf.Tensor(0.122424655, shape=(), dtype=float32)\n",
            "tf.Tensor(0.122036055, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12164902, shape=(), dtype=float32)\n",
            "tf.Tensor(0.121263534, shape=(), dtype=float32)\n",
            "tf.Tensor(0.120879605, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12049725, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12011641, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11973712, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11935937, shape=(), dtype=float32)\n",
            "tf.Tensor(0.118983135, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11860842, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11823521, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11786353, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11749333, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11712462, shape=(), dtype=float32)\n",
            "tf.Tensor(0.116757415, shape=(), dtype=float32)\n",
            "tf.Tensor(0.116391696, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11602745, shape=(), dtype=float32)\n",
            "tf.Tensor(0.115664676, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11530334, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1149435, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1145851, shape=(), dtype=float32)\n",
            "tf.Tensor(0.114228144, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11387261, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11351853, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11316588, shape=(), dtype=float32)\n",
            "tf.Tensor(0.112814635, shape=(), dtype=float32)\n",
            "tf.Tensor(0.112464845, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11211644, shape=(), dtype=float32)\n",
            "tf.Tensor(0.111769445, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11142386, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11107966, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11073686, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11039545, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1100554, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10971675, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10937944, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1090435, shape=(), dtype=float32)\n",
            "tf.Tensor(0.108708926, shape=(), dtype=float32)\n",
            "tf.Tensor(0.108375676, shape=(), dtype=float32)\n",
            "tf.Tensor(0.108043805, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10771326, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10738405, shape=(), dtype=float32)\n",
            "tf.Tensor(0.107056156, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10672959, shape=(), dtype=float32)\n",
            "tf.Tensor(0.106404334, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1060804, shape=(), dtype=float32)\n",
            "tf.Tensor(0.105757765, shape=(), dtype=float32)\n",
            "tf.Tensor(0.105436444, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10511643, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10479769, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10448024, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10416407, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10384917, shape=(), dtype=float32)\n",
            "tf.Tensor(0.103535555, shape=(), dtype=float32)\n",
            "tf.Tensor(0.1032232, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10291209, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10260226, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10229367, shape=(), dtype=float32)\n",
            "tf.Tensor(0.101986334, shape=(), dtype=float32)\n",
            "tf.Tensor(0.101680234, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10137536, shape=(), dtype=float32)\n",
            "tf.Tensor(0.101071715, shape=(), dtype=float32)\n",
            "tf.Tensor(0.100769304, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10046812, shape=(), dtype=float32)\n",
            "tf.Tensor(0.10016814, shape=(), dtype=float32)\n",
            "tf.Tensor(0.099869385, shape=(), dtype=float32)\n",
            "tf.Tensor(0.099571824, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09927546, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0989803, shape=(), dtype=float32)\n",
            "tf.Tensor(0.098686315, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09839352, shape=(), dtype=float32)\n",
            "tf.Tensor(0.098101914, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09781148, shape=(), dtype=float32)\n",
            "tf.Tensor(0.097522214, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09723412, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09694721, shape=(), dtype=float32)\n",
            "tf.Tensor(0.096661426, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09637681, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09609334, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09581101, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09552982, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09524976, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09497082, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09469301, shape=(), dtype=float32)\n",
            "tf.Tensor(0.094416335, shape=(), dtype=float32)\n",
            "tf.Tensor(0.094140776, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09386633, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09359299, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09332074, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0930496, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09277955, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09251059, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09224269, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0919759, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09171017, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09144554, shape=(), dtype=float32)\n",
            "tf.Tensor(0.091181956, shape=(), dtype=float32)\n",
            "tf.Tensor(0.090919435, shape=(), dtype=float32)\n",
            "tf.Tensor(0.090657964, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09039756, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09013818, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08987988, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0896226, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08936636, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08911119, shape=(), dtype=float32)\n",
            "tf.Tensor(0.088856995, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08860384, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08835171, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0881006, shape=(), dtype=float32)\n",
            "tf.Tensor(0.087850496, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08760139, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0873533, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0871062, shape=(), dtype=float32)\n",
            "tf.Tensor(0.086860105, shape=(), dtype=float32)\n",
            "tf.Tensor(0.086615, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08637089, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08612777, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08588564, shape=(), dtype=float32)\n",
            "tf.Tensor(0.085644454, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08540426, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08516502, shape=(), dtype=float32)\n",
            "tf.Tensor(0.084926754, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08468945, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08445309, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08421771, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08398326, shape=(), dtype=float32)\n",
            "tf.Tensor(0.083749756, shape=(), dtype=float32)\n",
            "tf.Tensor(0.083517194, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08328557, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08305488, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08282511, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08259628, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08236836, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08214137, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0819153, shape=(), dtype=float32)\n",
            "tf.Tensor(0.081690125, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08146587, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08124252, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08102005, shape=(), dtype=float32)\n",
            "tf.Tensor(0.080798484, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08057781, shape=(), dtype=float32)\n",
            "tf.Tensor(0.08035802, shape=(), dtype=float32)\n",
            "tf.Tensor(0.080139145, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07992113, shape=(), dtype=float32)\n",
            "tf.Tensor(0.079703994, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07948773, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07927234, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07905782, shape=(), dtype=float32)\n",
            "tf.Tensor(0.078844175, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07863139, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07841945, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07820834, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07799812, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07778873, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07758019, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07737247, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0771656, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07695958, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07675438, shape=(), dtype=float32)\n",
            "tf.Tensor(0.076549985, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07634644, shape=(), dtype=float32)\n",
            "tf.Tensor(0.076143704, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07594179, shape=(), dtype=float32)\n",
            "tf.Tensor(0.075740695, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07554041, shape=(), dtype=float32)\n",
            "tf.Tensor(0.075340904, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07514221, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07494432, shape=(), dtype=float32)\n",
            "tf.Tensor(0.074747235, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07455095, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07435543, shape=(), dtype=float32)\n",
            "tf.Tensor(0.074160725, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07396678, shape=(), dtype=float32)\n",
            "tf.Tensor(0.073773645, shape=(), dtype=float32)\n",
            "tf.Tensor(0.073581256, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07338966, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07319883, shape=(), dtype=float32)\n",
            "tf.Tensor(0.073008776, shape=(), dtype=float32)\n",
            "tf.Tensor(0.072819486, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07263095, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07244317, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07225615, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07206989, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07188438, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0716996, shape=(), dtype=float32)\n",
            "tf.Tensor(0.071515575, shape=(), dtype=float32)\n",
            "tf.Tensor(0.071332276, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07114974, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07096791, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07078683, shape=(), dtype=float32)\n",
            "tf.Tensor(0.070606485, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07042685, shape=(), dtype=float32)\n",
            "tf.Tensor(0.070247956, shape=(), dtype=float32)\n",
            "tf.Tensor(0.070069775, shape=(), dtype=float32)\n",
            "tf.Tensor(0.069892325, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06971557, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06953953, shape=(), dtype=float32)\n",
            "tf.Tensor(0.069364205, shape=(), dtype=float32)\n",
            "tf.Tensor(0.069189586, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06901567, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06884244, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06866991, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06849807, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06832694, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06815649, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06798673, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06781765, shape=(), dtype=float32)\n",
            "tf.Tensor(0.067649245, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06748154, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06731448, shape=(), dtype=float32)\n",
            "tf.Tensor(0.067148104, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06698239, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06681735, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06665298, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06648927, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06632622, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06616383, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0660021, shape=(), dtype=float32)\n",
            "tf.Tensor(0.065841004, shape=(), dtype=float32)\n",
            "tf.Tensor(0.065680556, shape=(), dtype=float32)\n",
            "tf.Tensor(0.065520756, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06536159, shape=(), dtype=float32)\n",
            "tf.Tensor(0.065203086, shape=(), dtype=float32)\n",
            "tf.Tensor(0.065045215, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06488797, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06473135, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06457538, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06442003, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06426529, shape=(), dtype=float32)\n",
            "tf.Tensor(0.064111196, shape=(), dtype=float32)\n",
            "tf.Tensor(0.063957706, shape=(), dtype=float32)\n",
            "tf.Tensor(0.063804835, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06365258, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06350094, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0633499, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06319948, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06304967, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06290045, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06275182, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06260381, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06245639, shape=(), dtype=float32)\n",
            "tf.Tensor(0.062309552, shape=(), dtype=float32)\n",
            "tf.Tensor(0.062163316, shape=(), dtype=float32)\n",
            "tf.Tensor(0.062017653, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06187259, shape=(), dtype=float32)\n",
            "tf.Tensor(0.061728112, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06158422, shape=(), dtype=float32)\n",
            "tf.Tensor(0.061440907, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06129816, shape=(), dtype=float32)\n",
            "tf.Tensor(0.061155975, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06101438, shape=(), dtype=float32)\n",
            "tf.Tensor(0.060873345, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06073288, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06059298, shape=(), dtype=float32)\n",
            "tf.Tensor(0.060453642, shape=(), dtype=float32)\n",
            "tf.Tensor(0.060314864, shape=(), dtype=float32)\n",
            "tf.Tensor(0.060176644, shape=(), dtype=float32)\n",
            "tf.Tensor(0.060038988, shape=(), dtype=float32)\n",
            "tf.Tensor(0.059901867, shape=(), dtype=float32)\n",
            "tf.Tensor(0.059765305, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0596293, shape=(), dtype=float32)\n",
            "tf.Tensor(0.059493836, shape=(), dtype=float32)\n",
            "tf.Tensor(0.059358917, shape=(), dtype=float32)\n",
            "tf.Tensor(0.059224542, shape=(), dtype=float32)\n",
            "tf.Tensor(0.059090707, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05895741, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05882466, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05869243, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05856072, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05842956, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05829892, shape=(), dtype=float32)\n",
            "tf.Tensor(0.058168806, shape=(), dtype=float32)\n",
            "tf.Tensor(0.058039207, shape=(), dtype=float32)\n",
            "tf.Tensor(0.057910144, shape=(), dtype=float32)\n",
            "tf.Tensor(0.057781592, shape=(), dtype=float32)\n",
            "tf.Tensor(0.057653565, shape=(), dtype=float32)\n",
            "tf.Tensor(0.057526045, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05739903, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05727254, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05714655, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05702106, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05689608, shape=(), dtype=float32)\n",
            "tf.Tensor(0.056771606, shape=(), dtype=float32)\n",
            "tf.Tensor(0.056647632, shape=(), dtype=float32)\n",
            "tf.Tensor(0.056524154, shape=(), dtype=float32)\n",
            "tf.Tensor(0.056401167, shape=(), dtype=float32)\n",
            "tf.Tensor(0.056278687, shape=(), dtype=float32)\n",
            "tf.Tensor(0.056156676, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05603518, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05591417, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05579363, shape=(), dtype=float32)\n",
            "tf.Tensor(0.055673584, shape=(), dtype=float32)\n",
            "tf.Tensor(0.055554025, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05543494, shape=(), dtype=float32)\n",
            "tf.Tensor(0.055316336, shape=(), dtype=float32)\n",
            "tf.Tensor(0.055198207, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05508055, shape=(), dtype=float32)\n",
            "tf.Tensor(0.054963373, shape=(), dtype=float32)\n",
            "tf.Tensor(0.054846656, shape=(), dtype=float32)\n",
            "tf.Tensor(0.054730415, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05461465, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05449933, shape=(), dtype=float32)\n",
            "tf.Tensor(0.054384485, shape=(), dtype=float32)\n",
            "tf.Tensor(0.054270096, shape=(), dtype=float32)\n",
            "tf.Tensor(0.054156177, shape=(), dtype=float32)\n",
            "tf.Tensor(0.054042708, shape=(), dtype=float32)\n",
            "tf.Tensor(0.053929687, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05381713, shape=(), dtype=float32)\n",
            "tf.Tensor(0.053705033, shape=(), dtype=float32)\n",
            "tf.Tensor(0.053593375, shape=(), dtype=float32)\n",
            "tf.Tensor(0.053482164, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0533714, shape=(), dtype=float32)\n",
            "tf.Tensor(0.053261075, shape=(), dtype=float32)\n",
            "tf.Tensor(0.053151198, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05304177, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05293277, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05282421, shape=(), dtype=float32)\n",
            "tf.Tensor(0.052716095, shape=(), dtype=float32)\n",
            "tf.Tensor(0.052608397, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05250116, shape=(), dtype=float32)\n",
            "tf.Tensor(0.052394334, shape=(), dtype=float32)\n",
            "tf.Tensor(0.052287944, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05218197, shape=(), dtype=float32)\n",
            "tf.Tensor(0.052076437, shape=(), dtype=float32)\n",
            "tf.Tensor(0.051971313, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05186663, shape=(), dtype=float32)\n",
            "tf.Tensor(0.051762354, shape=(), dtype=float32)\n",
            "tf.Tensor(0.051658493, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05155506, shape=(), dtype=float32)\n",
            "tf.Tensor(0.051452033, shape=(), dtype=float32)\n",
            "tf.Tensor(0.051349435, shape=(), dtype=float32)\n",
            "tf.Tensor(0.051247228, shape=(), dtype=float32)\n",
            "tf.Tensor(0.051145434, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05104406, shape=(), dtype=float32)\n",
            "tf.Tensor(0.050943088, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05084252, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05074236, shape=(), dtype=float32)\n",
            "tf.Tensor(0.050642595, shape=(), dtype=float32)\n",
            "tf.Tensor(0.050543245, shape=(), dtype=float32)\n",
            "tf.Tensor(0.050444286, shape=(), dtype=float32)\n",
            "tf.Tensor(0.050345723, shape=(), dtype=float32)\n",
            "tf.Tensor(0.050247546, shape=(), dtype=float32)\n",
            "tf.Tensor(0.05014978, shape=(), dtype=float32)\n",
            "tf.Tensor(0.050052397, shape=(), dtype=float32)\n",
            "tf.Tensor(0.049955413, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0498588, shape=(), dtype=float32)\n",
            "tf.Tensor(0.049762595, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04966677, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04957133, shape=(), dtype=float32)\n",
            "tf.Tensor(0.049476273, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0493816, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0492873, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04919338, shape=(), dtype=float32)\n",
            "tf.Tensor(0.049099836, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04900667, shape=(), dtype=float32)\n",
            "tf.Tensor(0.048913874, shape=(), dtype=float32)\n",
            "tf.Tensor(0.048821457, shape=(), dtype=float32)\n",
            "tf.Tensor(0.048729416, shape=(), dtype=float32)\n",
            "tf.Tensor(0.048637733, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04854642, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04845546, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04836489, shape=(), dtype=float32)\n",
            "tf.Tensor(0.048274674, shape=(), dtype=float32)\n",
            "tf.Tensor(0.048184816, shape=(), dtype=float32)\n",
            "tf.Tensor(0.048095316, shape=(), dtype=float32)\n",
            "tf.Tensor(0.048006184, shape=(), dtype=float32)\n",
            "tf.Tensor(0.047917396, shape=(), dtype=float32)\n",
            "tf.Tensor(0.047828976, shape=(), dtype=float32)\n",
            "tf.Tensor(0.047740906, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0476532, shape=(), dtype=float32)\n",
            "tf.Tensor(0.047565833, shape=(), dtype=float32)\n",
            "tf.Tensor(0.047478817, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04739216, shape=(), dtype=float32)\n",
            "tf.Tensor(0.047305834, shape=(), dtype=float32)\n",
            "tf.Tensor(0.047219872, shape=(), dtype=float32)\n",
            "tf.Tensor(0.047134243, shape=(), dtype=float32)\n",
            "tf.Tensor(0.047048964, shape=(), dtype=float32)\n",
            "tf.Tensor(0.046964027, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04687943, shape=(), dtype=float32)\n",
            "tf.Tensor(0.046795167, shape=(), dtype=float32)\n",
            "tf.Tensor(0.046711247, shape=(), dtype=float32)\n",
            "tf.Tensor(0.046627656, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04654441, shape=(), dtype=float32)\n",
            "tf.Tensor(0.046461497, shape=(), dtype=float32)\n",
            "tf.Tensor(0.046378914, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04629666, shape=(), dtype=float32)\n",
            "tf.Tensor(0.046214733, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04613315, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04605188, shape=(), dtype=float32)\n",
            "tf.Tensor(0.045970947, shape=(), dtype=float32)\n",
            "tf.Tensor(0.045890328, shape=(), dtype=float32)\n",
            "tf.Tensor(0.045810036, shape=(), dtype=float32)\n",
            "tf.Tensor(0.045730066, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04565042, shape=(), dtype=float32)\n",
            "tf.Tensor(0.045571085, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04549208, shape=(), dtype=float32)\n",
            "tf.Tensor(0.045413382, shape=(), dtype=float32)\n",
            "tf.Tensor(0.045335006, shape=(), dtype=float32)\n",
            "tf.Tensor(0.045256946, shape=(), dtype=float32)\n",
            "tf.Tensor(0.045179196, shape=(), dtype=float32)\n",
            "tf.Tensor(0.045101754, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04502462, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04494779, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04487129, shape=(), dtype=float32)\n",
            "tf.Tensor(0.044795085, shape=(), dtype=float32)\n",
            "tf.Tensor(0.044719182, shape=(), dtype=float32)\n",
            "tf.Tensor(0.044643585, shape=(), dtype=float32)\n",
            "tf.Tensor(0.044568293, shape=(), dtype=float32)\n",
            "tf.Tensor(0.044493295, shape=(), dtype=float32)\n",
            "tf.Tensor(0.044418607, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04434422, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04427012, shape=(), dtype=float32)\n",
            "tf.Tensor(0.044196326, shape=(), dtype=float32)\n",
            "tf.Tensor(0.044122826, shape=(), dtype=float32)\n",
            "tf.Tensor(0.044049617, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0439767, shape=(), dtype=float32)\n",
            "tf.Tensor(0.043904085, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04383176, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04375971, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04368796, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0436165, shape=(), dtype=float32)\n",
            "tf.Tensor(0.043545328, shape=(), dtype=float32)\n",
            "tf.Tensor(0.043474432, shape=(), dtype=float32)\n",
            "tf.Tensor(0.043403823, shape=(), dtype=float32)\n",
            "tf.Tensor(0.043333508, shape=(), dtype=float32)\n",
            "tf.Tensor(0.043263458, shape=(), dtype=float32)\n",
            "tf.Tensor(0.043193698, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04312422, shape=(), dtype=float32)\n",
            "tf.Tensor(0.043055017, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04298609, shape=(), dtype=float32)\n",
            "tf.Tensor(0.042917434, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04284906, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04278096, shape=(), dtype=float32)\n",
            "tf.Tensor(0.042713143, shape=(), dtype=float32)\n",
            "tf.Tensor(0.042645585, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04257829, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04251128, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04244453, shape=(), dtype=float32)\n",
            "tf.Tensor(0.042378057, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04231184, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04224589, shape=(), dtype=float32)\n",
            "tf.Tensor(0.042180207, shape=(), dtype=float32)\n",
            "tf.Tensor(0.042114783, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04204962, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04198473, shape=(), dtype=float32)\n",
            "tf.Tensor(0.041920096, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04185571, shape=(), dtype=float32)\n",
            "tf.Tensor(0.041791588, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04172772, shape=(), dtype=float32)\n",
            "tf.Tensor(0.041664116, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04160076, shape=(), dtype=float32)\n",
            "tf.Tensor(0.041537665, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04147481, shape=(), dtype=float32)\n",
            "tf.Tensor(0.041412223, shape=(), dtype=float32)\n",
            "tf.Tensor(0.041349877, shape=(), dtype=float32)\n",
            "tf.Tensor(0.041287776, shape=(), dtype=float32)\n",
            "tf.Tensor(0.041225936, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04116434, shape=(), dtype=float32)\n",
            "tf.Tensor(0.041102983, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04104188, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040981017, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040920407, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040860027, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040799897, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040740006, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040680353, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04062094, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04056176, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040502828, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040444117, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04038566, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040327422, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040269423, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04021166, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04015412, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040096816, shape=(), dtype=float32)\n",
            "tf.Tensor(0.040039733, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039982885, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03992626, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039869875, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03981371, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039757762, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03970204, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039646536, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039591264, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039536208, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039481375, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039426774, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039372377, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0393182, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039264243, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039210495, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03915696, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039103646, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039050546, shape=(), dtype=float32)\n",
            "tf.Tensor(0.038997658, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03894498, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03889251, shape=(), dtype=float32)\n",
            "tf.Tensor(0.038840257, shape=(), dtype=float32)\n",
            "tf.Tensor(0.038788207, shape=(), dtype=float32)\n",
            "tf.Tensor(0.038736366, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03868473, shape=(), dtype=float32)\n",
            "tf.Tensor(0.038633313, shape=(), dtype=float32)\n",
            "tf.Tensor(0.038582083, shape=(), dtype=float32)\n",
            "tf.Tensor(0.038531076, shape=(), dtype=float32)\n",
            "tf.Tensor(0.038480263, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03842965, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03837925, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03832905, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03827904, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03822924, shape=(), dtype=float32)\n",
            "tf.Tensor(0.038179643, shape=(), dtype=float32)\n",
            "tf.Tensor(0.038130235, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03808103, shape=(), dtype=float32)\n",
            "tf.Tensor(0.038032014, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03798321, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03793459, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03788616, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037837934, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037789896, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037742056, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037694406, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037646938, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037599664, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037552573, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03750568, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037458967, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037412446, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03736611, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037319962, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037274, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037228215, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037182618, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037137203, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037091963, shape=(), dtype=float32)\n",
            "tf.Tensor(0.037046913, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03700204, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036957335, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036912818, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03686848, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036824327, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036780342, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036736533, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036692906, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036649443, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036606163, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036563054, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03652012, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036477353, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036434747, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036392316, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03635006, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036307972, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03626605, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0362243, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036182716, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036141295, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036100045, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03605895, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036018033, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03597727, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035936672, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03589624, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035855964, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035815846, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03577589, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03573609, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035696466, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03565698, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03561767, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03557851, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0355395, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035500653, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035461955, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035423424, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035385024, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035346795, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03530872, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0352708, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035233017, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035195395, shape=(), dtype=float32)\n",
            "tf.Tensor(0.035157923, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0351206, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03508342, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03504639, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03500951, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034972783, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034936197, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034899756, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034863465, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034827318, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03479131, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034755446, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034719735, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034684163, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03464873, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03461344, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034578286, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03454328, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034508407, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034473676, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034439087, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034404635, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034370314, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034336142, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0343021, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034268193, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034234423, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03420079, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034167286, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03413392, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034100685, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03406759, shape=(), dtype=float32)\n",
            "tf.Tensor(0.034034617, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03400178, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03396907, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033936486, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033904046, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033871725, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033839535, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03380748, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033775542, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033743735, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033712067, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033680514, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033649087, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033617787, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033586614, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033555556, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033524632, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033493828, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033463147, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033432588, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033402152, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033371832, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033341642, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033311572, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033281617, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033251785, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033222076, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033192474, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033163, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033133637, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033104394, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03307527, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033046257, shape=(), dtype=float32)\n",
            "tf.Tensor(0.033017363, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03298858, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03295992, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032931373, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03290293, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03287461, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0328464, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032818303, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032790318, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03276244, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03273468, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03270703, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03267949, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032652054, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032624733, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03259752, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03257042, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032543425, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03251653, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032489747, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032463074, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03243651, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03241004, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032383684, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032357432, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032331284, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032305237, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032279305, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032253467, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032227736, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032202106, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032176584, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032151155, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032125827, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03210061, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032075487, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03205046, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032025542, shape=(), dtype=float32)\n",
            "tf.Tensor(0.032000717, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031975996, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031951368, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031926837, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031902403, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031878065, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031853832, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031829696, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031805646, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031781703, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031757854, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03173409, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031710427, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031686857, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03166339, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031640004, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031616718, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031593524, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031570423, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031547412, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031524494, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031501666, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03147893, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031456284, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03143373, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03141126, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031388883, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031366598, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0313444, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03132229, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031300265, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031278335, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031256486, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031234726, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03121305, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031191457, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031169964, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031148547, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031127213, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03110597, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031084806, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031063732, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03104274, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03102183, shape=(), dtype=float32)\n",
            "tf.Tensor(0.031001003, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030980263, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030959602, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030939026, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030918531, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030898113, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030877782, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030857531, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03083736, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030817267, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03079726, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030777324, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030757472, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030737704, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03071801, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030698393, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030678852, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030659396, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030640015, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030620713, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030601483, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030582326, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030563248, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030544251, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03052533, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03050648, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030487705, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03046901, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030450381, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030431831, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030413354, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03039495, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03037662, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030358365, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030340184, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030322071, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030304035, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030286064, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030268174, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030250346, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030232597, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030214913, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0301973, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030179758, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030162284, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03014488, shape=(), dtype=float32)\n",
            "tf.Tensor(0.03012754, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030110274, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030093078, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030075949, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030058887, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030041896, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030024972, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030008113, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029991321, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029974598, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029957943, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029941348, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029924823, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029908363, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029891971, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029875642, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029859377, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029843181, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029827042, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029810974, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029794963, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029779023, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029763145, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02974733, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029731575, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029715883, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029700253, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029684685, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029669184, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029653735, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029638356, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029623032, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029607775, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02959258, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029577442, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029562362, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029547341, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02953238, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029517485, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029502645, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029487865, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029473143, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02945848, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029443875, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02942933, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02941484, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029400406, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029386032, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029371714, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029357454, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029343246, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029329102, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029315012, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029300975, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029286994, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029273069, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0292592, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029245388, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029231627, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029217927, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029204277, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029190678, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029177139, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029163651, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029150218, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029136833, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02912351, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029110234, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02909701, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029083839, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029070726, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029057661, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029044649, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029031685, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029018773, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029005919, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02899311, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028980354, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028967641, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02895499, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02894238, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028929824, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028917324, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028904868, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02889246, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028880104, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028867798, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028855536, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028843325, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028831162, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028819049, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028806983, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028794963, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028782997, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028771076, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0287592, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028747376, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028735595, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028723862, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028712178, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028700534, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028688937, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028677395, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028665889, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02865443, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028643018, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02863165, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028620329, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028609047, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028597817, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028586632, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028575491, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028564392, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028553337, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028542329, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028531358, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028520437, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028509554, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028498717, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028487926, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028477173, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028466461, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028455798, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028445173, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028434593, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028424053, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028413555, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0284031, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02839269, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02838231, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02837198, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028361687, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028351437, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028341223, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028331054, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028320929, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02831084, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028300788, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028290778, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028280815, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028270885, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028260995, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028251141, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02824133, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028231557, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028221821, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028212128, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028202469, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02819285, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028183267, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028173726, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02816422, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028154755, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028145323, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02813593, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028126577, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028117256, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028107975, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028098732, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028089523, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02808035, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028071217, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028062116, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028053055, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028044028, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028035037, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028026082, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028017167, shape=(), dtype=float32)\n",
            "tf.Tensor(0.028008278, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027999427, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027990611, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027981834, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027973091, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027964376, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027955703, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027947063, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027938455, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027929882, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027921345, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027912837, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027904369, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027895927, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027887525, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027879154, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027870815, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027862506, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027854236, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027846001, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027837789, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027829621, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027821476, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02781337, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027805291, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02779724, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02778923, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027781248, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027773296, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02776538, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027757492, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027749637, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02774181, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02773402, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027726253, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027718522, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02771082, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027703147, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027695509, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027687898, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027680317, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02767277, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027665248, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027657757, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027650295, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027642865, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02763546, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02762809, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027620746, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027613431, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027606145, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02759889, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027591659, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027584461, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02757729, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027570145, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02756303, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027555946, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027548889, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02754186, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02753486, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027527882, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027520938, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027514018, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02750713, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027500262, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027493427, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027486619, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027479831, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027473079, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027466351, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027459644, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027452972, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02744632, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027439693, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027433092, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027426522, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027419979, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027413454, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027406963, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02740049, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02739405, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027387632, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027381241, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027374875, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02736853, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027362213, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027355922, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027349653, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027343415, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027337195, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027331006, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027324833, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02731869, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027312573, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027306478, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027300406, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027294356, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027288334, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027282337, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027276361, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027270408, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027264481, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027258571, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027252689, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027246835, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027240997, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027235184, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027229395, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027223628, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027217882, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027212162, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027206467, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02720079, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027195137, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027189506, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027183896, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027178306, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027172744, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0271672, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027161678, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027156182, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027150704, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027145248, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027139813, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0271344, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02712901, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02712364, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027118292, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027112965, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027107656, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027102372, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027097112, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027091864, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02708664, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027081437, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027076257, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027071094, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027065957, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027060833, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027055731, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027050653, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02704559, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027040552, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027035529, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027030531, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027025547, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02702059, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027015645, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027010726, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027005823, shape=(), dtype=float32)\n",
            "tf.Tensor(0.027000938, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026996076, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026991233, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026986407, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026981601, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026976813, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026972046, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026967293, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026962565, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026957847, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026953159, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02694848, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026943825, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026939185, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026934564, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026929965, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026925381, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026920812, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026916267, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02691174, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026907222, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026902733, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026898257, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026893795, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026889354, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02688493, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026880529, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026876137, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026871765, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02686741, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026863078, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026858756, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02685445, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026850168, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026845898, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026841648, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026837412, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026833197, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026828993, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026824808, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026820641, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026816484, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026812349, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026808232, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026804127, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026800038, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026795968, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026791912, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026787873, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026783856, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026779842, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026775852, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026771877, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026767917, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026763974, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026760042, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026756132, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026752232, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026748348, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026744483, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026740631, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026736798, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02673297, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026729168, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026725372, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0267216, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026717838, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02671409, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026710358, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026706642, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026702937, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026699249, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026695576, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026691917, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026688272, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026684644, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026681026, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026677424, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026673838, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026670264, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026666706, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02666316, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02665963, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026656114, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02665261, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026649121, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026645642, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026642177, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02663873, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026635295, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026631873, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026628466, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026625069, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026621688, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026618324, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026614968, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02661163, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0266083, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026604984, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026601685, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026598394, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026595118, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026591856, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026588602, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026585367, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026582144, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02657893, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026575731, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026572544, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02656937, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02656621, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026563061, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026559925, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026556801, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026553685, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026550587, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026547503, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026544427, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026541362, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02653831, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02653527, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026532242, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026529225, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026526222, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02652323, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026520249, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026517281, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026514325, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026511379, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026508447, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026505524, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026502613, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026499715, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026496826, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02649395, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026491089, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026488235, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026485391, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02648256, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026479736, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026476933, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026474133, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026471345, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026468571, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026465805, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02646305, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026460307, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026457572, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026454851, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026452137, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02644944, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02644675, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026444068, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026441405, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026438745, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026436098, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02643346, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026430834, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026428219, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026425611, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026423015, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02642043, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026417855, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026415287, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026412731, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026410187, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026407648, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026405126, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026402611, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026400104, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02639761, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026395123, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02639265, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026390182, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026387721, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026385278, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02638284, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02638041, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026377995, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02637559, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026373183, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026370795, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026368415, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026366048, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026363682, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02636133, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026358988, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026356652, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02635433, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026352013, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026349705, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026347408, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026345119, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02634284, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026340568, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026338309, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026336053, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02633381, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026331574, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026329348, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026327131, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026324922, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02632272, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02632053, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026318345, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026316175, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026314007, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026311848, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0263097, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02630756, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026305428, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026303306, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026301194, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026299082, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026296986, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026294895, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02629281, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02629074, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02628867, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026286613, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026284564, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026282521, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02628049, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026278464, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026276447, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026274437, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026272435, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026270442, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026268452, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026266474, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026264504, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026262539, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026260588, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02625864, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026256703, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026254768, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026252842, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026250927, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026249016, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026247116, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026245223, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026243335, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026241455, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02623958, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026237719, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02623586, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026234008, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026232166, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02623033, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026228502, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02622668, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026224867, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026223058, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026221259, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026219467, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026217679, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0262159, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026214128, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026212363, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026210606, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026208855, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02620711, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026205372, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02620364, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026201915, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0262002, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026198488, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026196785, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026195087, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026193395, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026191713, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026190035, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026188364, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0261867, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026185043, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026183391, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026181748, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02618011, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026178477, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026176851, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026175236, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02617362, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026172012, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026170416, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02616882, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026167234, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026165653, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026164077, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026162507, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026160944, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026159387, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026157835, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026156295, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026154758, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026153227, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026151702, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026150176, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026148662, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026147155, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02614565, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026144158, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026142666, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02614118, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026139699, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026138227, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026136762, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026135296, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02613384, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02613239, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026130946, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026129505, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026128074, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026126646, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026125222, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026123809, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026122399, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02612099, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026119592, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026118197, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026116807, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026115425, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026114045, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026112674, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026111305, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026109943, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026108587, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026107235, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02610589, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026104549, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026103213, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026101884, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026100557, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026099239, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026097924, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026096614, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026095314, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026094012, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026092716, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026091427, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026090141, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026088864, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02608759, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02608632, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026085055, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026083797, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026082542, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026081294, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026080046, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026078807, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026077572, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026076343, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02607512, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0260739, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026072685, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026071472, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026070263, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026069064, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026067868, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026066676, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02606549, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026064306, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02606313, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026061954, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026060784, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02605962, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02605846, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026057305, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026056156, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02605501, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02605387, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026052728, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026051598, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026050469, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026049346, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026048226, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026047112, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026046002, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026044896, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026043793, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026042696, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0260416, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026040511, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026039422, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026038347, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026037268, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026036197, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026035128, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026034065, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026033005, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026031952, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026030896, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02602985, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026028808, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02602777, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026026737, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026025703, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026024673, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026023652, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026022632, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026021618, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026020609, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0260196, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026018597, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026017597, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026016602, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026015611, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026014624, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026013637, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02601266, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026011685, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02601071, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026009742, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026008781, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02600782, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02600686, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026005907, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026004957, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026004013, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02600307, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026002128, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026001196, shape=(), dtype=float32)\n",
            "tf.Tensor(0.026000267, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025999336, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025998412, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025997493, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025996575, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025995662, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025994752, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025993844, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025992943, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025992043, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025991147, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025990255, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025989369, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025988482, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025987603, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025986724, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025985848, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025984976, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025984108, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025983242, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025982384, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025981525, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025980666, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025979817, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025978971, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025978126, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025977284, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025976446, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025975613, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025974782, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025973953, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02597313, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025972305, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025971487, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025970677, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025969861, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02596905, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025968246, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025967441, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025966644, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02596585, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025965054, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025964262, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025963478, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025962692, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025961911, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025961136, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02596036, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025959587, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025958821, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025958056, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02595729, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02595653, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025955776, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025955021, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02595427, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025953522, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025952782, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025952034, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025951294, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025950558, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025949826, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025949094, shape=(), dtype=float32)\n",
            "tf.Tensor(0.025948366, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adgY-dPk7NlP",
        "outputId": "ac374c31-e59d-4915-b9e5-dfad27689712"
      },
      "source": [
        "class LinearRegressionKeras(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = tf.keras.layers.Dense(1, activation=None) # , input_shape=[1]\n",
        "\n",
        "    def call(self, x): \n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "def generate_data(n=2000):\n",
        "    x = np.random.uniform(-math.pi,math.pi, n)\n",
        "    noise = np.random.normal(0, 0.15, n)\n",
        "    y = np.sin(x) + noise\n",
        "    return x.astype(np.float32), y.astype(np.float32)\n",
        "\n",
        "x, y = generate_data()\n",
        "\n",
        "learning_rate = 0.002\n",
        "\n",
        "tf_model = LinearRegressionKeras()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "def squared_error(y_pred, y_true):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y_true))\n",
        "\n",
        "tf_model_train_loop = LinearRegressionKeras()\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "for epoch in range(2000):\n",
        "    x_batch = tf.reshape(x, [2000, 1])\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = tf_model_train_loop(x_batch)\n",
        "        y_pred = tf.reshape(y_pred, [2000])\n",
        "        loss = tf.losses.mse(y_pred, y)\n",
        "    \n",
        "    grads = tape.gradient(loss, tf_model_train_loop.variables)\n",
        "    \n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, tf_model_train_loop.variables))\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch} : Loss {loss.numpy()}\")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 : Loss 12.20061206817627\n",
            "Epoch 20 : Loss 7.18570613861084\n",
            "Epoch 40 : Loss 4.270078182220459\n",
            "Epoch 60 : Loss 2.5749545097351074\n",
            "Epoch 80 : Loss 1.5894218683242798\n",
            "Epoch 100 : Loss 1.0164408683776855\n",
            "Epoch 120 : Loss 0.6833142638206482\n",
            "Epoch 140 : Loss 0.48963701725006104\n",
            "Epoch 160 : Loss 0.377034455537796\n",
            "Epoch 180 : Loss 0.3115682005882263\n",
            "Epoch 200 : Loss 0.27350664138793945\n",
            "Epoch 220 : Loss 0.2513779103755951\n",
            "Epoch 240 : Loss 0.23851245641708374\n",
            "Epoch 260 : Loss 0.23103255033493042\n",
            "Epoch 280 : Loss 0.22668379545211792\n",
            "Epoch 300 : Loss 0.2241554707288742\n",
            "Epoch 320 : Loss 0.2226855456829071\n",
            "Epoch 340 : Loss 0.22183090448379517\n",
            "Epoch 360 : Loss 0.22133402526378632\n",
            "Epoch 380 : Loss 0.22104515135288239\n",
            "Epoch 400 : Loss 0.22087720036506653\n",
            "Epoch 420 : Loss 0.22077953815460205\n",
            "Epoch 440 : Loss 0.22072277963161469\n",
            "Epoch 460 : Loss 0.22068975865840912\n",
            "Epoch 480 : Loss 0.22067059576511383\n",
            "Epoch 500 : Loss 0.22065943479537964\n",
            "Epoch 520 : Loss 0.22065293788909912\n",
            "Epoch 540 : Loss 0.22064916789531708\n",
            "Epoch 560 : Loss 0.2206469625234604\n",
            "Epoch 580 : Loss 0.2206456959247589\n",
            "Epoch 600 : Loss 0.22064493596553802\n",
            "Epoch 620 : Loss 0.2206445336341858\n",
            "Epoch 640 : Loss 0.2206442505121231\n",
            "Epoch 660 : Loss 0.22064411640167236\n",
            "Epoch 680 : Loss 0.2206440418958664\n",
            "Epoch 700 : Loss 0.22064398229122162\n",
            "Epoch 720 : Loss 0.22064395248889923\n",
            "Epoch 740 : Loss 0.22064395248889923\n",
            "Epoch 760 : Loss 0.22064392268657684\n",
            "Epoch 780 : Loss 0.22064393758773804\n",
            "Epoch 800 : Loss 0.22064393758773804\n",
            "Epoch 820 : Loss 0.22064392268657684\n",
            "Epoch 840 : Loss 0.22064393758773804\n",
            "Epoch 860 : Loss 0.22064393758773804\n",
            "Epoch 880 : Loss 0.22064393758773804\n",
            "Epoch 900 : Loss 0.22064395248889923\n",
            "Epoch 920 : Loss 0.22064390778541565\n",
            "Epoch 940 : Loss 0.22064392268657684\n",
            "Epoch 960 : Loss 0.22064390778541565\n",
            "Epoch 980 : Loss 0.22064393758773804\n",
            "Epoch 1000 : Loss 0.22064390778541565\n",
            "Epoch 1020 : Loss 0.22064393758773804\n",
            "Epoch 1040 : Loss 0.22064390778541565\n",
            "Epoch 1060 : Loss 0.22064392268657684\n",
            "Epoch 1080 : Loss 0.22064392268657684\n",
            "Epoch 1100 : Loss 0.22064392268657684\n",
            "Epoch 1120 : Loss 0.22064393758773804\n",
            "Epoch 1140 : Loss 0.22064392268657684\n",
            "Epoch 1160 : Loss 0.22064392268657684\n",
            "Epoch 1180 : Loss 0.22064392268657684\n",
            "Epoch 1200 : Loss 0.22064392268657684\n",
            "Epoch 1220 : Loss 0.22064393758773804\n",
            "Epoch 1240 : Loss 0.22064392268657684\n",
            "Epoch 1260 : Loss 0.22064392268657684\n",
            "Epoch 1280 : Loss 0.22064392268657684\n",
            "Epoch 1300 : Loss 0.22064390778541565\n",
            "Epoch 1320 : Loss 0.22064392268657684\n",
            "Epoch 1340 : Loss 0.22064392268657684\n",
            "Epoch 1360 : Loss 0.22064392268657684\n",
            "Epoch 1380 : Loss 0.22064392268657684\n",
            "Epoch 1400 : Loss 0.22064393758773804\n",
            "Epoch 1420 : Loss 0.22064393758773804\n",
            "Epoch 1440 : Loss 0.22064392268657684\n",
            "Epoch 1460 : Loss 0.22064392268657684\n",
            "Epoch 1480 : Loss 0.22064392268657684\n",
            "Epoch 1500 : Loss 0.22064392268657684\n",
            "Epoch 1520 : Loss 0.22064392268657684\n",
            "Epoch 1540 : Loss 0.22064392268657684\n",
            "Epoch 1560 : Loss 0.22064392268657684\n",
            "Epoch 1580 : Loss 0.22064392268657684\n",
            "Epoch 1600 : Loss 0.22064393758773804\n",
            "Epoch 1620 : Loss 0.22064393758773804\n",
            "Epoch 1640 : Loss 0.22064392268657684\n",
            "Epoch 1660 : Loss 0.22064393758773804\n",
            "Epoch 1680 : Loss 0.22064392268657684\n",
            "Epoch 1700 : Loss 0.22064395248889923\n",
            "Epoch 1720 : Loss 0.22064392268657684\n",
            "Epoch 1740 : Loss 0.22064392268657684\n",
            "Epoch 1760 : Loss 0.22064392268657684\n",
            "Epoch 1780 : Loss 0.22064392268657684\n",
            "Epoch 1800 : Loss 0.22064392268657684\n",
            "Epoch 1820 : Loss 0.22064392268657684\n",
            "Epoch 1840 : Loss 0.22064392268657684\n",
            "Epoch 1860 : Loss 0.22064392268657684\n",
            "Epoch 1880 : Loss 0.22064392268657684\n",
            "Epoch 1900 : Loss 0.22064392268657684\n",
            "Epoch 1920 : Loss 0.22064392268657684\n",
            "Epoch 1940 : Loss 0.22064392268657684\n",
            "Epoch 1960 : Loss 0.22064392268657684\n",
            "Epoch 1980 : Loss 0.22064392268657684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQdetMfJXrj9"
      },
      "source": [
        "*PyTorch*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEi8kQcpzRGX"
      },
      "source": [
        "import torch\n",
        "class LinearRegressionPyTorch(torch.nn.Module): \n",
        "    def __init__(self): \n",
        "        super().__init__() \n",
        "        self.w3 = torch.nn.Parameter(torch.Tensor(1, 1).uniform_())\n",
        "        self.w2 = torch.nn.Parameter(torch.Tensor(1, 1).uniform_())\n",
        "        self.w1 = torch.nn.Parameter(torch.Tensor(1, 1).uniform_())\n",
        "        self.b = torch.nn.Parameter(torch.Tensor(1).uniform_())\n",
        "    def forward(self, x):  \n",
        "        return  x**3@self.w3 + x**2@self.w2 + x @ self.w1 + self.b"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Si3j-4pSaeN",
        "outputId": "315e251e-9fb5-46fc-d2a3-1bf57e322458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "def generate_data(n=2000):\n",
        "    x = np.random.uniform(-math.pi,math.pi, n)\n",
        "    noise = np.random.normal(0, 0.15, n)\n",
        "    y = np.sin(x) + noise\n",
        "    return x.astype(np.float32), y.astype(np.float32)\n",
        "\n",
        "x, y = generate_data()\n",
        "\n",
        "x = torch.from_numpy(x.reshape(-1, 1))\n",
        "y = torch.from_numpy(y.reshape(-1, 1))\n",
        "\n",
        "torch_model = LinearRegressionPyTorch()\n",
        "[w3, w2, w1, b] =  torch_model.parameters()\n",
        "\n",
        "def squared_error(y_pred, y_true):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y_true))\n",
        "\n",
        "learning_rate = 1e-6\n",
        "\n",
        "for t in range(2000):\n",
        "    # Forward pass: compute predicted y\n",
        "    # y = a + b x + c x^2 + d x^3\n",
        "    y_pred = torch_model(x)    \n",
        "\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_b = torch.sum(grad_y_pred)\n",
        "    grad_w1 = torch.sum(grad_y_pred * x)\n",
        "    grad_w2 = torch.sum(grad_y_pred * x ** 2)\n",
        "    grad_w3 =  torch.sum(grad_y_pred * x ** 3)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "    # Update weights\n",
        "        b -= learning_rate * grad_b\n",
        "        w1 -= learning_rate * grad_w1\n",
        "        w2 -= learning_rate * grad_w2\n",
        "        w3 -= learning_rate * grad_w3\n",
        "\n",
        "    print(b)\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([0.1005], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0996], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0989], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0982], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0976], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0970], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0964], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0959], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0954], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0949], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0945], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0940], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0936], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0932], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0928], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0925], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0921], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0918], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0915], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0911], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0908], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0905], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0903], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0900], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0897], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0894], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0892], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0889], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0887], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0884], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0882], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0880], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0877], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0875], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0873], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0871], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0868], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0866], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0864], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0862], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0860], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0858], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0856], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0854], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0852], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0850], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0848], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0846], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0844], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0842], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0840], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0838], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0836], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0835], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0833], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0831], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0829], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0827], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0825], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0823], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0822], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0820], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0818], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0816], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0814], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0813], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0811], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0809], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0807], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0806], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0804], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0802], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0800], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0798], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0797], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0795], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0793], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0792], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0790], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0788], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0786], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0785], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0783], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0781], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0779], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0778], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0776], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0774], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0773], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0771], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0769], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0768], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0766], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0764], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0763], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0761], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0759], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0758], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0756], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0754], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0753], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0751], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0749], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0748], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0746], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0744], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0743], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0741], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0739], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0738], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0736], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0735], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0733], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0731], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0730], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0728], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0727], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0725], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0723], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0722], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0720], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0719], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0717], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0715], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0714], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0712], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0711], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0709], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0707], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0706], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0704], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0703], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0701], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0700], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0698], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0697], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0695], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0693], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0692], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0690], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0689], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0687], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0686], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0684], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0683], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0681], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0680], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0678], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0677], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0675], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0674], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0672], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0671], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0669], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0668], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0666], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0665], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0663], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0662], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0660], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0659], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0657], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0656], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0654], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0653], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0651], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0650], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0648], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0647], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0645], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0644], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0643], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0641], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0640], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0638], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0637], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0635], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0634], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0632], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0631], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0630], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0628], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0627], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0625], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0624], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0623], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0621], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0620], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0618], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0617], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0615], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0614], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0613], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0611], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0610], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0609], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0607], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0606], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0604], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0603], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0602], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0600], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0599], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0597], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0596], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0595], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0593], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0592], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0591], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0589], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0588], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0587], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0585], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0584], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0583], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0581], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0580], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0579], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0577], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0576], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0575], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0573], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0572], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0571], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0569], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0568], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0567], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0565], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0564], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0563], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0561], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0560], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0559], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0558], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0556], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0555], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0554], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0552], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0551], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0550], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0549], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0547], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0546], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0545], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0543], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0542], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0541], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0540], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0538], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0537], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0536], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0535], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0533], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0532], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0531], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0530], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0528], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0527], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0526], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0525], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0523], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0522], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0521], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0520], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0518], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0517], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0516], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0515], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0514], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0512], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0511], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0510], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0509], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0508], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0506], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0505], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0504], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0503], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0502], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0500], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0499], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0498], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0497], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0496], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0494], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0493], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0492], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0491], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0490], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0489], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0487], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0486], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0485], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0484], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0483], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0482], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0480], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0479], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0478], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0477], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0476], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0475], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0474], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0472], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0471], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0470], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0469], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0468], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0467], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0466], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0464], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0463], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0462], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0461], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0460], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0459], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0458], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0457], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0455], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0454], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0453], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0452], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0451], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0450], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0449], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0448], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0447], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0446], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0444], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0443], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0442], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0441], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0440], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0439], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0438], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0437], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0436], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0435], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0434], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0433], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0432], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0430], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0429], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0428], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0427], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0426], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0425], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0424], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0423], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0422], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0421], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0420], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0419], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0418], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0417], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0416], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0415], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0414], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0413], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0412], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0411], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0410], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0409], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0408], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0407], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0405], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0404], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0403], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0402], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0401], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0400], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0399], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0398], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0397], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0396], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0395], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0394], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0393], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0392], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0391], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0390], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0389], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0388], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0387], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0386], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0385], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0384], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0384], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0383], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0382], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0381], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0380], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0379], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0378], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0377], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0376], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0375], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0374], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0373], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0372], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0371], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0370], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0369], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0368], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0367], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0366], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0365], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0364], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0363], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0362], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0361], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0361], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0360], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0359], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0358], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0357], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0356], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0355], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0354], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0353], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0352], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0351], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0350], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0349], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0348], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0348], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0347], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0346], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0345], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0344], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0343], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0342], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0341], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0340], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0339], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0339], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0338], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0337], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0336], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0335], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0334], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0333], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0332], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0331], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0331], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0330], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0329], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0328], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0327], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0326], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0325], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0324], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0324], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0323], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0322], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0321], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0320], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0319], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0318], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0317], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0317], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0316], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0315], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0314], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0313], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0312], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0311], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0311], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0310], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0309], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0308], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0307], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0306], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0306], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0305], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0304], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0303], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0302], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0301], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0301], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0300], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0299], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0298], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0297], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0296], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0296], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0295], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0294], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0293], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0292], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0292], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0291], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0290], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0289], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0288], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0288], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0287], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0286], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0285], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0284], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0284], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0283], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0282], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0281], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0280], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0280], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0279], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0278], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0277], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0276], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0276], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0275], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0274], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0273], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0273], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0272], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0271], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0270], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0269], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0269], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0268], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0267], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0266], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0266], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0265], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0264], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0263], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0263], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0262], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0261], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0260], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0259], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0259], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0258], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0257], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0256], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0256], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0255], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0254], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0254], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0253], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0252], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0251], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0251], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0250], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0249], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0248], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0248], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0247], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0246], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0245], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0245], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0244], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0243], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0243], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0242], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0241], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0240], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0240], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0239], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0238], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0237], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0237], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0236], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0235], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0235], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0234], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0233], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0233], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0232], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0231], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0230], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0230], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0229], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0228], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0228], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0227], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0226], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0226], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0225], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0224], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0223], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0223], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0222], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0221], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0221], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0220], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0219], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0219], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0218], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0217], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0217], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0216], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0215], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0215], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0214], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0213], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0213], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0212], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0211], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0211], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0210], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0209], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0209], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0208], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0207], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0207], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0206], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0205], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0205], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0204], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0203], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0203], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0202], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0201], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0201], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0200], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0199], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0199], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0198], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0198], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0197], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0196], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0196], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0195], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0194], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0194], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0193], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0192], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0192], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0191], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0191], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0190], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0189], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0189], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0188], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0187], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0187], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0186], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0186], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0185], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0184], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0184], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0183], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0182], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0182], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0181], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0181], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0180], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0179], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0179], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0178], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0178], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0177], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0176], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0176], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0175], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0175], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0174], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0173], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0173], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0172], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0172], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0171], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0170], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0170], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0169], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0169], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0168], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0167], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0167], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0166], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0166], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0165], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0165], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0164], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0163], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0163], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0162], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0162], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0161], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0161], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0160], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0159], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0159], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0158], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0158], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0157], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0157], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0156], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0155], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0155], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0154], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0154], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0153], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0153], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0152], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0151], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0151], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0150], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0150], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0149], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0149], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0148], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0148], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0147], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0146], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0146], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0145], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0145], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0144], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0144], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0143], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0143], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0142], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0142], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0141], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0141], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0140], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0139], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0139], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0138], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0138], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0137], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0137], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0136], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0136], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0135], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0135], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0134], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0134], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0133], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0133], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0132], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0131], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0131], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0130], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0130], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0129], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0129], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0103], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0103], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0100], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0100], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0098], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0098], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0097], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0097], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0096], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0096], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0095], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0095], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0093], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0093], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0092], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0092], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0091], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0091], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0090], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0090], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0089], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0089], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0089], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0088], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0088], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0087], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0087], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0086], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0086], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0086], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0085], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0085], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0084], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0084], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0083], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0083], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0082], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0082], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0082], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0081], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0081], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0080], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0080], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0079], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0079], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0079], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0078], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0078], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0077], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0077], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0076], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0076], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0076], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0075], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0075], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0074], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0074], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0074], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0073], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0073], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0072], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0072], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0071], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0071], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0071], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0070], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0070], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0069], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0069], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0069], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0068], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0068], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0067], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0067], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0067], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0066], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0066], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0065], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0065], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0065], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0064], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0064], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0063], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0063], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0063], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0062], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0062], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0061], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0061], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0061], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0060], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0060], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0059], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0059], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0059], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0058], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0058], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0057], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0057], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0057], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0056], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0056], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0055], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0055], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0055], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0054], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0054], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0054], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0053], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0053], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0052], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0052], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0052], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0051], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0051], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0051], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0050], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0050], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0049], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0049], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0049], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0048], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0048], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0048], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0047], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0047], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0046], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0046], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0046], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0045], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0045], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0045], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0044], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0044], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0044], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0043], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0043], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0042], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0042], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0042], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0041], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0041], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0041], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0040], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0040], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0040], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0039], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0039], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0039], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0038], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0038], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0037], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0037], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0037], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0036], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0036], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0036], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0035], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0035], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0035], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0034], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0034], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0034], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0033], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0033], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0033], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0032], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0032], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0032], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0031], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0031], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0031], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0030], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0030], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0030], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0029], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0029], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0029], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0028], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0028], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0028], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0027], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0027], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0027], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0026], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0026], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0026], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0025], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0025], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0025], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0024], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0024], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0024], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0023], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0023], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0023], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0022], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0022], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0022], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0021], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0021], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0021], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0020], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0020], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0020], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0019], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0019], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0019], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0018], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0018], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0018], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0017], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0017], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0017], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0016], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0016], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0016], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0016], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0015], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0015], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0015], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0013], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0013], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0013], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0012], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0012], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0012], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0012], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0011], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0011], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0011], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0010], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0010], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0010], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0009], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0009], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0009], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0008], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0008], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0008], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0008], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0007], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0007], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0007], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0006], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0006], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0006], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0006], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0005], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0005], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0005], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0004], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0004], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0004], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0003], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0003], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0003], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0003], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0002], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0002], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0002], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0001], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0001], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([8.7078e-05], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([5.8470e-05], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([2.9913e-05], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([1.4082e-06], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-2.7046e-05], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-5.5449e-05], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-8.3801e-05], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0001], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0001], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0002], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0002], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0002], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0003], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0003], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0003], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0003], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0004], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0004], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0004], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0004], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0005], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0005], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0005], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0006], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0006], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0006], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0006], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0007], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0007], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0007], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0007], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0008], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0008], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0008], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0009], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0009], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0009], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0009], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0010], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0010], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0010], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0010], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0011], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0011], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0011], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0012], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0012], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0012], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0012], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0013], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0013], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0013], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0013], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0014], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0014], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0014], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0014], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0015], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0015], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0015], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0015], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0016], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0016], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0016], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0016], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0017], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0017], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0017], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0017], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0018], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0018], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0018], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0018], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0019], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0019], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0019], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0019], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0020], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0020], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0020], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0020], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0021], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0021], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0021], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0021], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0022], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0022], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0022], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0022], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0023], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0023], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0023], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0023], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0024], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0024], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0024], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0024], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0025], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0025], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0025], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0025], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0026], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0026], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0026], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0026], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0027], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0027], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0027], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0027], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0027], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0028], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0028], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0028], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0028], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0029], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0029], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0029], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0029], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0030], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0030], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0030], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0030], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0030], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0031], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0031], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0031], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0031], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0032], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0032], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0032], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0032], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0033], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0033], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0033], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0033], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0033], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0034], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0034], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0034], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0034], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0035], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0035], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0035], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0035], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0035], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0036], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0036], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0036], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0036], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0037], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0037], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0037], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0037], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0037], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0038], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0038], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0038], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0038], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0039], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0039], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0039], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0039], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0039], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0040], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0040], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0040], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0040], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0040], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0041], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0041], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0041], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0041], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0041], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0042], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0042], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0042], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0042], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0043], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0043], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0043], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0043], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0043], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0044], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0044], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0044], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0044], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0044], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0045], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0045], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0045], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0045], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0045], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0046], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0046], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0046], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0046], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0046], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0047], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0047], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0047], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0047], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0047], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0048], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0048], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0048], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0048], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0048], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0049], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0049], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0049], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0049], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0049], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0050], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0050], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0050], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0050], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0050], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0051], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0051], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0051], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0051], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0051], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0052], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0052], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0052], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0052], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0052], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0053], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0053], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0053], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0053], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0053], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0053], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0054], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0054], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0054], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0054], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0054], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0055], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0055], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0055], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0055], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0055], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0056], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0056], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0056], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0056], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0056], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0056], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0057], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0057], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0057], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0057], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0057], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0058], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0058], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0058], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0058], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0058], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0058], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0059], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0059], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0059], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0059], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0059], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0060], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0060], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0060], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0060], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0060], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0060], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0061], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0061], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0061], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0061], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0061], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0061], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0062], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0062], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0062], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0062], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0062], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0062], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0063], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0063], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0063], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0063], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0063], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0064], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0064], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0064], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0064], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0064], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0064], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0065], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0065], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0065], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0065], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0065], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0065], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0066], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0066], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0066], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0066], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0066], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0066], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0067], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0067], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0067], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0067], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0067], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0067], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0068], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0068], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0068], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0068], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0068], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0068], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0069], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0069], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0069], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0069], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0069], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0069], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0069], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0070], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0070], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0070], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0070], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0070], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0070], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0071], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0071], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0071], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0071], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0071], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0071], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0072], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0072], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0072], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0072], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0072], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0072], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0072], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0073], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0073], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0073], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0073], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0073], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0073], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0074], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0074], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0074], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0074], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0074], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0074], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0074], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0075], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0075], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0075], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0075], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0075], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0075], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0076], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0076], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0076], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0076], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0076], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0076], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0076], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0077], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0077], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0077], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0077], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0077], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0077], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0077], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0078], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0078], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0078], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0078], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0078], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0078], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0078], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0079], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0079], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0079], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0079], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0079], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0079], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0079], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0080], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0080], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0080], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0080], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0080], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0080], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0080], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0081], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0081], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0081], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0081], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0081], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0081], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0081], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0082], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0082], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0082], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0082], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0082], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0082], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0082], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0083], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0083], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0083], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0083], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0083], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0083], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0083], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0083], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0084], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0084], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0084], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0084], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0084], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0084], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0084], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0085], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0085], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0085], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0085], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0085], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0085], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0085], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0085], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0086], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0086], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0086], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0086], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0086], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0086], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0086], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0087], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0087], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0087], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0087], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0087], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0087], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0087], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0087], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0088], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0088], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0088], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0088], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0088], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0088], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0088], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0088], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0089], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0089], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0089], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0089], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0089], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0089], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0089], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0089], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0090], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0090], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0090], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0090], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0090], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0090], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0090], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0090], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0091], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0091], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0091], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0091], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0091], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0091], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0091], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0091], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0092], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0092], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0092], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0092], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0092], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0092], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0092], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0092], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0092], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0093], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0093], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0093], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0093], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0093], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0093], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0093], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0093], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0094], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0095], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0095], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0095], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0095], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0095], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0095], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0095], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0095], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0096], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0096], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0096], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0096], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0096], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0096], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0096], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0096], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0096], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0097], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0097], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0097], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0097], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0097], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0097], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0097], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0097], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0097], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0098], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0098], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0098], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0098], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0098], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0098], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0098], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0098], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0098], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0099], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0100], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0100], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0100], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0100], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0100], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0100], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0100], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0100], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0100], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0101], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0102], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0103], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0103], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0103], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0103], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0103], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0103], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0103], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0103], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0103], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0104], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0106], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0107], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0108], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0109], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0110], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0111], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0112], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0113], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0114], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0115], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0116], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0118], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0119], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0120], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0121], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0122], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0123], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0125], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0126], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0127], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0128], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0129], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0129], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0129], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0129], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0129], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0129], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0129], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0129], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GmiSG4AjzOW",
        "outputId": "fa291565-cf04-481f-ba0a-5801fe0a6b14"
      },
      "source": [
        "\n",
        "def generate_data(n=2000):\n",
        "    x = np.random.uniform(-math.pi,math.pi, n)\n",
        "    noise = np.random.normal(0, 0.15, n)\n",
        "    y = np.sin(x) + noise\n",
        "    return x.astype(np.float32), y.astype(np.float32)\n",
        "\n",
        "x, y = generate_data()\n",
        "\n",
        "x = torch.from_numpy(x.reshape(-1, 1))\n",
        "y = torch.from_numpy(y.reshape(-1, 1))\n",
        "\n",
        "\n",
        "def squared_error(y_pred, y_true):\n",
        "    return torch.mean(torch.square(y_pred - y_true))\n",
        "\n",
        "\n",
        "torch_model = LinearRegressionPyTorch()\n",
        "[w3, w2, w1, b] =  torch_model.parameters()\n",
        "\n",
        "learning_rate = 0.002\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(2000):\n",
        "    y_pred = torch_model(x)\n",
        "    loss = squared_error(y_pred, y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        w1 -= w1.grad * learning_rate\n",
        "        w2 -= w2.grad * learning_rate\n",
        "        w3 -= w3.grad * learning_rate\n",
        "        b -= b.grad * learning_rate\n",
        "        w1.grad.zero_()\n",
        "        w2.grad.zero_()\n",
        "        w3.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "\n",
        "    print(f\"Epoch {epoch} : Loss {loss.data}\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 : Loss 119.58746337890625\n",
            "Epoch 1 : Loss 37.74802780151367\n",
            "Epoch 2 : Loss 17.943822860717773\n",
            "Epoch 3 : Loss 12.152372360229492\n",
            "Epoch 4 : Loss 9.676018714904785\n",
            "Epoch 5 : Loss 8.109704971313477\n",
            "Epoch 6 : Loss 6.8940019607543945\n",
            "Epoch 7 : Loss 5.882986068725586\n",
            "Epoch 8 : Loss 5.025717258453369\n",
            "Epoch 9 : Loss 4.295061111450195\n",
            "Epoch 10 : Loss 3.6714775562286377\n",
            "Epoch 11 : Loss 3.1390886306762695\n",
            "Epoch 12 : Loss 2.684516668319702\n",
            "Epoch 13 : Loss 2.2963781356811523\n",
            "Epoch 14 : Loss 1.9649615287780762\n",
            "Epoch 15 : Loss 1.6819778680801392\n",
            "Epoch 16 : Loss 1.4403491020202637\n",
            "Epoch 17 : Loss 1.2340307235717773\n",
            "Epoch 18 : Loss 1.0578628778457642\n",
            "Epoch 19 : Loss 0.9074399471282959\n",
            "Epoch 20 : Loss 0.778998851776123\n",
            "Epoch 21 : Loss 0.6693279147148132\n",
            "Epoch 22 : Loss 0.5756833553314209\n",
            "Epoch 23 : Loss 0.4957236349582672\n",
            "Epoch 24 : Loss 0.42744845151901245\n",
            "Epoch 25 : Loss 0.36915063858032227\n",
            "Epoch 26 : Loss 0.3193718194961548\n",
            "Epoch 27 : Loss 0.27686718106269836\n",
            "Epoch 28 : Loss 0.2405737191438675\n",
            "Epoch 29 : Loss 0.209583580493927\n",
            "Epoch 30 : Loss 0.18312188982963562\n",
            "Epoch 31 : Loss 0.1605267971754074\n",
            "Epoch 32 : Loss 0.14123325049877167\n",
            "Epoch 33 : Loss 0.1247587576508522\n",
            "Epoch 34 : Loss 0.11069141328334808\n",
            "Epoch 35 : Loss 0.09867937117815018\n",
            "Epoch 36 : Loss 0.0884222760796547\n",
            "Epoch 37 : Loss 0.07966369390487671\n",
            "Epoch 38 : Loss 0.07218464463949203\n",
            "Epoch 39 : Loss 0.06579811125993729\n",
            "Epoch 40 : Loss 0.06034444272518158\n",
            "Epoch 41 : Loss 0.055687315762043\n",
            "Epoch 42 : Loss 0.0517103411257267\n",
            "Epoch 43 : Loss 0.04831409081816673\n",
            "Epoch 44 : Loss 0.045413725078105927\n",
            "Epoch 45 : Loss 0.04293676093220711\n",
            "Epoch 46 : Loss 0.040821343660354614\n",
            "Epoch 47 : Loss 0.03901462256908417\n",
            "Epoch 48 : Loss 0.03747148811817169\n",
            "Epoch 49 : Loss 0.03615343198180199\n",
            "Epoch 50 : Loss 0.03502755984663963\n",
            "Epoch 51 : Loss 0.03406578302383423\n",
            "Epoch 52 : Loss 0.03324412554502487\n",
            "Epoch 53 : Loss 0.03254210203886032\n",
            "Epoch 54 : Loss 0.03194224834442139\n",
            "Epoch 55 : Loss 0.03142962604761124\n",
            "Epoch 56 : Loss 0.030991489067673683\n",
            "Epoch 57 : Loss 0.03061695396900177\n",
            "Epoch 58 : Loss 0.030296726152300835\n",
            "Epoch 59 : Loss 0.030022872611880302\n",
            "Epoch 60 : Loss 0.02978861704468727\n",
            "Epoch 61 : Loss 0.02958817221224308\n",
            "Epoch 62 : Loss 0.029416603967547417\n",
            "Epoch 63 : Loss 0.029269689694046974\n",
            "Epoch 64 : Loss 0.02914382517337799\n",
            "Epoch 65 : Loss 0.029035944491624832\n",
            "Epoch 66 : Loss 0.028943410143256187\n",
            "Epoch 67 : Loss 0.028863990679383278\n",
            "Epoch 68 : Loss 0.028795765712857246\n",
            "Epoch 69 : Loss 0.028737101703882217\n",
            "Epoch 70 : Loss 0.028686601668596268\n",
            "Epoch 71 : Loss 0.02864307537674904\n",
            "Epoch 72 : Loss 0.028605511412024498\n",
            "Epoch 73 : Loss 0.02857302315533161\n",
            "Epoch 74 : Loss 0.02854488603770733\n",
            "Epoch 75 : Loss 0.028520459309220314\n",
            "Epoch 76 : Loss 0.028499208390712738\n",
            "Epoch 77 : Loss 0.028480660170316696\n",
            "Epoch 78 : Loss 0.028464425355196\n",
            "Epoch 79 : Loss 0.028450170531868935\n",
            "Epoch 80 : Loss 0.028437603265047073\n",
            "Epoch 81 : Loss 0.028426479548215866\n",
            "Epoch 82 : Loss 0.028416596353054047\n",
            "Epoch 83 : Loss 0.028407763689756393\n",
            "Epoch 84 : Loss 0.028399834409356117\n",
            "Epoch 85 : Loss 0.02839267998933792\n",
            "Epoch 86 : Loss 0.028386183083057404\n",
            "Epoch 87 : Loss 0.028380250558257103\n",
            "Epoch 88 : Loss 0.0283748060464859\n",
            "Epoch 89 : Loss 0.028369775041937828\n",
            "Epoch 90 : Loss 0.02836509793996811\n",
            "Epoch 91 : Loss 0.028360730037093163\n",
            "Epoch 92 : Loss 0.02835661731660366\n",
            "Epoch 93 : Loss 0.028352735564112663\n",
            "Epoch 94 : Loss 0.02834904007613659\n",
            "Epoch 95 : Loss 0.028345519676804543\n",
            "Epoch 96 : Loss 0.02834213897585869\n",
            "Epoch 97 : Loss 0.028338881209492683\n",
            "Epoch 98 : Loss 0.028335729613900185\n",
            "Epoch 99 : Loss 0.028332673013210297\n",
            "Epoch 100 : Loss 0.028329694643616676\n",
            "Epoch 101 : Loss 0.028326787054538727\n",
            "Epoch 102 : Loss 0.028323940932750702\n",
            "Epoch 103 : Loss 0.028321148827672005\n",
            "Epoch 104 : Loss 0.02831840328872204\n",
            "Epoch 105 : Loss 0.028315698727965355\n",
            "Epoch 106 : Loss 0.028313031420111656\n",
            "Epoch 107 : Loss 0.028310393914580345\n",
            "Epoch 108 : Loss 0.02830778807401657\n",
            "Epoch 109 : Loss 0.028305210173130035\n",
            "Epoch 110 : Loss 0.02830265276134014\n",
            "Epoch 111 : Loss 0.02830011583864689\n",
            "Epoch 112 : Loss 0.028297599405050278\n",
            "Epoch 113 : Loss 0.02829510159790516\n",
            "Epoch 114 : Loss 0.028292622417211533\n",
            "Epoch 115 : Loss 0.0282901581376791\n",
            "Epoch 116 : Loss 0.028287701308727264\n",
            "Epoch 117 : Loss 0.02828526310622692\n",
            "Epoch 118 : Loss 0.02828283980488777\n",
            "Epoch 119 : Loss 0.02828042395412922\n",
            "Epoch 120 : Loss 0.02827802300453186\n",
            "Epoch 121 : Loss 0.028275633230805397\n",
            "Epoch 122 : Loss 0.02827325090765953\n",
            "Epoch 123 : Loss 0.02827088162302971\n",
            "Epoch 124 : Loss 0.028268523514270782\n",
            "Epoch 125 : Loss 0.028266174718737602\n",
            "Epoch 126 : Loss 0.02826383151113987\n",
            "Epoch 127 : Loss 0.028261501342058182\n",
            "Epoch 128 : Loss 0.02825917676091194\n",
            "Epoch 129 : Loss 0.028256863355636597\n",
            "Epoch 130 : Loss 0.028254559263586998\n",
            "Epoch 131 : Loss 0.028252266347408295\n",
            "Epoch 132 : Loss 0.02824997715651989\n",
            "Epoch 133 : Loss 0.02824769727885723\n",
            "Epoch 134 : Loss 0.028245430439710617\n",
            "Epoch 135 : Loss 0.0282431673258543\n",
            "Epoch 136 : Loss 0.028240913525223732\n",
            "Epoch 137 : Loss 0.02823866717517376\n",
            "Epoch 138 : Loss 0.028236432000994682\n",
            "Epoch 139 : Loss 0.028234200552105904\n",
            "Epoch 140 : Loss 0.02823198214173317\n",
            "Epoch 141 : Loss 0.028229769319295883\n",
            "Epoch 142 : Loss 0.028227562084794044\n",
            "Epoch 143 : Loss 0.028225364163517952\n",
            "Epoch 144 : Loss 0.028223177418112755\n",
            "Epoch 145 : Loss 0.028220996260643005\n",
            "Epoch 146 : Loss 0.028218822553753853\n",
            "Epoch 147 : Loss 0.028216656297445297\n",
            "Epoch 148 : Loss 0.028214501217007637\n",
            "Epoch 149 : Loss 0.028212346136569977\n",
            "Epoch 150 : Loss 0.02821020968258381\n",
            "Epoch 151 : Loss 0.028208071365952492\n",
            "Epoch 152 : Loss 0.02820594608783722\n",
            "Epoch 153 : Loss 0.028203824535012245\n",
            "Epoch 154 : Loss 0.028201714158058167\n",
            "Epoch 155 : Loss 0.028199607506394386\n",
            "Epoch 156 : Loss 0.0281975120306015\n",
            "Epoch 157 : Loss 0.028195422142744064\n",
            "Epoch 158 : Loss 0.028193337842822075\n",
            "Epoch 159 : Loss 0.02819126471877098\n",
            "Epoch 160 : Loss 0.028189199045300484\n",
            "Epoch 161 : Loss 0.028187138959765434\n",
            "Epoch 162 : Loss 0.028185084462165833\n",
            "Epoch 163 : Loss 0.028183043003082275\n",
            "Epoch 164 : Loss 0.028181001543998718\n",
            "Epoch 165 : Loss 0.028178973123431206\n",
            "Epoch 166 : Loss 0.02817695029079914\n",
            "Epoch 167 : Loss 0.028174931183457375\n",
            "Epoch 168 : Loss 0.028172923251986504\n",
            "Epoch 169 : Loss 0.02817092090845108\n",
            "Epoch 170 : Loss 0.028168927878141403\n",
            "Epoch 171 : Loss 0.028166938573122025\n",
            "Epoch 172 : Loss 0.028164958581328392\n",
            "Epoch 173 : Loss 0.028162984177470207\n",
            "Epoch 174 : Loss 0.02816101908683777\n",
            "Epoch 175 : Loss 0.028159059584140778\n",
            "Epoch 176 : Loss 0.028157103806734085\n",
            "Epoch 177 : Loss 0.028155159205198288\n",
            "Epoch 178 : Loss 0.028153223916888237\n",
            "Epoch 179 : Loss 0.028151288628578186\n",
            "Epoch 180 : Loss 0.02814936451613903\n",
            "Epoch 181 : Loss 0.028147447854280472\n",
            "Epoch 182 : Loss 0.02814553864300251\n",
            "Epoch 183 : Loss 0.028143631294369698\n",
            "Epoch 184 : Loss 0.02814173325896263\n",
            "Epoch 185 : Loss 0.028139842674136162\n",
            "Epoch 186 : Loss 0.02813795767724514\n",
            "Epoch 187 : Loss 0.028136081993579865\n",
            "Epoch 188 : Loss 0.028134208172559738\n",
            "Epoch 189 : Loss 0.028132349252700806\n",
            "Epoch 190 : Loss 0.02813049405813217\n",
            "Epoch 191 : Loss 0.028128638863563538\n",
            "Epoch 192 : Loss 0.0281267948448658\n",
            "Epoch 193 : Loss 0.028124958276748657\n",
            "Epoch 194 : Loss 0.028123125433921814\n",
            "Epoch 195 : Loss 0.028121300041675568\n",
            "Epoch 196 : Loss 0.028119482100009918\n",
            "Epoch 197 : Loss 0.028117671608924866\n",
            "Epoch 198 : Loss 0.02811586670577526\n",
            "Epoch 199 : Loss 0.028114067390561104\n",
            "Epoch 200 : Loss 0.028112275525927544\n",
            "Epoch 201 : Loss 0.02811048924922943\n",
            "Epoch 202 : Loss 0.028108706697821617\n",
            "Epoch 203 : Loss 0.028106937184929848\n",
            "Epoch 204 : Loss 0.028105169534683228\n",
            "Epoch 205 : Loss 0.028103409335017204\n",
            "Epoch 206 : Loss 0.02810165472328663\n",
            "Epoch 207 : Loss 0.0280999094247818\n",
            "Epoch 208 : Loss 0.02809816598892212\n",
            "Epoch 209 : Loss 0.028096430003643036\n",
            "Epoch 210 : Loss 0.0280946996062994\n",
            "Epoch 211 : Loss 0.028092974796891212\n",
            "Epoch 212 : Loss 0.02809125930070877\n",
            "Epoch 213 : Loss 0.028089547529816628\n",
            "Epoch 214 : Loss 0.02808784320950508\n",
            "Epoch 215 : Loss 0.028086142614483833\n",
            "Epoch 216 : Loss 0.02808445133268833\n",
            "Epoch 217 : Loss 0.02808276377618313\n",
            "Epoch 218 : Loss 0.028081083670258522\n",
            "Epoch 219 : Loss 0.028079411014914513\n",
            "Epoch 220 : Loss 0.02807774394750595\n",
            "Epoch 221 : Loss 0.02807607874274254\n",
            "Epoch 222 : Loss 0.028074420988559723\n",
            "Epoch 223 : Loss 0.028072768822312355\n",
            "Epoch 224 : Loss 0.028071124106645584\n",
            "Epoch 225 : Loss 0.02806948497891426\n",
            "Epoch 226 : Loss 0.028067851439118385\n",
            "Epoch 227 : Loss 0.028066223487257957\n",
            "Epoch 228 : Loss 0.028064601123332977\n",
            "Epoch 229 : Loss 0.028062986209988594\n",
            "Epoch 230 : Loss 0.02806137502193451\n",
            "Epoch 231 : Loss 0.028059769421815872\n",
            "Epoch 232 : Loss 0.028058167546987534\n",
            "Epoch 233 : Loss 0.02805657498538494\n",
            "Epoch 234 : Loss 0.028054989874362946\n",
            "Epoch 235 : Loss 0.02805340848863125\n",
            "Epoch 236 : Loss 0.028051832690835\n",
            "Epoch 237 : Loss 0.028050262480974197\n",
            "Epoch 238 : Loss 0.028048694133758545\n",
            "Epoch 239 : Loss 0.028047138825058937\n",
            "Epoch 240 : Loss 0.02804558165371418\n",
            "Epoch 241 : Loss 0.02804403379559517\n",
            "Epoch 242 : Loss 0.028042491525411606\n",
            "Epoch 243 : Loss 0.02804095484316349\n",
            "Epoch 244 : Loss 0.028039423748850822\n",
            "Epoch 245 : Loss 0.028037894517183304\n",
            "Epoch 246 : Loss 0.028036372736096382\n",
            "Epoch 247 : Loss 0.028034858405590057\n",
            "Epoch 248 : Loss 0.02803334780037403\n",
            "Epoch 249 : Loss 0.028031840920448303\n",
            "Epoch 250 : Loss 0.028030341491103172\n",
            "Epoch 251 : Loss 0.028028851374983788\n",
            "Epoch 252 : Loss 0.028027363121509552\n",
            "Epoch 253 : Loss 0.028025876730680466\n",
            "Epoch 254 : Loss 0.028024399653077126\n",
            "Epoch 255 : Loss 0.028022926300764084\n",
            "Epoch 256 : Loss 0.02802146039903164\n",
            "Epoch 257 : Loss 0.028019994497299194\n",
            "Epoch 258 : Loss 0.028018536046147346\n",
            "Epoch 259 : Loss 0.028017086908221245\n",
            "Epoch 260 : Loss 0.028015635907649994\n",
            "Epoch 261 : Loss 0.02801419608294964\n",
            "Epoch 262 : Loss 0.02801275998353958\n",
            "Epoch 263 : Loss 0.028011327609419823\n",
            "Epoch 264 : Loss 0.028009900823235512\n",
            "Epoch 265 : Loss 0.02800847962498665\n",
            "Epoch 266 : Loss 0.028007064014673233\n",
            "Epoch 267 : Loss 0.028005653992295265\n",
            "Epoch 268 : Loss 0.028004245832562447\n",
            "Epoch 269 : Loss 0.028002841398119926\n",
            "Epoch 270 : Loss 0.02800145000219345\n",
            "Epoch 271 : Loss 0.028000056743621826\n",
            "Epoch 272 : Loss 0.02799866907298565\n",
            "Epoch 273 : Loss 0.02799728699028492\n",
            "Epoch 274 : Loss 0.027995912358164787\n",
            "Epoch 275 : Loss 0.027994541451334953\n",
            "Epoch 276 : Loss 0.027993177995085716\n",
            "Epoch 277 : Loss 0.02799181453883648\n",
            "Epoch 278 : Loss 0.02799045480787754\n",
            "Epoch 279 : Loss 0.0279891025274992\n",
            "Epoch 280 : Loss 0.027987759560346603\n",
            "Epoch 281 : Loss 0.02798641286790371\n",
            "Epoch 282 : Loss 0.02798507548868656\n",
            "Epoch 283 : Loss 0.02798374369740486\n",
            "Epoch 284 : Loss 0.02798241376876831\n",
            "Epoch 285 : Loss 0.027981091290712357\n",
            "Epoch 286 : Loss 0.027979770675301552\n",
            "Epoch 287 : Loss 0.027978455647826195\n",
            "Epoch 288 : Loss 0.027977146208286285\n",
            "Epoch 289 : Loss 0.027975842356681824\n",
            "Epoch 290 : Loss 0.02797454223036766\n",
            "Epoch 291 : Loss 0.027973247691988945\n",
            "Epoch 292 : Loss 0.02797195501625538\n",
            "Epoch 293 : Loss 0.027970673516392708\n",
            "Epoch 294 : Loss 0.02796938642859459\n",
            "Epoch 295 : Loss 0.027968112379312515\n",
            "Epoch 296 : Loss 0.02796683833003044\n",
            "Epoch 297 : Loss 0.027965568006038666\n",
            "Epoch 298 : Loss 0.027964305132627487\n",
            "Epoch 299 : Loss 0.027963049709796906\n",
            "Epoch 300 : Loss 0.027961794286966324\n",
            "Epoch 301 : Loss 0.02796054258942604\n",
            "Epoch 302 : Loss 0.027959296479821205\n",
            "Epoch 303 : Loss 0.027958057820796967\n",
            "Epoch 304 : Loss 0.027956821024417877\n",
            "Epoch 305 : Loss 0.027955587953329086\n",
            "Epoch 306 : Loss 0.027954358607530594\n",
            "Epoch 307 : Loss 0.0279531367123127\n",
            "Epoch 308 : Loss 0.027951914817094803\n",
            "Epoch 309 : Loss 0.027950700372457504\n",
            "Epoch 310 : Loss 0.027949493378400803\n",
            "Epoch 311 : Loss 0.027948280796408653\n",
            "Epoch 312 : Loss 0.027947083115577698\n",
            "Epoch 313 : Loss 0.027945881709456444\n",
            "Epoch 314 : Loss 0.027944691479206085\n",
            "Epoch 315 : Loss 0.027943503111600876\n",
            "Epoch 316 : Loss 0.027942316606640816\n",
            "Epoch 317 : Loss 0.027941133826971054\n",
            "Epoch 318 : Loss 0.02793995849788189\n",
            "Epoch 319 : Loss 0.027938785031437874\n",
            "Epoch 320 : Loss 0.027937617152929306\n",
            "Epoch 321 : Loss 0.027936452999711037\n",
            "Epoch 322 : Loss 0.027935290709137917\n",
            "Epoch 323 : Loss 0.027934139594435692\n",
            "Epoch 324 : Loss 0.02793298475444317\n",
            "Epoch 325 : Loss 0.027931837365031242\n",
            "Epoch 326 : Loss 0.027930691838264465\n",
            "Epoch 327 : Loss 0.027929555624723434\n",
            "Epoch 328 : Loss 0.027928417548537254\n",
            "Epoch 329 : Loss 0.02792728878557682\n",
            "Epoch 330 : Loss 0.027926161885261536\n",
            "Epoch 331 : Loss 0.0279250368475914\n",
            "Epoch 332 : Loss 0.02792391926050186\n",
            "Epoch 333 : Loss 0.027922803536057472\n",
            "Epoch 334 : Loss 0.027921689674258232\n",
            "Epoch 335 : Loss 0.02792058140039444\n",
            "Epoch 336 : Loss 0.027919480577111244\n",
            "Epoch 337 : Loss 0.027918381616473198\n",
            "Epoch 338 : Loss 0.02791728638112545\n",
            "Epoch 339 : Loss 0.027916191145777702\n",
            "Epoch 340 : Loss 0.02791510336101055\n",
            "Epoch 341 : Loss 0.0279140193015337\n",
            "Epoch 342 : Loss 0.027912940829992294\n",
            "Epoch 343 : Loss 0.02791186422109604\n",
            "Epoch 344 : Loss 0.027910791337490082\n",
            "Epoch 345 : Loss 0.027909724041819572\n",
            "Epoch 346 : Loss 0.027908658608794212\n",
            "Epoch 347 : Loss 0.02790759690105915\n",
            "Epoch 348 : Loss 0.027906540781259537\n",
            "Epoch 349 : Loss 0.027905486524105072\n",
            "Epoch 350 : Loss 0.027904437854886055\n",
            "Epoch 351 : Loss 0.027903391048312187\n",
            "Epoch 352 : Loss 0.027902347967028618\n",
            "Epoch 353 : Loss 0.027901310473680496\n",
            "Epoch 354 : Loss 0.027900274842977524\n",
            "Epoch 355 : Loss 0.02789924480021\n",
            "Epoch 356 : Loss 0.027898218482732773\n",
            "Epoch 357 : Loss 0.027897194027900696\n",
            "Epoch 358 : Loss 0.027896171435713768\n",
            "Epoch 359 : Loss 0.027895156294107437\n",
            "Epoch 360 : Loss 0.027894143015146255\n",
            "Epoch 361 : Loss 0.02789313532412052\n",
            "Epoch 362 : Loss 0.027892127633094788\n",
            "Epoch 363 : Loss 0.0278911255300045\n",
            "Epoch 364 : Loss 0.027890127152204514\n",
            "Epoch 365 : Loss 0.027889128774404526\n",
            "Epoch 366 : Loss 0.027888139709830284\n",
            "Epoch 367 : Loss 0.027887150645256042\n",
            "Epoch 368 : Loss 0.0278861653059721\n",
            "Epoch 369 : Loss 0.027885187417268753\n",
            "Epoch 370 : Loss 0.027884209528565407\n",
            "Epoch 371 : Loss 0.02788323350250721\n",
            "Epoch 372 : Loss 0.02788226306438446\n",
            "Epoch 373 : Loss 0.02788129821419716\n",
            "Epoch 374 : Loss 0.027880333364009857\n",
            "Epoch 375 : Loss 0.027879375964403152\n",
            "Epoch 376 : Loss 0.0278784167021513\n",
            "Epoch 377 : Loss 0.027877461165189743\n",
            "Epoch 378 : Loss 0.027876514941453934\n",
            "Epoch 379 : Loss 0.027875564992427826\n",
            "Epoch 380 : Loss 0.027874622493982315\n",
            "Epoch 381 : Loss 0.027873683720827103\n",
            "Epoch 382 : Loss 0.02787274681031704\n",
            "Epoch 383 : Loss 0.027871813625097275\n",
            "Epoch 384 : Loss 0.02787088416516781\n",
            "Epoch 385 : Loss 0.02786995843052864\n",
            "Epoch 386 : Loss 0.027869034558534622\n",
            "Epoch 387 : Loss 0.027868112549185753\n",
            "Epoch 388 : Loss 0.02786719612777233\n",
            "Epoch 389 : Loss 0.027866283431649208\n",
            "Epoch 390 : Loss 0.027865374460816383\n",
            "Epoch 391 : Loss 0.02786446548998356\n",
            "Epoch 392 : Loss 0.02786356396973133\n",
            "Epoch 393 : Loss 0.027862658724188805\n",
            "Epoch 394 : Loss 0.027861762791872025\n",
            "Epoch 395 : Loss 0.027860872447490692\n",
            "Epoch 396 : Loss 0.02785997837781906\n",
            "Epoch 397 : Loss 0.027859093621373177\n",
            "Epoch 398 : Loss 0.027858205139636993\n",
            "Epoch 399 : Loss 0.027857325971126556\n",
            "Epoch 400 : Loss 0.02785644680261612\n",
            "Epoch 401 : Loss 0.02785556949675083\n",
            "Epoch 402 : Loss 0.02785470150411129\n",
            "Epoch 403 : Loss 0.0278538316488266\n",
            "Epoch 404 : Loss 0.027852965518832207\n",
            "Epoch 405 : Loss 0.027852103114128113\n",
            "Epoch 406 : Loss 0.027851242572069168\n",
            "Epoch 407 : Loss 0.027850385755300522\n",
            "Epoch 408 : Loss 0.027849528938531876\n",
            "Epoch 409 : Loss 0.027848683297634125\n",
            "Epoch 410 : Loss 0.027847833931446075\n",
            "Epoch 411 : Loss 0.027846988290548325\n",
            "Epoch 412 : Loss 0.02784614823758602\n",
            "Epoch 413 : Loss 0.02784530632197857\n",
            "Epoch 414 : Loss 0.027844473719596863\n",
            "Epoch 415 : Loss 0.027843639254570007\n",
            "Epoch 416 : Loss 0.02784280851483345\n",
            "Epoch 417 : Loss 0.027841981500387192\n",
            "Epoch 418 : Loss 0.02784116007387638\n",
            "Epoch 419 : Loss 0.02784034051001072\n",
            "Epoch 420 : Loss 0.02783951908349991\n",
            "Epoch 421 : Loss 0.027838706970214844\n",
            "Epoch 422 : Loss 0.02783789485692978\n",
            "Epoch 423 : Loss 0.027837084606289864\n",
            "Epoch 424 : Loss 0.027836276218295097\n",
            "Epoch 425 : Loss 0.02783547341823578\n",
            "Epoch 426 : Loss 0.02783467434346676\n",
            "Epoch 427 : Loss 0.02783387340605259\n",
            "Epoch 428 : Loss 0.027833079919219017\n",
            "Epoch 429 : Loss 0.027832288295030594\n",
            "Epoch 430 : Loss 0.02783149853348732\n",
            "Epoch 431 : Loss 0.027830714359879494\n",
            "Epoch 432 : Loss 0.027829930186271667\n",
            "Epoch 433 : Loss 0.02782915160059929\n",
            "Epoch 434 : Loss 0.02782837115228176\n",
            "Epoch 435 : Loss 0.02782759629189968\n",
            "Epoch 436 : Loss 0.027826819568872452\n",
            "Epoch 437 : Loss 0.027826054021716118\n",
            "Epoch 438 : Loss 0.027825286611914635\n",
            "Epoch 439 : Loss 0.02782452292740345\n",
            "Epoch 440 : Loss 0.027823761105537415\n",
            "Epoch 441 : Loss 0.02782299742102623\n",
            "Epoch 442 : Loss 0.02782224491238594\n",
            "Epoch 443 : Loss 0.027821490541100502\n",
            "Epoch 444 : Loss 0.02782074175775051\n",
            "Epoch 445 : Loss 0.027819989249110222\n",
            "Epoch 446 : Loss 0.027819247916340828\n",
            "Epoch 447 : Loss 0.027818502858281136\n",
            "Epoch 448 : Loss 0.02781776338815689\n",
            "Epoch 449 : Loss 0.027817025780677795\n",
            "Epoch 450 : Loss 0.02781629003584385\n",
            "Epoch 451 : Loss 0.02781555987894535\n",
            "Epoch 452 : Loss 0.027814827859401703\n",
            "Epoch 453 : Loss 0.027814099565148354\n",
            "Epoch 454 : Loss 0.027813374996185303\n",
            "Epoch 455 : Loss 0.02781265415251255\n",
            "Epoch 456 : Loss 0.027811935171484947\n",
            "Epoch 457 : Loss 0.027811216190457344\n",
            "Epoch 458 : Loss 0.02781050279736519\n",
            "Epoch 459 : Loss 0.027809791266918182\n",
            "Epoch 460 : Loss 0.027809081599116325\n",
            "Epoch 461 : Loss 0.027808373793959618\n",
            "Epoch 462 : Loss 0.027807675302028656\n",
            "Epoch 463 : Loss 0.027806969359517097\n",
            "Epoch 464 : Loss 0.027806270867586136\n",
            "Epoch 465 : Loss 0.027805576100945473\n",
            "Epoch 466 : Loss 0.02780487760901451\n",
            "Epoch 467 : Loss 0.027804188430309296\n",
            "Epoch 468 : Loss 0.02780350111424923\n",
            "Epoch 469 : Loss 0.027802810072898865\n",
            "Epoch 470 : Loss 0.027802126482129097\n",
            "Epoch 471 : Loss 0.02780144289135933\n",
            "Epoch 472 : Loss 0.02780076488852501\n",
            "Epoch 473 : Loss 0.02780008874833584\n",
            "Epoch 474 : Loss 0.027799410745501518\n",
            "Epoch 475 : Loss 0.027798740193247795\n",
            "Epoch 476 : Loss 0.02779807336628437\n",
            "Epoch 477 : Loss 0.027797404676675797\n",
            "Epoch 478 : Loss 0.02779673971235752\n",
            "Epoch 479 : Loss 0.027796078473329544\n",
            "Epoch 480 : Loss 0.02779541350901127\n",
            "Epoch 481 : Loss 0.02779475599527359\n",
            "Epoch 482 : Loss 0.02779410406947136\n",
            "Epoch 483 : Loss 0.02779345028102398\n",
            "Epoch 484 : Loss 0.02779279835522175\n",
            "Epoch 485 : Loss 0.027792146429419518\n",
            "Epoch 486 : Loss 0.027791501954197884\n",
            "Epoch 487 : Loss 0.02779085747897625\n",
            "Epoch 488 : Loss 0.027790218591690063\n",
            "Epoch 489 : Loss 0.02778957597911358\n",
            "Epoch 490 : Loss 0.02778894081711769\n",
            "Epoch 491 : Loss 0.027788301929831505\n",
            "Epoch 492 : Loss 0.027787672355771065\n",
            "Epoch 493 : Loss 0.027787042781710625\n",
            "Epoch 494 : Loss 0.027786413207650185\n",
            "Epoch 495 : Loss 0.027785787358880043\n",
            "Epoch 496 : Loss 0.02778516337275505\n",
            "Epoch 497 : Loss 0.02778453938663006\n",
            "Epoch 498 : Loss 0.027783924713730812\n",
            "Epoch 499 : Loss 0.02778330259025097\n",
            "Epoch 500 : Loss 0.027782687917351723\n",
            "Epoch 501 : Loss 0.027782076969742775\n",
            "Epoch 502 : Loss 0.02778146229684353\n",
            "Epoch 503 : Loss 0.02778085693717003\n",
            "Epoch 504 : Loss 0.02778024785220623\n",
            "Epoch 505 : Loss 0.027779648080468178\n",
            "Epoch 506 : Loss 0.027779044583439827\n",
            "Epoch 507 : Loss 0.027778444811701775\n",
            "Epoch 508 : Loss 0.02777784690260887\n",
            "Epoch 509 : Loss 0.027777252718806267\n",
            "Epoch 510 : Loss 0.02777666039764881\n",
            "Epoch 511 : Loss 0.027776066213846207\n",
            "Epoch 512 : Loss 0.02777547389268875\n",
            "Epoch 513 : Loss 0.027774889022111893\n",
            "Epoch 514 : Loss 0.027774306014180183\n",
            "Epoch 515 : Loss 0.027773719280958176\n",
            "Epoch 516 : Loss 0.027773141860961914\n",
            "Epoch 517 : Loss 0.027772564440965652\n",
            "Epoch 518 : Loss 0.027771983295679092\n",
            "Epoch 519 : Loss 0.02777140960097313\n",
            "Epoch 520 : Loss 0.027770835906267166\n",
            "Epoch 521 : Loss 0.02777026779949665\n",
            "Epoch 522 : Loss 0.027769695967435837\n",
            "Epoch 523 : Loss 0.02776913158595562\n",
            "Epoch 524 : Loss 0.027768567204475403\n",
            "Epoch 525 : Loss 0.027768004685640335\n",
            "Epoch 526 : Loss 0.027767442166805267\n",
            "Epoch 527 : Loss 0.027766887098550797\n",
            "Epoch 528 : Loss 0.027766326442360878\n",
            "Epoch 529 : Loss 0.027765773236751556\n",
            "Epoch 530 : Loss 0.027765221893787384\n",
            "Epoch 531 : Loss 0.027764668688178062\n",
            "Epoch 532 : Loss 0.02776411920785904\n",
            "Epoch 533 : Loss 0.027763577178120613\n",
            "Epoch 534 : Loss 0.02776303142309189\n",
            "Epoch 535 : Loss 0.027762487530708313\n",
            "Epoch 536 : Loss 0.027761947363615036\n",
            "Epoch 537 : Loss 0.02776140533387661\n",
            "Epoch 538 : Loss 0.02776087075471878\n",
            "Epoch 539 : Loss 0.027760334312915802\n",
            "Epoch 540 : Loss 0.027759801596403122\n",
            "Epoch 541 : Loss 0.027759268879890442\n",
            "Epoch 542 : Loss 0.02775874175131321\n",
            "Epoch 543 : Loss 0.027758212760090828\n",
            "Epoch 544 : Loss 0.027757687494158745\n",
            "Epoch 545 : Loss 0.02775716409087181\n",
            "Epoch 546 : Loss 0.027756644412875175\n",
            "Epoch 547 : Loss 0.02775612100958824\n",
            "Epoch 548 : Loss 0.027755601331591606\n",
            "Epoch 549 : Loss 0.02775508537888527\n",
            "Epoch 550 : Loss 0.02775457128882408\n",
            "Epoch 551 : Loss 0.027754059061408043\n",
            "Epoch 552 : Loss 0.027753546833992004\n",
            "Epoch 553 : Loss 0.027753036469221115\n",
            "Epoch 554 : Loss 0.027752531692385674\n",
            "Epoch 555 : Loss 0.027752025052905083\n",
            "Epoch 556 : Loss 0.02775152027606964\n",
            "Epoch 557 : Loss 0.027751019224524498\n",
            "Epoch 558 : Loss 0.027750520035624504\n",
            "Epoch 559 : Loss 0.02775002270936966\n",
            "Epoch 560 : Loss 0.027749523520469666\n",
            "Epoch 561 : Loss 0.02774903178215027\n",
            "Epoch 562 : Loss 0.027748536318540573\n",
            "Epoch 563 : Loss 0.027748046442866325\n",
            "Epoch 564 : Loss 0.027747558429837227\n",
            "Epoch 565 : Loss 0.02774706855416298\n",
            "Epoch 566 : Loss 0.02774658240377903\n",
            "Epoch 567 : Loss 0.02774609811604023\n",
            "Epoch 568 : Loss 0.02774561382830143\n",
            "Epoch 569 : Loss 0.027745133265852928\n",
            "Epoch 570 : Loss 0.027744652703404427\n",
            "Epoch 571 : Loss 0.027744177728891373\n",
            "Epoch 572 : Loss 0.02774369902908802\n",
            "Epoch 573 : Loss 0.027743225917220116\n",
            "Epoch 574 : Loss 0.02774275280535221\n",
            "Epoch 575 : Loss 0.027742285281419754\n",
            "Epoch 576 : Loss 0.027741814032197\n",
            "Epoch 577 : Loss 0.02774134837090969\n",
            "Epoch 578 : Loss 0.027740878984332085\n",
            "Epoch 579 : Loss 0.027740417048335075\n",
            "Epoch 580 : Loss 0.027739955112338066\n",
            "Epoch 581 : Loss 0.027739495038986206\n",
            "Epoch 582 : Loss 0.027739033102989197\n",
            "Epoch 583 : Loss 0.027738576754927635\n",
            "Epoch 584 : Loss 0.027738118544220924\n",
            "Epoch 585 : Loss 0.02773766778409481\n",
            "Epoch 586 : Loss 0.027737217023968697\n",
            "Epoch 587 : Loss 0.027736762538552284\n",
            "Epoch 588 : Loss 0.02773631364107132\n",
            "Epoch 589 : Loss 0.027735866606235504\n",
            "Epoch 590 : Loss 0.02773541957139969\n",
            "Epoch 591 : Loss 0.027734976261854172\n",
            "Epoch 592 : Loss 0.027734531089663506\n",
            "Epoch 593 : Loss 0.027734089642763138\n",
            "Epoch 594 : Loss 0.02773365005850792\n",
            "Epoch 595 : Loss 0.02773321233689785\n",
            "Epoch 596 : Loss 0.02773277461528778\n",
            "Epoch 597 : Loss 0.02773234061896801\n",
            "Epoch 598 : Loss 0.02773190662264824\n",
            "Epoch 599 : Loss 0.027731474488973618\n",
            "Epoch 600 : Loss 0.027731042355298996\n",
            "Epoch 601 : Loss 0.027730612084269524\n",
            "Epoch 602 : Loss 0.0277301836758852\n",
            "Epoch 603 : Loss 0.027729760855436325\n",
            "Epoch 604 : Loss 0.0277293361723423\n",
            "Epoch 605 : Loss 0.027728911489248276\n",
            "Epoch 606 : Loss 0.0277284923940897\n",
            "Epoch 607 : Loss 0.027728071436285973\n",
            "Epoch 608 : Loss 0.027727654203772545\n",
            "Epoch 609 : Loss 0.02772723324596882\n",
            "Epoch 610 : Loss 0.02772681787610054\n",
            "Epoch 611 : Loss 0.02772640250623226\n",
            "Epoch 612 : Loss 0.02772599458694458\n",
            "Epoch 613 : Loss 0.02772558107972145\n",
            "Epoch 614 : Loss 0.02772517316043377\n",
            "Epoch 615 : Loss 0.02772476151585579\n",
            "Epoch 616 : Loss 0.027724357321858406\n",
            "Epoch 617 : Loss 0.027723951265215874\n",
            "Epoch 618 : Loss 0.02772354707121849\n",
            "Epoch 619 : Loss 0.027723144739866257\n",
            "Epoch 620 : Loss 0.027722742408514023\n",
            "Epoch 621 : Loss 0.027722345665097237\n",
            "Epoch 622 : Loss 0.0277219470590353\n",
            "Epoch 623 : Loss 0.027721550315618515\n",
            "Epoch 624 : Loss 0.02772115357220173\n",
            "Epoch 625 : Loss 0.027720758691430092\n",
            "Epoch 626 : Loss 0.027720369398593903\n",
            "Epoch 627 : Loss 0.027719974517822266\n",
            "Epoch 628 : Loss 0.027719585224986076\n",
            "Epoch 629 : Loss 0.027719195932149887\n",
            "Epoch 630 : Loss 0.027718808501958847\n",
            "Epoch 631 : Loss 0.027718426659703255\n",
            "Epoch 632 : Loss 0.027718041092157364\n",
            "Epoch 633 : Loss 0.02771765924990177\n",
            "Epoch 634 : Loss 0.02771727740764618\n",
            "Epoch 635 : Loss 0.027716895565390587\n",
            "Epoch 636 : Loss 0.027716519311070442\n",
            "Epoch 637 : Loss 0.02771614119410515\n",
            "Epoch 638 : Loss 0.027715763077139854\n",
            "Epoch 639 : Loss 0.02771538868546486\n",
            "Epoch 640 : Loss 0.027715014293789864\n",
            "Epoch 641 : Loss 0.027714641764760017\n",
            "Epoch 642 : Loss 0.02771427109837532\n",
            "Epoch 643 : Loss 0.027713900431990623\n",
            "Epoch 644 : Loss 0.027713533490896225\n",
            "Epoch 645 : Loss 0.027713168412446976\n",
            "Epoch 646 : Loss 0.027712799608707428\n",
            "Epoch 647 : Loss 0.027712436392903328\n",
            "Epoch 648 : Loss 0.027712075039744377\n",
            "Epoch 649 : Loss 0.027711713686585426\n",
            "Epoch 650 : Loss 0.027711348608136177\n",
            "Epoch 651 : Loss 0.027710992842912674\n",
            "Epoch 652 : Loss 0.02771063521504402\n",
            "Epoch 653 : Loss 0.02771027944982052\n",
            "Epoch 654 : Loss 0.027709923684597015\n",
            "Epoch 655 : Loss 0.02770956978201866\n",
            "Epoch 656 : Loss 0.027709217742085457\n",
            "Epoch 657 : Loss 0.027708865702152252\n",
            "Epoch 658 : Loss 0.027708513662219048\n",
            "Epoch 659 : Loss 0.027708163484930992\n",
            "Epoch 660 : Loss 0.027707818895578384\n",
            "Epoch 661 : Loss 0.027707472443580627\n",
            "Epoch 662 : Loss 0.02770712599158287\n",
            "Epoch 663 : Loss 0.027706781402230263\n",
            "Epoch 664 : Loss 0.027706440538167953\n",
            "Epoch 665 : Loss 0.027706097811460495\n",
            "Epoch 666 : Loss 0.027705758810043335\n",
            "Epoch 667 : Loss 0.027705417945981026\n",
            "Epoch 668 : Loss 0.027705080807209015\n",
            "Epoch 669 : Loss 0.027704745531082153\n",
            "Epoch 670 : Loss 0.027704406529664993\n",
            "Epoch 671 : Loss 0.02770407125353813\n",
            "Epoch 672 : Loss 0.02770373970270157\n",
            "Epoch 673 : Loss 0.027703408151865005\n",
            "Epoch 674 : Loss 0.02770307846367359\n",
            "Epoch 675 : Loss 0.02770274505019188\n",
            "Epoch 676 : Loss 0.027702417224645615\n",
            "Epoch 677 : Loss 0.0277020912617445\n",
            "Epoch 678 : Loss 0.027701767161488533\n",
            "Epoch 679 : Loss 0.02770143933594227\n",
            "Epoch 680 : Loss 0.027701115235686302\n",
            "Epoch 681 : Loss 0.027700794860720634\n",
            "Epoch 682 : Loss 0.027700472623109818\n",
            "Epoch 683 : Loss 0.02770015224814415\n",
            "Epoch 684 : Loss 0.02769983373582363\n",
            "Epoch 685 : Loss 0.027699515223503113\n",
            "Epoch 686 : Loss 0.027699196711182594\n",
            "Epoch 687 : Loss 0.027698880061507225\n",
            "Epoch 688 : Loss 0.027698568999767303\n",
            "Epoch 689 : Loss 0.027698254212737083\n",
            "Epoch 690 : Loss 0.027697939425706863\n",
            "Epoch 691 : Loss 0.027697628363966942\n",
            "Epoch 692 : Loss 0.02769731916487217\n",
            "Epoch 693 : Loss 0.027697008103132248\n",
            "Epoch 694 : Loss 0.027696700766682625\n",
            "Epoch 695 : Loss 0.027696391567587852\n",
            "Epoch 696 : Loss 0.02769608423113823\n",
            "Epoch 697 : Loss 0.027695782482624054\n",
            "Epoch 698 : Loss 0.02769547887146473\n",
            "Epoch 699 : Loss 0.027695175260305405\n",
            "Epoch 700 : Loss 0.02769487351179123\n",
            "Epoch 701 : Loss 0.027694575488567352\n",
            "Epoch 702 : Loss 0.027694277465343475\n",
            "Epoch 703 : Loss 0.02769397757947445\n",
            "Epoch 704 : Loss 0.02769368141889572\n",
            "Epoch 705 : Loss 0.027693381533026695\n",
            "Epoch 706 : Loss 0.027693087235093117\n",
            "Epoch 707 : Loss 0.02769279293715954\n",
            "Epoch 708 : Loss 0.02769250050187111\n",
            "Epoch 709 : Loss 0.02769220992922783\n",
            "Epoch 710 : Loss 0.0276919137686491\n",
            "Epoch 711 : Loss 0.02769162505865097\n",
            "Epoch 712 : Loss 0.02769133821129799\n",
            "Epoch 713 : Loss 0.027691049501299858\n",
            "Epoch 714 : Loss 0.027690762653946877\n",
            "Epoch 715 : Loss 0.027690475806593895\n",
            "Epoch 716 : Loss 0.027690190821886063\n",
            "Epoch 717 : Loss 0.02768990956246853\n",
            "Epoch 718 : Loss 0.027689624577760696\n",
            "Epoch 719 : Loss 0.027689343318343163\n",
            "Epoch 720 : Loss 0.027689063921570778\n",
            "Epoch 721 : Loss 0.027688786387443542\n",
            "Epoch 722 : Loss 0.02768850326538086\n",
            "Epoch 723 : Loss 0.027688223868608475\n",
            "Epoch 724 : Loss 0.02768794819712639\n",
            "Epoch 725 : Loss 0.027687672525644302\n",
            "Epoch 726 : Loss 0.027687396854162216\n",
            "Epoch 727 : Loss 0.02768712490797043\n",
            "Epoch 728 : Loss 0.02768685109913349\n",
            "Epoch 729 : Loss 0.027686579152941704\n",
            "Epoch 730 : Loss 0.027686307206749916\n",
            "Epoch 731 : Loss 0.02768603526055813\n",
            "Epoch 732 : Loss 0.027685770764946938\n",
            "Epoch 733 : Loss 0.02768550254404545\n",
            "Epoch 734 : Loss 0.02768523432314396\n",
            "Epoch 735 : Loss 0.02768496796488762\n",
            "Epoch 736 : Loss 0.027684703469276428\n",
            "Epoch 737 : Loss 0.027684437111020088\n",
            "Epoch 738 : Loss 0.027684174478054047\n",
            "Epoch 739 : Loss 0.027683909982442856\n",
            "Epoch 740 : Loss 0.027683649212121964\n",
            "Epoch 741 : Loss 0.02768339030444622\n",
            "Epoch 742 : Loss 0.027683129534125328\n",
            "Epoch 743 : Loss 0.027682870626449585\n",
            "Epoch 744 : Loss 0.027682611718773842\n",
            "Epoch 745 : Loss 0.027682356536388397\n",
            "Epoch 746 : Loss 0.027682099491357803\n",
            "Epoch 747 : Loss 0.027681846171617508\n",
            "Epoch 748 : Loss 0.027681589126586914\n",
            "Epoch 749 : Loss 0.027681337669491768\n",
            "Epoch 750 : Loss 0.027681084349751472\n",
            "Epoch 751 : Loss 0.027680831030011177\n",
            "Epoch 752 : Loss 0.02768057957291603\n",
            "Epoch 753 : Loss 0.027680329978466034\n",
            "Epoch 754 : Loss 0.027680084109306335\n",
            "Epoch 755 : Loss 0.027679836377501488\n",
            "Epoch 756 : Loss 0.02767959050834179\n",
            "Epoch 757 : Loss 0.02767934277653694\n",
            "Epoch 758 : Loss 0.027679096907377243\n",
            "Epoch 759 : Loss 0.027678854763507843\n",
            "Epoch 760 : Loss 0.027678610756993294\n",
            "Epoch 761 : Loss 0.027678363025188446\n",
            "Epoch 762 : Loss 0.027678124606609344\n",
            "Epoch 763 : Loss 0.027677882462739944\n",
            "Epoch 764 : Loss 0.027677644044160843\n",
            "Epoch 765 : Loss 0.027677401900291443\n",
            "Epoch 766 : Loss 0.02767716534435749\n",
            "Epoch 767 : Loss 0.027676928788423538\n",
            "Epoch 768 : Loss 0.027676690369844437\n",
            "Epoch 769 : Loss 0.027676453813910484\n",
            "Epoch 770 : Loss 0.02767621912062168\n",
            "Epoch 771 : Loss 0.027675984427332878\n",
            "Epoch 772 : Loss 0.027675753459334373\n",
            "Epoch 773 : Loss 0.02767551876604557\n",
            "Epoch 774 : Loss 0.027675289660692215\n",
            "Epoch 775 : Loss 0.027675054967403412\n",
            "Epoch 776 : Loss 0.027674827724695206\n",
            "Epoch 777 : Loss 0.0276745967566967\n",
            "Epoch 778 : Loss 0.027674369513988495\n",
            "Epoch 779 : Loss 0.027674144133925438\n",
            "Epoch 780 : Loss 0.027673915028572083\n",
            "Epoch 781 : Loss 0.027673691511154175\n",
            "Epoch 782 : Loss 0.02767346240580082\n",
            "Epoch 783 : Loss 0.02767323888838291\n",
            "Epoch 784 : Loss 0.027673017233610153\n",
            "Epoch 785 : Loss 0.027672791853547096\n",
            "Epoch 786 : Loss 0.027672572061419487\n",
            "Epoch 787 : Loss 0.02767234854400158\n",
            "Epoch 788 : Loss 0.02767213061451912\n",
            "Epoch 789 : Loss 0.02767190709710121\n",
            "Epoch 790 : Loss 0.02767168916761875\n",
            "Epoch 791 : Loss 0.02767147310078144\n",
            "Epoch 792 : Loss 0.02767125703394413\n",
            "Epoch 793 : Loss 0.02767103910446167\n",
            "Epoch 794 : Loss 0.02767081931233406\n",
            "Epoch 795 : Loss 0.027670608833432198\n",
            "Epoch 796 : Loss 0.027670392766594887\n",
            "Epoch 797 : Loss 0.027670178562402725\n",
            "Epoch 798 : Loss 0.027669968083500862\n",
            "Epoch 799 : Loss 0.02766975201666355\n",
            "Epoch 800 : Loss 0.027669541537761688\n",
            "Epoch 801 : Loss 0.027669336646795273\n",
            "Epoch 802 : Loss 0.02766912430524826\n",
            "Epoch 803 : Loss 0.027668915688991547\n",
            "Epoch 804 : Loss 0.027668707072734833\n",
            "Epoch 805 : Loss 0.027668500319123268\n",
            "Epoch 806 : Loss 0.027668293565511703\n",
            "Epoch 807 : Loss 0.02766808494925499\n",
            "Epoch 808 : Loss 0.027667883783578873\n",
            "Epoch 809 : Loss 0.027667677029967308\n",
            "Epoch 810 : Loss 0.027667472139000893\n",
            "Epoch 811 : Loss 0.027667270973324776\n",
            "Epoch 812 : Loss 0.02766706794500351\n",
            "Epoch 813 : Loss 0.027666863054037094\n",
            "Epoch 814 : Loss 0.027666665613651276\n",
            "Epoch 815 : Loss 0.02766646258533001\n",
            "Epoch 816 : Loss 0.02766626514494419\n",
            "Epoch 817 : Loss 0.027666067704558372\n",
            "Epoch 818 : Loss 0.027665866538882256\n",
            "Epoch 819 : Loss 0.027665669098496437\n",
            "Epoch 820 : Loss 0.027665473520755768\n",
            "Epoch 821 : Loss 0.0276652779430151\n",
            "Epoch 822 : Loss 0.02766508236527443\n",
            "Epoch 823 : Loss 0.02766488678753376\n",
            "Epoch 824 : Loss 0.02766469120979309\n",
            "Epoch 825 : Loss 0.02766450121998787\n",
            "Epoch 826 : Loss 0.02766430750489235\n",
            "Epoch 827 : Loss 0.027664117515087128\n",
            "Epoch 828 : Loss 0.027663923799991608\n",
            "Epoch 829 : Loss 0.027663731947541237\n",
            "Epoch 830 : Loss 0.027663543820381165\n",
            "Epoch 831 : Loss 0.027663353830575943\n",
            "Epoch 832 : Loss 0.02766316570341587\n",
            "Epoch 833 : Loss 0.02766297571361065\n",
            "Epoch 834 : Loss 0.027662791311740875\n",
            "Epoch 835 : Loss 0.027662603184580803\n",
            "Epoch 836 : Loss 0.02766241878271103\n",
            "Epoch 837 : Loss 0.027662232518196106\n",
            "Epoch 838 : Loss 0.02766204997897148\n",
            "Epoch 839 : Loss 0.027661865577101707\n",
            "Epoch 840 : Loss 0.027661683037877083\n",
            "Epoch 841 : Loss 0.02766149863600731\n",
            "Epoch 842 : Loss 0.027661317959427834\n",
            "Epoch 843 : Loss 0.02766113542020321\n",
            "Epoch 844 : Loss 0.027660952880978584\n",
            "Epoch 845 : Loss 0.027660774067044258\n",
            "Epoch 846 : Loss 0.02766059897840023\n",
            "Epoch 847 : Loss 0.027660418301820755\n",
            "Epoch 848 : Loss 0.02766023948788643\n",
            "Epoch 849 : Loss 0.027660060673952103\n",
            "Epoch 850 : Loss 0.027659885585308075\n",
            "Epoch 851 : Loss 0.027659710496664047\n",
            "Epoch 852 : Loss 0.02765953354537487\n",
            "Epoch 853 : Loss 0.027659358456730843\n",
            "Epoch 854 : Loss 0.027659181505441666\n",
            "Epoch 855 : Loss 0.027659008279442787\n",
            "Epoch 856 : Loss 0.027658838778734207\n",
            "Epoch 857 : Loss 0.02765866369009018\n",
            "Epoch 858 : Loss 0.02765849232673645\n",
            "Epoch 859 : Loss 0.02765832096338272\n",
            "Epoch 860 : Loss 0.02765815146267414\n",
            "Epoch 861 : Loss 0.02765798009932041\n",
            "Epoch 862 : Loss 0.02765781246125698\n",
            "Epoch 863 : Loss 0.02765764109790325\n",
            "Epoch 864 : Loss 0.02765747532248497\n",
            "Epoch 865 : Loss 0.02765730582177639\n",
            "Epoch 866 : Loss 0.02765714004635811\n",
            "Epoch 867 : Loss 0.027656972408294678\n",
            "Epoch 868 : Loss 0.027656810358166695\n",
            "Epoch 869 : Loss 0.027656642720103264\n",
            "Epoch 870 : Loss 0.02765648066997528\n",
            "Epoch 871 : Loss 0.027656314894557\n",
            "Epoch 872 : Loss 0.027656150981783867\n",
            "Epoch 873 : Loss 0.027655988931655884\n",
            "Epoch 874 : Loss 0.02765582501888275\n",
            "Epoch 875 : Loss 0.02765566296875477\n",
            "Epoch 876 : Loss 0.027655504643917084\n",
            "Epoch 877 : Loss 0.02765534073114395\n",
            "Epoch 878 : Loss 0.027655180543661118\n",
            "Epoch 879 : Loss 0.027655022218823433\n",
            "Epoch 880 : Loss 0.0276548620313406\n",
            "Epoch 881 : Loss 0.027654703706502914\n",
            "Epoch 882 : Loss 0.027654549106955528\n",
            "Epoch 883 : Loss 0.027654388919472694\n",
            "Epoch 884 : Loss 0.02765423245728016\n",
            "Epoch 885 : Loss 0.027654077857732773\n",
            "Epoch 886 : Loss 0.027653921395540237\n",
            "Epoch 887 : Loss 0.027653768658638\n",
            "Epoch 888 : Loss 0.027653614059090614\n",
            "Epoch 889 : Loss 0.02765345759689808\n",
            "Epoch 890 : Loss 0.027653302997350693\n",
            "Epoch 891 : Loss 0.027653148397803307\n",
            "Epoch 892 : Loss 0.027652999386191368\n",
            "Epoch 893 : Loss 0.027652844786643982\n",
            "Epoch 894 : Loss 0.027652693912386894\n",
            "Epoch 895 : Loss 0.027652546763420105\n",
            "Epoch 896 : Loss 0.027652399614453316\n",
            "Epoch 897 : Loss 0.02765224687755108\n",
            "Epoch 898 : Loss 0.02765209786593914\n",
            "Epoch 899 : Loss 0.02765195071697235\n",
            "Epoch 900 : Loss 0.027651801705360413\n",
            "Epoch 901 : Loss 0.027651656419038773\n",
            "Epoch 902 : Loss 0.027651507407426834\n",
            "Epoch 903 : Loss 0.027651360258460045\n",
            "Epoch 904 : Loss 0.027651213109493256\n",
            "Epoch 905 : Loss 0.027651069685816765\n",
            "Epoch 906 : Loss 0.027650924399495125\n",
            "Epoch 907 : Loss 0.027650779113173485\n",
            "Epoch 908 : Loss 0.027650637552142143\n",
            "Epoch 909 : Loss 0.027650494128465652\n",
            "Epoch 910 : Loss 0.027650348842144012\n",
            "Epoch 911 : Loss 0.02765020914375782\n",
            "Epoch 912 : Loss 0.02765006758272648\n",
            "Epoch 913 : Loss 0.027649926021695137\n",
            "Epoch 914 : Loss 0.027649784460663795\n",
            "Epoch 915 : Loss 0.027649642899632454\n",
            "Epoch 916 : Loss 0.027649501338601112\n",
            "Epoch 917 : Loss 0.027649367228150368\n",
            "Epoch 918 : Loss 0.027649227529764175\n",
            "Epoch 919 : Loss 0.027649087831377983\n",
            "Epoch 920 : Loss 0.02764895185828209\n",
            "Epoch 921 : Loss 0.027648812159895897\n",
            "Epoch 922 : Loss 0.027648674324154854\n",
            "Epoch 923 : Loss 0.02764853835105896\n",
            "Epoch 924 : Loss 0.027648402377963066\n",
            "Epoch 925 : Loss 0.02764826826751232\n",
            "Epoch 926 : Loss 0.027648132294416428\n",
            "Epoch 927 : Loss 0.027647998183965683\n",
            "Epoch 928 : Loss 0.027647865936160088\n",
            "Epoch 929 : Loss 0.027647731825709343\n",
            "Epoch 930 : Loss 0.0276475977152586\n",
            "Epoch 931 : Loss 0.027647467330098152\n",
            "Epoch 932 : Loss 0.027647333219647408\n",
            "Epoch 933 : Loss 0.027647200971841812\n",
            "Epoch 934 : Loss 0.027647072449326515\n",
            "Epoch 935 : Loss 0.02764694206416607\n",
            "Epoch 936 : Loss 0.027646807953715324\n",
            "Epoch 937 : Loss 0.027646683156490326\n",
            "Epoch 938 : Loss 0.02764655277132988\n",
            "Epoch 939 : Loss 0.027646420523524284\n",
            "Epoch 940 : Loss 0.027646293863654137\n",
            "Epoch 941 : Loss 0.02764616347849369\n",
            "Epoch 942 : Loss 0.027646038681268692\n",
            "Epoch 943 : Loss 0.027645913884043694\n",
            "Epoch 944 : Loss 0.027645785361528397\n",
            "Epoch 945 : Loss 0.02764565870165825\n",
            "Epoch 946 : Loss 0.027645530179142952\n",
            "Epoch 947 : Loss 0.027645407244563103\n",
            "Epoch 948 : Loss 0.027645282447338104\n",
            "Epoch 949 : Loss 0.027645159512758255\n",
            "Epoch 950 : Loss 0.027645036578178406\n",
            "Epoch 951 : Loss 0.027644913643598557\n",
            "Epoch 952 : Loss 0.027644788846373558\n",
            "Epoch 953 : Loss 0.02764466404914856\n",
            "Epoch 954 : Loss 0.02764454297721386\n",
            "Epoch 955 : Loss 0.02764442190527916\n",
            "Epoch 956 : Loss 0.02764430269598961\n",
            "Epoch 957 : Loss 0.02764417976140976\n",
            "Epoch 958 : Loss 0.02764406055212021\n",
            "Epoch 959 : Loss 0.02764393948018551\n",
            "Epoch 960 : Loss 0.027643820270895958\n",
            "Epoch 961 : Loss 0.027643701061606407\n",
            "Epoch 962 : Loss 0.027643583714962006\n",
            "Epoch 963 : Loss 0.027643464505672455\n",
            "Epoch 964 : Loss 0.027643345296382904\n",
            "Epoch 965 : Loss 0.027643227949738503\n",
            "Epoch 966 : Loss 0.02764311246573925\n",
            "Epoch 967 : Loss 0.02764299511909485\n",
            "Epoch 968 : Loss 0.027642879635095596\n",
            "Epoch 969 : Loss 0.027642764151096344\n",
            "Epoch 970 : Loss 0.02764265052974224\n",
            "Epoch 971 : Loss 0.02764253504574299\n",
            "Epoch 972 : Loss 0.027642417699098587\n",
            "Epoch 973 : Loss 0.027642305940389633\n",
            "Epoch 974 : Loss 0.02764219231903553\n",
            "Epoch 975 : Loss 0.027642078697681427\n",
            "Epoch 976 : Loss 0.027641966938972473\n",
            "Epoch 977 : Loss 0.02764185145497322\n",
            "Epoch 978 : Loss 0.027641741558909416\n",
            "Epoch 979 : Loss 0.027641627937555313\n",
            "Epoch 980 : Loss 0.02764151617884636\n",
            "Epoch 981 : Loss 0.027641408145427704\n",
            "Epoch 982 : Loss 0.02764129638671875\n",
            "Epoch 983 : Loss 0.027641188353300095\n",
            "Epoch 984 : Loss 0.02764107473194599\n",
            "Epoch 985 : Loss 0.027640964835882187\n",
            "Epoch 986 : Loss 0.02764085680246353\n",
            "Epoch 987 : Loss 0.027640750631690025\n",
            "Epoch 988 : Loss 0.02764064446091652\n",
            "Epoch 989 : Loss 0.027640532702207565\n",
            "Epoch 990 : Loss 0.02764042653143406\n",
            "Epoch 991 : Loss 0.027640320360660553\n",
            "Epoch 992 : Loss 0.02764021046459675\n",
            "Epoch 993 : Loss 0.02764010615646839\n",
            "Epoch 994 : Loss 0.027640001848340034\n",
            "Epoch 995 : Loss 0.02763989567756653\n",
            "Epoch 996 : Loss 0.027639789506793022\n",
            "Epoch 997 : Loss 0.027639683336019516\n",
            "Epoch 998 : Loss 0.02763958089053631\n",
            "Epoch 999 : Loss 0.0276394784450531\n",
            "Epoch 1000 : Loss 0.027639372274279594\n",
            "Epoch 1001 : Loss 0.027639271691441536\n",
            "Epoch 1002 : Loss 0.02763916738331318\n",
            "Epoch 1003 : Loss 0.027639063075184822\n",
            "Epoch 1004 : Loss 0.027638962492346764\n",
            "Epoch 1005 : Loss 0.027638860046863556\n",
            "Epoch 1006 : Loss 0.0276387557387352\n",
            "Epoch 1007 : Loss 0.02763865701854229\n",
            "Epoch 1008 : Loss 0.02763855829834938\n",
            "Epoch 1009 : Loss 0.027638455852866173\n",
            "Epoch 1010 : Loss 0.027638355270028114\n",
            "Epoch 1011 : Loss 0.027638258412480354\n",
            "Epoch 1012 : Loss 0.027638155966997147\n",
            "Epoch 1013 : Loss 0.027638055384159088\n",
            "Epoch 1014 : Loss 0.027637958526611328\n",
            "Epoch 1015 : Loss 0.027637861669063568\n",
            "Epoch 1016 : Loss 0.02763776294887066\n",
            "Epoch 1017 : Loss 0.02763766422867775\n",
            "Epoch 1018 : Loss 0.02763756923377514\n",
            "Epoch 1019 : Loss 0.02763747051358223\n",
            "Epoch 1020 : Loss 0.02763737551867962\n",
            "Epoch 1021 : Loss 0.02763727866113186\n",
            "Epoch 1022 : Loss 0.027637183666229248\n",
            "Epoch 1023 : Loss 0.027637086808681488\n",
            "Epoch 1024 : Loss 0.027636991813778877\n",
            "Epoch 1025 : Loss 0.027636898681521416\n",
            "Epoch 1026 : Loss 0.027636801823973656\n",
            "Epoch 1027 : Loss 0.027636708691716194\n",
            "Epoch 1028 : Loss 0.027636613696813583\n",
            "Epoch 1029 : Loss 0.027636520564556122\n",
            "Epoch 1030 : Loss 0.02763643115758896\n",
            "Epoch 1031 : Loss 0.027636338025331497\n",
            "Epoch 1032 : Loss 0.027636244893074036\n",
            "Epoch 1033 : Loss 0.027636149898171425\n",
            "Epoch 1034 : Loss 0.027636060491204262\n",
            "Epoch 1035 : Loss 0.0276359673589468\n",
            "Epoch 1036 : Loss 0.027635877951979637\n",
            "Epoch 1037 : Loss 0.027635784819722176\n",
            "Epoch 1038 : Loss 0.027635697275400162\n",
            "Epoch 1039 : Loss 0.0276356041431427\n",
            "Epoch 1040 : Loss 0.027635514736175537\n",
            "Epoch 1041 : Loss 0.027635425329208374\n",
            "Epoch 1042 : Loss 0.02763533405959606\n",
            "Epoch 1043 : Loss 0.0276352446526289\n",
            "Epoch 1044 : Loss 0.027635160833597183\n",
            "Epoch 1045 : Loss 0.02763507142663002\n",
            "Epoch 1046 : Loss 0.027634982019662857\n",
            "Epoch 1047 : Loss 0.027634894475340843\n",
            "Epoch 1048 : Loss 0.02763480693101883\n",
            "Epoch 1049 : Loss 0.027634719386696815\n",
            "Epoch 1050 : Loss 0.0276346318423748\n",
            "Epoch 1051 : Loss 0.027634546160697937\n",
            "Epoch 1052 : Loss 0.027634460479021072\n",
            "Epoch 1053 : Loss 0.02763437293469906\n",
            "Epoch 1054 : Loss 0.027634289115667343\n",
            "Epoch 1055 : Loss 0.02763420343399048\n",
            "Epoch 1056 : Loss 0.027634117752313614\n",
            "Epoch 1057 : Loss 0.0276340339332819\n",
            "Epoch 1058 : Loss 0.027633951976895332\n",
            "Epoch 1059 : Loss 0.02763386443257332\n",
            "Epoch 1060 : Loss 0.027633780613541603\n",
            "Epoch 1061 : Loss 0.027633698657155037\n",
            "Epoch 1062 : Loss 0.02763361483812332\n",
            "Epoch 1063 : Loss 0.027633532881736755\n",
            "Epoch 1064 : Loss 0.02763345092535019\n",
            "Epoch 1065 : Loss 0.027633368968963623\n",
            "Epoch 1066 : Loss 0.027633285149931908\n",
            "Epoch 1067 : Loss 0.02763320319354534\n",
            "Epoch 1068 : Loss 0.027633123099803925\n",
            "Epoch 1069 : Loss 0.02763303928077221\n",
            "Epoch 1070 : Loss 0.02763296104967594\n",
            "Epoch 1071 : Loss 0.027632879093289375\n",
            "Epoch 1072 : Loss 0.02763279713690281\n",
            "Epoch 1073 : Loss 0.02763272076845169\n",
            "Epoch 1074 : Loss 0.027632638812065125\n",
            "Epoch 1075 : Loss 0.027632560580968857\n",
            "Epoch 1076 : Loss 0.02763248048722744\n",
            "Epoch 1077 : Loss 0.027632402256131172\n",
            "Epoch 1078 : Loss 0.027632325887680054\n",
            "Epoch 1079 : Loss 0.027632247656583786\n",
            "Epoch 1080 : Loss 0.02763216756284237\n",
            "Epoch 1081 : Loss 0.0276320893317461\n",
            "Epoch 1082 : Loss 0.027632011100649834\n",
            "Epoch 1083 : Loss 0.027631936594843864\n",
            "Epoch 1084 : Loss 0.027631862089037895\n",
            "Epoch 1085 : Loss 0.02763178013265133\n",
            "Epoch 1086 : Loss 0.02763170748949051\n",
            "Epoch 1087 : Loss 0.02763162925839424\n",
            "Epoch 1088 : Loss 0.027631554752588272\n",
            "Epoch 1089 : Loss 0.027631476521492004\n",
            "Epoch 1090 : Loss 0.027631403878331184\n",
            "Epoch 1091 : Loss 0.027631331235170364\n",
            "Epoch 1092 : Loss 0.027631253004074097\n",
            "Epoch 1093 : Loss 0.027631180360913277\n",
            "Epoch 1094 : Loss 0.027631105855107307\n",
            "Epoch 1095 : Loss 0.027631031349301338\n",
            "Epoch 1096 : Loss 0.02763095684349537\n",
            "Epoch 1097 : Loss 0.027630886062979698\n",
            "Epoch 1098 : Loss 0.02763081155717373\n",
            "Epoch 1099 : Loss 0.02763073891401291\n",
            "Epoch 1100 : Loss 0.02763066440820694\n",
            "Epoch 1101 : Loss 0.02763058990240097\n",
            "Epoch 1102 : Loss 0.0276305191218853\n",
            "Epoch 1103 : Loss 0.02763044647872448\n",
            "Epoch 1104 : Loss 0.027630381286144257\n",
            "Epoch 1105 : Loss 0.027630308642983437\n",
            "Epoch 1106 : Loss 0.027630239725112915\n",
            "Epoch 1107 : Loss 0.027630163356661797\n",
            "Epoch 1108 : Loss 0.027630092576146126\n",
            "Epoch 1109 : Loss 0.027630021795630455\n",
            "Epoch 1110 : Loss 0.027629952877759933\n",
            "Epoch 1111 : Loss 0.027629883959889412\n",
            "Epoch 1112 : Loss 0.02762981504201889\n",
            "Epoch 1113 : Loss 0.02762974426150322\n",
            "Epoch 1114 : Loss 0.027629675343632698\n",
            "Epoch 1115 : Loss 0.027629606425762177\n",
            "Epoch 1116 : Loss 0.027629537507891655\n",
            "Epoch 1117 : Loss 0.027629470452666283\n",
            "Epoch 1118 : Loss 0.027629399672150612\n",
            "Epoch 1119 : Loss 0.02762933447957039\n",
            "Epoch 1120 : Loss 0.027629265561699867\n",
            "Epoch 1121 : Loss 0.027629198506474495\n",
            "Epoch 1122 : Loss 0.027629133313894272\n",
            "Epoch 1123 : Loss 0.02762906439602375\n",
            "Epoch 1124 : Loss 0.027628997340798378\n",
            "Epoch 1125 : Loss 0.027628932148218155\n",
            "Epoch 1126 : Loss 0.027628865092992783\n",
            "Epoch 1127 : Loss 0.02762879990041256\n",
            "Epoch 1128 : Loss 0.027628734707832336\n",
            "Epoch 1129 : Loss 0.027628669515252113\n",
            "Epoch 1130 : Loss 0.02762860246002674\n",
            "Epoch 1131 : Loss 0.027628537267446518\n",
            "Epoch 1132 : Loss 0.027628473937511444\n",
            "Epoch 1133 : Loss 0.027628406882286072\n",
            "Epoch 1134 : Loss 0.02762834168970585\n",
            "Epoch 1135 : Loss 0.027628280222415924\n",
            "Epoch 1136 : Loss 0.02762821689248085\n",
            "Epoch 1137 : Loss 0.027628151699900627\n",
            "Epoch 1138 : Loss 0.027628088369965553\n",
            "Epoch 1139 : Loss 0.02762802504003048\n",
            "Epoch 1140 : Loss 0.027627959847450256\n",
            "Epoch 1141 : Loss 0.02762789838016033\n",
            "Epoch 1142 : Loss 0.027627838775515556\n",
            "Epoch 1143 : Loss 0.027627775445580482\n",
            "Epoch 1144 : Loss 0.02762771211564541\n",
            "Epoch 1145 : Loss 0.027627650648355484\n",
            "Epoch 1146 : Loss 0.02762759104371071\n",
            "Epoch 1147 : Loss 0.027627529576420784\n",
            "Epoch 1148 : Loss 0.02762746624648571\n",
            "Epoch 1149 : Loss 0.027627404779195786\n",
            "Epoch 1150 : Loss 0.02762734517455101\n",
            "Epoch 1151 : Loss 0.027627285569906235\n",
            "Epoch 1152 : Loss 0.02762722596526146\n",
            "Epoch 1153 : Loss 0.027627162635326385\n",
            "Epoch 1154 : Loss 0.02762710116803646\n",
            "Epoch 1155 : Loss 0.027627043426036835\n",
            "Epoch 1156 : Loss 0.02762698382139206\n",
            "Epoch 1157 : Loss 0.027626924216747284\n",
            "Epoch 1158 : Loss 0.02762686461210251\n",
            "Epoch 1159 : Loss 0.027626806870102882\n",
            "Epoch 1160 : Loss 0.027626747265458107\n",
            "Epoch 1161 : Loss 0.02762668952345848\n",
            "Epoch 1162 : Loss 0.027626631781458855\n",
            "Epoch 1163 : Loss 0.02762657217681408\n",
            "Epoch 1164 : Loss 0.02762651816010475\n",
            "Epoch 1165 : Loss 0.027626458555459976\n",
            "Epoch 1166 : Loss 0.0276264026761055\n",
            "Epoch 1167 : Loss 0.027626344934105873\n",
            "Epoch 1168 : Loss 0.027626285329461098\n",
            "Epoch 1169 : Loss 0.02762622758746147\n",
            "Epoch 1170 : Loss 0.027626173570752144\n",
            "Epoch 1171 : Loss 0.027626115828752518\n",
            "Epoch 1172 : Loss 0.02762606181204319\n",
            "Epoch 1173 : Loss 0.027626004070043564\n",
            "Epoch 1174 : Loss 0.027625951915979385\n",
            "Epoch 1175 : Loss 0.02762589231133461\n",
            "Epoch 1176 : Loss 0.02762584015727043\n",
            "Epoch 1177 : Loss 0.027625784277915955\n",
            "Epoch 1178 : Loss 0.02762572467327118\n",
            "Epoch 1179 : Loss 0.027625672519207\n",
            "Epoch 1180 : Loss 0.027625618502497673\n",
            "Epoch 1181 : Loss 0.027625566348433495\n",
            "Epoch 1182 : Loss 0.02762550860643387\n",
            "Epoch 1183 : Loss 0.02762545645236969\n",
            "Epoch 1184 : Loss 0.027625402435660362\n",
            "Epoch 1185 : Loss 0.027625344693660736\n",
            "Epoch 1186 : Loss 0.027625294402241707\n",
            "Epoch 1187 : Loss 0.02762524038553238\n",
            "Epoch 1188 : Loss 0.0276251882314682\n",
            "Epoch 1189 : Loss 0.027625134214758873\n",
            "Epoch 1190 : Loss 0.027625082060694695\n",
            "Epoch 1191 : Loss 0.027625028043985367\n",
            "Epoch 1192 : Loss 0.027624977752566338\n",
            "Epoch 1193 : Loss 0.02762492559850216\n",
            "Epoch 1194 : Loss 0.02762487344443798\n",
            "Epoch 1195 : Loss 0.02762482315301895\n",
            "Epoch 1196 : Loss 0.027624770998954773\n",
            "Epoch 1197 : Loss 0.027624716982245445\n",
            "Epoch 1198 : Loss 0.027624666690826416\n",
            "Epoch 1199 : Loss 0.027624616399407387\n",
            "Epoch 1200 : Loss 0.02762456238269806\n",
            "Epoch 1201 : Loss 0.02762451581656933\n",
            "Epoch 1202 : Loss 0.02762445993721485\n",
            "Epoch 1203 : Loss 0.02762441709637642\n",
            "Epoch 1204 : Loss 0.02762436307966709\n",
            "Epoch 1205 : Loss 0.027624312788248062\n",
            "Epoch 1206 : Loss 0.02762426622211933\n",
            "Epoch 1207 : Loss 0.027624214068055153\n",
            "Epoch 1208 : Loss 0.027624163776636124\n",
            "Epoch 1209 : Loss 0.027624115347862244\n",
            "Epoch 1210 : Loss 0.027624065056443214\n",
            "Epoch 1211 : Loss 0.027624020352959633\n",
            "Epoch 1212 : Loss 0.027623970061540604\n",
            "Epoch 1213 : Loss 0.027623919770121574\n",
            "Epoch 1214 : Loss 0.027623873203992844\n",
            "Epoch 1215 : Loss 0.027623824775218964\n",
            "Epoch 1216 : Loss 0.027623774483799934\n",
            "Epoch 1217 : Loss 0.027623727917671204\n",
            "Epoch 1218 : Loss 0.027623679488897324\n",
            "Epoch 1219 : Loss 0.027623634785413742\n",
            "Epoch 1220 : Loss 0.027623584493994713\n",
            "Epoch 1221 : Loss 0.027623537927865982\n",
            "Epoch 1222 : Loss 0.027623489499092102\n",
            "Epoch 1223 : Loss 0.02762344293296337\n",
            "Epoch 1224 : Loss 0.02762339636683464\n",
            "Epoch 1225 : Loss 0.02762334793806076\n",
            "Epoch 1226 : Loss 0.02762330323457718\n",
            "Epoch 1227 : Loss 0.027623258531093597\n",
            "Epoch 1228 : Loss 0.027623213827610016\n",
            "Epoch 1229 : Loss 0.027623167261481285\n",
            "Epoch 1230 : Loss 0.027623118832707405\n",
            "Epoch 1231 : Loss 0.027623075991868973\n",
            "Epoch 1232 : Loss 0.027623027563095093\n",
            "Epoch 1233 : Loss 0.02762298285961151\n",
            "Epoch 1234 : Loss 0.02762293629348278\n",
            "Epoch 1235 : Loss 0.0276228915899992\n",
            "Epoch 1236 : Loss 0.027622848749160767\n",
            "Epoch 1237 : Loss 0.027622804045677185\n",
            "Epoch 1238 : Loss 0.027622761204838753\n",
            "Epoch 1239 : Loss 0.02762271650135517\n",
            "Epoch 1240 : Loss 0.02762267366051674\n",
            "Epoch 1241 : Loss 0.02762262523174286\n",
            "Epoch 1242 : Loss 0.027622584253549576\n",
            "Epoch 1243 : Loss 0.027622539550065994\n",
            "Epoch 1244 : Loss 0.027622494846582413\n",
            "Epoch 1245 : Loss 0.02762245200574398\n",
            "Epoch 1246 : Loss 0.027622409164905548\n",
            "Epoch 1247 : Loss 0.027622368186712265\n",
            "Epoch 1248 : Loss 0.027622321620583534\n",
            "Epoch 1249 : Loss 0.02762228436768055\n",
            "Epoch 1250 : Loss 0.02762223780155182\n",
            "Epoch 1251 : Loss 0.027622196823358536\n",
            "Epoch 1252 : Loss 0.027622155845165253\n",
            "Epoch 1253 : Loss 0.02762211114168167\n",
            "Epoch 1254 : Loss 0.027622072026133537\n",
            "Epoch 1255 : Loss 0.027622029185295105\n",
            "Epoch 1256 : Loss 0.027621986344456673\n",
            "Epoch 1257 : Loss 0.02762194350361824\n",
            "Epoch 1258 : Loss 0.027621904388070107\n",
            "Epoch 1259 : Loss 0.027621861547231674\n",
            "Epoch 1260 : Loss 0.02762182056903839\n",
            "Epoch 1261 : Loss 0.027621779590845108\n",
            "Epoch 1262 : Loss 0.027621738612651825\n",
            "Epoch 1263 : Loss 0.02762169949710369\n",
            "Epoch 1264 : Loss 0.027621658518910408\n",
            "Epoch 1265 : Loss 0.027621617540717125\n",
            "Epoch 1266 : Loss 0.02762157842516899\n",
            "Epoch 1267 : Loss 0.027621537446975708\n",
            "Epoch 1268 : Loss 0.027621496468782425\n",
            "Epoch 1269 : Loss 0.02762145735323429\n",
            "Epoch 1270 : Loss 0.027621418237686157\n",
            "Epoch 1271 : Loss 0.027621377259492874\n",
            "Epoch 1272 : Loss 0.02762134186923504\n",
            "Epoch 1273 : Loss 0.027621297165751457\n",
            "Epoch 1274 : Loss 0.027621261775493622\n",
            "Epoch 1275 : Loss 0.027621222659945488\n",
            "Epoch 1276 : Loss 0.027621179819107056\n",
            "Epoch 1277 : Loss 0.02762114256620407\n",
            "Epoch 1278 : Loss 0.027621105313301086\n",
            "Epoch 1279 : Loss 0.027621066197752953\n",
            "Epoch 1280 : Loss 0.027621028944849968\n",
            "Epoch 1281 : Loss 0.027620987966656685\n",
            "Epoch 1282 : Loss 0.02762095257639885\n",
            "Epoch 1283 : Loss 0.027620915323495865\n",
            "Epoch 1284 : Loss 0.02762087807059288\n",
            "Epoch 1285 : Loss 0.027620840817689896\n",
            "Epoch 1286 : Loss 0.027620801702141762\n",
            "Epoch 1287 : Loss 0.027620766311883926\n",
            "Epoch 1288 : Loss 0.027620723471045494\n",
            "Epoch 1289 : Loss 0.027620691806077957\n",
            "Epoch 1290 : Loss 0.027620654553174973\n",
            "Epoch 1291 : Loss 0.027620617300271988\n",
            "Epoch 1292 : Loss 0.027620580047369003\n",
            "Epoch 1293 : Loss 0.02762054279446602\n",
            "Epoch 1294 : Loss 0.027620507404208183\n",
            "Epoch 1295 : Loss 0.027620472013950348\n",
            "Epoch 1296 : Loss 0.027620432898402214\n",
            "Epoch 1297 : Loss 0.027620399370789528\n",
            "Epoch 1298 : Loss 0.027620365843176842\n",
            "Epoch 1299 : Loss 0.027620328590273857\n",
            "Epoch 1300 : Loss 0.02762029506266117\n",
            "Epoch 1301 : Loss 0.027620254084467888\n",
            "Epoch 1302 : Loss 0.0276202205568552\n",
            "Epoch 1303 : Loss 0.027620185166597366\n",
            "Epoch 1304 : Loss 0.02762014977633953\n",
            "Epoch 1305 : Loss 0.027620114386081696\n",
            "Epoch 1306 : Loss 0.02762008085846901\n",
            "Epoch 1307 : Loss 0.027620045468211174\n",
            "Epoch 1308 : Loss 0.02762000821530819\n",
            "Epoch 1309 : Loss 0.027619974687695503\n",
            "Epoch 1310 : Loss 0.027619941160082817\n",
            "Epoch 1311 : Loss 0.02761990763247013\n",
            "Epoch 1312 : Loss 0.027619870379567146\n",
            "Epoch 1313 : Loss 0.02761983871459961\n",
            "Epoch 1314 : Loss 0.027619807049632072\n",
            "Epoch 1315 : Loss 0.027619769796729088\n",
            "Epoch 1316 : Loss 0.02761973813176155\n",
            "Epoch 1317 : Loss 0.027619702741503716\n",
            "Epoch 1318 : Loss 0.02761966735124588\n",
            "Epoch 1319 : Loss 0.027619637548923492\n",
            "Epoch 1320 : Loss 0.027619604021310806\n",
            "Epoch 1321 : Loss 0.02761956863105297\n",
            "Epoch 1322 : Loss 0.027619540691375732\n",
            "Epoch 1323 : Loss 0.027619505301117897\n",
            "Epoch 1324 : Loss 0.02761947177350521\n",
            "Epoch 1325 : Loss 0.027619438245892525\n",
            "Epoch 1326 : Loss 0.027619408443570137\n",
            "Epoch 1327 : Loss 0.02761937491595745\n",
            "Epoch 1328 : Loss 0.027619343250989914\n",
            "Epoch 1329 : Loss 0.027619311586022377\n",
            "Epoch 1330 : Loss 0.02761928178369999\n",
            "Epoch 1331 : Loss 0.027619248256087303\n",
            "Epoch 1332 : Loss 0.027619214728474617\n",
            "Epoch 1333 : Loss 0.02761918492615223\n",
            "Epoch 1334 : Loss 0.027619149535894394\n",
            "Epoch 1335 : Loss 0.027619119733572006\n",
            "Epoch 1336 : Loss 0.027619091793894768\n",
            "Epoch 1337 : Loss 0.02761906012892723\n",
            "Epoch 1338 : Loss 0.027619024738669395\n",
            "Epoch 1339 : Loss 0.027618994936347008\n",
            "Epoch 1340 : Loss 0.02761896513402462\n",
            "Epoch 1341 : Loss 0.027618933469057083\n",
            "Epoch 1342 : Loss 0.027618903666734695\n",
            "Epoch 1343 : Loss 0.027618873864412308\n",
            "Epoch 1344 : Loss 0.02761884033679962\n",
            "Epoch 1345 : Loss 0.027618812397122383\n",
            "Epoch 1346 : Loss 0.027618780732154846\n",
            "Epoch 1347 : Loss 0.02761874906718731\n",
            "Epoch 1348 : Loss 0.02761872299015522\n",
            "Epoch 1349 : Loss 0.027618693187832832\n",
            "Epoch 1350 : Loss 0.027618659660220146\n",
            "Epoch 1351 : Loss 0.02761862985789776\n",
            "Epoch 1352 : Loss 0.02761860005557537\n",
            "Epoch 1353 : Loss 0.027618572115898132\n",
            "Epoch 1354 : Loss 0.027618544176220894\n",
            "Epoch 1355 : Loss 0.027618514373898506\n",
            "Epoch 1356 : Loss 0.027618486434221268\n",
            "Epoch 1357 : Loss 0.02761845476925373\n",
            "Epoch 1358 : Loss 0.027618424966931343\n",
            "Epoch 1359 : Loss 0.027618397027254105\n",
            "Epoch 1360 : Loss 0.027618367224931717\n",
            "Epoch 1361 : Loss 0.02761833928525448\n",
            "Epoch 1362 : Loss 0.02761831320822239\n",
            "Epoch 1363 : Loss 0.027618281543254852\n",
            "Epoch 1364 : Loss 0.027618253603577614\n",
            "Epoch 1365 : Loss 0.027618225663900375\n",
            "Epoch 1366 : Loss 0.027618197724223137\n",
            "Epoch 1367 : Loss 0.027618171647191048\n",
            "Epoch 1368 : Loss 0.02761813998222351\n",
            "Epoch 1369 : Loss 0.02761811390519142\n",
            "Epoch 1370 : Loss 0.027618084102869034\n",
            "Epoch 1371 : Loss 0.027618059888482094\n",
            "Epoch 1372 : Loss 0.027618031948804855\n",
            "Epoch 1373 : Loss 0.027618002146482468\n",
            "Epoch 1374 : Loss 0.02761797606945038\n",
            "Epoch 1375 : Loss 0.02761794626712799\n",
            "Epoch 1376 : Loss 0.027617918327450752\n",
            "Epoch 1377 : Loss 0.027617894113063812\n",
            "Epoch 1378 : Loss 0.027617866173386574\n",
            "Epoch 1379 : Loss 0.027617840096354485\n",
            "Epoch 1380 : Loss 0.027617814019322395\n",
            "Epoch 1381 : Loss 0.02761778235435486\n",
            "Epoch 1382 : Loss 0.027617760002613068\n",
            "Epoch 1383 : Loss 0.027617735788226128\n",
            "Epoch 1384 : Loss 0.02761770598590374\n",
            "Epoch 1385 : Loss 0.02761768363416195\n",
            "Epoch 1386 : Loss 0.02761765755712986\n",
            "Epoch 1387 : Loss 0.027617625892162323\n",
            "Epoch 1388 : Loss 0.027617603540420532\n",
            "Epoch 1389 : Loss 0.027617577463388443\n",
            "Epoch 1390 : Loss 0.027617549523711205\n",
            "Epoch 1391 : Loss 0.027617521584033966\n",
            "Epoch 1392 : Loss 0.027617501094937325\n",
            "Epoch 1393 : Loss 0.027617473155260086\n",
            "Epoch 1394 : Loss 0.027617447078227997\n",
            "Epoch 1395 : Loss 0.027617422863841057\n",
            "Epoch 1396 : Loss 0.027617396786808968\n",
            "Epoch 1397 : Loss 0.027617372572422028\n",
            "Epoch 1398 : Loss 0.02761734649538994\n",
            "Epoch 1399 : Loss 0.02761732041835785\n",
            "Epoch 1400 : Loss 0.02761729806661606\n",
            "Epoch 1401 : Loss 0.02761727198958397\n",
            "Epoch 1402 : Loss 0.02761724777519703\n",
            "Epoch 1403 : Loss 0.02761721983551979\n",
            "Epoch 1404 : Loss 0.02761719934642315\n",
            "Epoch 1405 : Loss 0.02761716954410076\n",
            "Epoch 1406 : Loss 0.02761714532971382\n",
            "Epoch 1407 : Loss 0.02761712670326233\n",
            "Epoch 1408 : Loss 0.02761710062623024\n",
            "Epoch 1409 : Loss 0.0276170764118433\n",
            "Epoch 1410 : Loss 0.02761704847216606\n",
            "Epoch 1411 : Loss 0.02761702798306942\n",
            "Epoch 1412 : Loss 0.02761700376868248\n",
            "Epoch 1413 : Loss 0.02761697955429554\n",
            "Epoch 1414 : Loss 0.0276169553399086\n",
            "Epoch 1415 : Loss 0.02761693298816681\n",
            "Epoch 1416 : Loss 0.02761690691113472\n",
            "Epoch 1417 : Loss 0.02761688455939293\n",
            "Epoch 1418 : Loss 0.027616864070296288\n",
            "Epoch 1419 : Loss 0.027616839855909348\n",
            "Epoch 1420 : Loss 0.027616817504167557\n",
            "Epoch 1421 : Loss 0.027616791427135468\n",
            "Epoch 1422 : Loss 0.027616767212748528\n",
            "Epoch 1423 : Loss 0.027616746723651886\n",
            "Epoch 1424 : Loss 0.027616724371910095\n",
            "Epoch 1425 : Loss 0.027616698294878006\n",
            "Epoch 1426 : Loss 0.027616675943136215\n",
            "Epoch 1427 : Loss 0.027616653591394424\n",
            "Epoch 1428 : Loss 0.027616631239652634\n",
            "Epoch 1429 : Loss 0.027616610750555992\n",
            "Epoch 1430 : Loss 0.027616586536169052\n",
            "Epoch 1431 : Loss 0.02761656418442726\n",
            "Epoch 1432 : Loss 0.02761654183268547\n",
            "Epoch 1433 : Loss 0.02761651761829853\n",
            "Epoch 1434 : Loss 0.02761649899184704\n",
            "Epoch 1435 : Loss 0.027616476640105247\n",
            "Epoch 1436 : Loss 0.027616450563073158\n",
            "Epoch 1437 : Loss 0.027616431936621666\n",
            "Epoch 1438 : Loss 0.027616409584879875\n",
            "Epoch 1439 : Loss 0.027616389095783234\n",
            "Epoch 1440 : Loss 0.027616366744041443\n",
            "Epoch 1441 : Loss 0.027616342529654503\n",
            "Epoch 1442 : Loss 0.02761632204055786\n",
            "Epoch 1443 : Loss 0.02761629968881607\n",
            "Epoch 1444 : Loss 0.02761627547442913\n",
            "Epoch 1445 : Loss 0.027616258710622787\n",
            "Epoch 1446 : Loss 0.027616238221526146\n",
            "Epoch 1447 : Loss 0.027616215869784355\n",
            "Epoch 1448 : Loss 0.027616195380687714\n",
            "Epoch 1449 : Loss 0.027616174891591072\n",
            "Epoch 1450 : Loss 0.02761615626513958\n",
            "Epoch 1451 : Loss 0.02761613391339779\n",
            "Epoch 1452 : Loss 0.027616111561655998\n",
            "Epoch 1453 : Loss 0.027616091072559357\n",
            "Epoch 1454 : Loss 0.027616070583462715\n",
            "Epoch 1455 : Loss 0.027616050094366074\n",
            "Epoch 1456 : Loss 0.027616027742624283\n",
            "Epoch 1457 : Loss 0.02761601097881794\n",
            "Epoch 1458 : Loss 0.02761598862707615\n",
            "Epoch 1459 : Loss 0.027615968137979507\n",
            "Epoch 1460 : Loss 0.027615951374173164\n",
            "Epoch 1461 : Loss 0.027615929022431374\n",
            "Epoch 1462 : Loss 0.02761591039597988\n",
            "Epoch 1463 : Loss 0.027615884318947792\n",
            "Epoch 1464 : Loss 0.027615869417786598\n",
            "Epoch 1465 : Loss 0.027615848928689957\n",
            "Epoch 1466 : Loss 0.027615830302238464\n",
            "Epoch 1467 : Loss 0.027615807950496674\n",
            "Epoch 1468 : Loss 0.02761579118669033\n",
            "Epoch 1469 : Loss 0.02761577069759369\n",
            "Epoch 1470 : Loss 0.027615753933787346\n",
            "Epoch 1471 : Loss 0.027615731582045555\n",
            "Epoch 1472 : Loss 0.027615711092948914\n",
            "Epoch 1473 : Loss 0.02761569246649742\n",
            "Epoch 1474 : Loss 0.02761567384004593\n",
            "Epoch 1475 : Loss 0.027615653350949287\n",
            "Epoch 1476 : Loss 0.027615632861852646\n",
            "Epoch 1477 : Loss 0.027615617960691452\n",
            "Epoch 1478 : Loss 0.02761560119688511\n",
            "Epoch 1479 : Loss 0.027615578845143318\n",
            "Epoch 1480 : Loss 0.027615558356046677\n",
            "Epoch 1481 : Loss 0.027615539729595184\n",
            "Epoch 1482 : Loss 0.02761552296578884\n",
            "Epoch 1483 : Loss 0.02761550061404705\n",
            "Epoch 1484 : Loss 0.027615483850240707\n",
            "Epoch 1485 : Loss 0.027615467086434364\n",
            "Epoch 1486 : Loss 0.027615448459982872\n",
            "Epoch 1487 : Loss 0.02761543169617653\n",
            "Epoch 1488 : Loss 0.027615411207079887\n",
            "Epoch 1489 : Loss 0.027615394443273544\n",
            "Epoch 1490 : Loss 0.0276153776794672\n",
            "Epoch 1491 : Loss 0.02761535719037056\n",
            "Epoch 1492 : Loss 0.027615340426564217\n",
            "Epoch 1493 : Loss 0.027615319937467575\n",
            "Epoch 1494 : Loss 0.027615303173661232\n",
            "Epoch 1495 : Loss 0.02761528454720974\n",
            "Epoch 1496 : Loss 0.027615265920758247\n",
            "Epoch 1497 : Loss 0.027615251019597054\n",
            "Epoch 1498 : Loss 0.02761523425579071\n",
            "Epoch 1499 : Loss 0.027615215629339218\n",
            "Epoch 1500 : Loss 0.027615197002887726\n",
            "Epoch 1501 : Loss 0.027615180239081383\n",
            "Epoch 1502 : Loss 0.02761516347527504\n",
            "Epoch 1503 : Loss 0.027615146711468697\n",
            "Epoch 1504 : Loss 0.027615128085017204\n",
            "Epoch 1505 : Loss 0.02761511318385601\n",
            "Epoch 1506 : Loss 0.02761509083211422\n",
            "Epoch 1507 : Loss 0.027615075930953026\n",
            "Epoch 1508 : Loss 0.027615059167146683\n",
            "Epoch 1509 : Loss 0.02761504240334034\n",
            "Epoch 1510 : Loss 0.027615025639533997\n",
            "Epoch 1511 : Loss 0.027615007013082504\n",
            "Epoch 1512 : Loss 0.02761499583721161\n",
            "Epoch 1513 : Loss 0.027614977210760117\n",
            "Epoch 1514 : Loss 0.027614960446953773\n",
            "Epoch 1515 : Loss 0.02761494368314743\n",
            "Epoch 1516 : Loss 0.027614928781986237\n",
            "Epoch 1517 : Loss 0.027614910155534744\n",
            "Epoch 1518 : Loss 0.02761489525437355\n",
            "Epoch 1519 : Loss 0.027614876627922058\n",
            "Epoch 1520 : Loss 0.027614859864115715\n",
            "Epoch 1521 : Loss 0.027614841237664223\n",
            "Epoch 1522 : Loss 0.02761482633650303\n",
            "Epoch 1523 : Loss 0.027614811435341835\n",
            "Epoch 1524 : Loss 0.02761479653418064\n",
            "Epoch 1525 : Loss 0.027614779770374298\n",
            "Epoch 1526 : Loss 0.027614763006567955\n",
            "Epoch 1527 : Loss 0.02761474996805191\n",
            "Epoch 1528 : Loss 0.027614731341600418\n",
            "Epoch 1529 : Loss 0.027614716440439224\n",
            "Epoch 1530 : Loss 0.02761469967663288\n",
            "Epoch 1531 : Loss 0.027614684775471687\n",
            "Epoch 1532 : Loss 0.027614669874310493\n",
            "Epoch 1533 : Loss 0.02761465311050415\n",
            "Epoch 1534 : Loss 0.027614638209342957\n",
            "Epoch 1535 : Loss 0.027614619582891464\n",
            "Epoch 1536 : Loss 0.02761460468173027\n",
            "Epoch 1537 : Loss 0.027614593505859375\n",
            "Epoch 1538 : Loss 0.027614576742053032\n",
            "Epoch 1539 : Loss 0.027614561840891838\n",
            "Epoch 1540 : Loss 0.027614545077085495\n",
            "Epoch 1541 : Loss 0.0276145301759243\n",
            "Epoch 1542 : Loss 0.027614517137408257\n",
            "Epoch 1543 : Loss 0.027614502236247063\n",
            "Epoch 1544 : Loss 0.02761448360979557\n",
            "Epoch 1545 : Loss 0.027614470571279526\n",
            "Epoch 1546 : Loss 0.027614455670118332\n",
            "Epoch 1547 : Loss 0.027614440768957138\n",
            "Epoch 1548 : Loss 0.027614425867795944\n",
            "Epoch 1549 : Loss 0.02761441469192505\n",
            "Epoch 1550 : Loss 0.027614397928118706\n",
            "Epoch 1551 : Loss 0.027614383026957512\n",
            "Epoch 1552 : Loss 0.027614368125796318\n",
            "Epoch 1553 : Loss 0.027614353224635124\n",
            "Epoch 1554 : Loss 0.02761433832347393\n",
            "Epoch 1555 : Loss 0.027614325284957886\n",
            "Epoch 1556 : Loss 0.027614310383796692\n",
            "Epoch 1557 : Loss 0.027614295482635498\n",
            "Epoch 1558 : Loss 0.027614280581474304\n",
            "Epoch 1559 : Loss 0.02761426754295826\n",
            "Epoch 1560 : Loss 0.027614254504442215\n",
            "Epoch 1561 : Loss 0.027614237740635872\n",
            "Epoch 1562 : Loss 0.027614222839474678\n",
            "Epoch 1563 : Loss 0.027614207938313484\n",
            "Epoch 1564 : Loss 0.02761419676244259\n",
            "Epoch 1565 : Loss 0.027614183723926544\n",
            "Epoch 1566 : Loss 0.02761417254805565\n",
            "Epoch 1567 : Loss 0.027614157646894455\n",
            "Epoch 1568 : Loss 0.02761414274573326\n",
            "Epoch 1569 : Loss 0.027614127844572067\n",
            "Epoch 1570 : Loss 0.027614112943410873\n",
            "Epoch 1571 : Loss 0.02761409990489483\n",
            "Epoch 1572 : Loss 0.027614088729023933\n",
            "Epoch 1573 : Loss 0.02761407382786274\n",
            "Epoch 1574 : Loss 0.027614057064056396\n",
            "Epoch 1575 : Loss 0.027614044025540352\n",
            "Epoch 1576 : Loss 0.027614032849669456\n",
            "Epoch 1577 : Loss 0.02761402167379856\n",
            "Epoch 1578 : Loss 0.027614008635282516\n",
            "Epoch 1579 : Loss 0.027613991871476173\n",
            "Epoch 1580 : Loss 0.02761397883296013\n",
            "Epoch 1581 : Loss 0.027613967657089233\n",
            "Epoch 1582 : Loss 0.02761395275592804\n",
            "Epoch 1583 : Loss 0.027613939717411995\n",
            "Epoch 1584 : Loss 0.0276139285415411\n",
            "Epoch 1585 : Loss 0.027613913640379906\n",
            "Epoch 1586 : Loss 0.02761390246450901\n",
            "Epoch 1587 : Loss 0.027613887563347816\n",
            "Epoch 1588 : Loss 0.02761387638747692\n",
            "Epoch 1589 : Loss 0.027613865211606026\n",
            "Epoch 1590 : Loss 0.02761385403573513\n",
            "Epoch 1591 : Loss 0.027613837271928787\n",
            "Epoch 1592 : Loss 0.027613826096057892\n",
            "Epoch 1593 : Loss 0.027613813057541847\n",
            "Epoch 1594 : Loss 0.027613801881670952\n",
            "Epoch 1595 : Loss 0.027613790705800056\n",
            "Epoch 1596 : Loss 0.027613777667284012\n",
            "Epoch 1597 : Loss 0.027613764628767967\n",
            "Epoch 1598 : Loss 0.027613749727606773\n",
            "Epoch 1599 : Loss 0.02761373668909073\n",
            "Epoch 1600 : Loss 0.027613723650574684\n",
            "Epoch 1601 : Loss 0.027613714337348938\n",
            "Epoch 1602 : Loss 0.027613701298832893\n",
            "Epoch 1603 : Loss 0.027613690122961998\n",
            "Epoch 1604 : Loss 0.027613677084445953\n",
            "Epoch 1605 : Loss 0.027613665908575058\n",
            "Epoch 1606 : Loss 0.027613652870059013\n",
            "Epoch 1607 : Loss 0.027613641694188118\n",
            "Epoch 1608 : Loss 0.027613632380962372\n",
            "Epoch 1609 : Loss 0.027613619342446327\n",
            "Epoch 1610 : Loss 0.027613608166575432\n",
            "Epoch 1611 : Loss 0.027613593265414238\n",
            "Epoch 1612 : Loss 0.027613582089543343\n",
            "Epoch 1613 : Loss 0.027613570913672447\n",
            "Epoch 1614 : Loss 0.027613559737801552\n",
            "Epoch 1615 : Loss 0.027613548561930656\n",
            "Epoch 1616 : Loss 0.027613535523414612\n",
            "Epoch 1617 : Loss 0.027613526210188866\n",
            "Epoch 1618 : Loss 0.027613511309027672\n",
            "Epoch 1619 : Loss 0.027613501995801926\n",
            "Epoch 1620 : Loss 0.02761349081993103\n",
            "Epoch 1621 : Loss 0.027613477781414986\n",
            "Epoch 1622 : Loss 0.02761346660554409\n",
            "Epoch 1623 : Loss 0.027613455429673195\n",
            "Epoch 1624 : Loss 0.0276134442538023\n",
            "Epoch 1625 : Loss 0.027613433077931404\n",
            "Epoch 1626 : Loss 0.02761342003941536\n",
            "Epoch 1627 : Loss 0.027613408863544464\n",
            "Epoch 1628 : Loss 0.027613399550318718\n",
            "Epoch 1629 : Loss 0.02761339209973812\n",
            "Epoch 1630 : Loss 0.027613380923867226\n",
            "Epoch 1631 : Loss 0.02761336974799633\n",
            "Epoch 1632 : Loss 0.027613352984189987\n",
            "Epoch 1633 : Loss 0.02761334553360939\n",
            "Epoch 1634 : Loss 0.027613334357738495\n",
            "Epoch 1635 : Loss 0.0276133231818676\n",
            "Epoch 1636 : Loss 0.027613315731287003\n",
            "Epoch 1637 : Loss 0.027613304555416107\n",
            "Epoch 1638 : Loss 0.027613289654254913\n",
            "Epoch 1639 : Loss 0.027613280341029167\n",
            "Epoch 1640 : Loss 0.02761327102780342\n",
            "Epoch 1641 : Loss 0.027613257989287376\n",
            "Epoch 1642 : Loss 0.02761325053870678\n",
            "Epoch 1643 : Loss 0.027613237500190735\n",
            "Epoch 1644 : Loss 0.02761322818696499\n",
            "Epoch 1645 : Loss 0.027613217011094093\n",
            "Epoch 1646 : Loss 0.027613207697868347\n",
            "Epoch 1647 : Loss 0.027613194659352303\n",
            "Epoch 1648 : Loss 0.027613185346126556\n",
            "Epoch 1649 : Loss 0.02761317789554596\n",
            "Epoch 1650 : Loss 0.027613164857029915\n",
            "Epoch 1651 : Loss 0.027613157406449318\n",
            "Epoch 1652 : Loss 0.027613142505288124\n",
            "Epoch 1653 : Loss 0.027613133192062378\n",
            "Epoch 1654 : Loss 0.02761312574148178\n",
            "Epoch 1655 : Loss 0.027613112702965736\n",
            "Epoch 1656 : Loss 0.02761310525238514\n",
            "Epoch 1657 : Loss 0.027613094076514244\n",
            "Epoch 1658 : Loss 0.02761308290064335\n",
            "Epoch 1659 : Loss 0.027613073587417603\n",
            "Epoch 1660 : Loss 0.027613064274191856\n",
            "Epoch 1661 : Loss 0.02761305682361126\n",
            "Epoch 1662 : Loss 0.027613045647740364\n",
            "Epoch 1663 : Loss 0.027613036334514618\n",
            "Epoch 1664 : Loss 0.027613027021288872\n",
            "Epoch 1665 : Loss 0.027613017708063126\n",
            "Epoch 1666 : Loss 0.02761300839483738\n",
            "Epoch 1667 : Loss 0.027612997218966484\n",
            "Epoch 1668 : Loss 0.02761298604309559\n",
            "Epoch 1669 : Loss 0.027612978592514992\n",
            "Epoch 1670 : Loss 0.027612969279289246\n",
            "Epoch 1671 : Loss 0.0276129562407732\n",
            "Epoch 1672 : Loss 0.027612948790192604\n",
            "Epoch 1673 : Loss 0.02761293761432171\n",
            "Epoch 1674 : Loss 0.027612930163741112\n",
            "Epoch 1675 : Loss 0.027612920850515366\n",
            "Epoch 1676 : Loss 0.02761291339993477\n",
            "Epoch 1677 : Loss 0.027612900361418724\n",
            "Epoch 1678 : Loss 0.02761288918554783\n",
            "Epoch 1679 : Loss 0.027612881734967232\n",
            "Epoch 1680 : Loss 0.027612874284386635\n",
            "Epoch 1681 : Loss 0.02761286310851574\n",
            "Epoch 1682 : Loss 0.027612857520580292\n",
            "Epoch 1683 : Loss 0.027612846344709396\n",
            "Epoch 1684 : Loss 0.02761283703148365\n",
            "Epoch 1685 : Loss 0.027612827718257904\n",
            "Epoch 1686 : Loss 0.027612820267677307\n",
            "Epoch 1687 : Loss 0.027612809091806412\n",
            "Epoch 1688 : Loss 0.027612799778580666\n",
            "Epoch 1689 : Loss 0.02761279046535492\n",
            "Epoch 1690 : Loss 0.027612783014774323\n",
            "Epoch 1691 : Loss 0.027612773701548576\n",
            "Epoch 1692 : Loss 0.02761276625096798\n",
            "Epoch 1693 : Loss 0.027612756937742233\n",
            "Epoch 1694 : Loss 0.027612747624516487\n",
            "Epoch 1695 : Loss 0.027612736448645592\n",
            "Epoch 1696 : Loss 0.027612730860710144\n",
            "Epoch 1697 : Loss 0.0276127178221941\n",
            "Epoch 1698 : Loss 0.02761271223425865\n",
            "Epoch 1699 : Loss 0.027612701058387756\n",
            "Epoch 1700 : Loss 0.02761269547045231\n",
            "Epoch 1701 : Loss 0.027612686157226562\n",
            "Epoch 1702 : Loss 0.027612678706645966\n",
            "Epoch 1703 : Loss 0.02761267125606537\n",
            "Epoch 1704 : Loss 0.027612660080194473\n",
            "Epoch 1705 : Loss 0.027612654492259026\n",
            "Epoch 1706 : Loss 0.02761264331638813\n",
            "Epoch 1707 : Loss 0.027612634003162384\n",
            "Epoch 1708 : Loss 0.027612628415226936\n",
            "Epoch 1709 : Loss 0.02761261910200119\n",
            "Epoch 1710 : Loss 0.027612611651420593\n",
            "Epoch 1711 : Loss 0.027612600475549698\n",
            "Epoch 1712 : Loss 0.02761259488761425\n",
            "Epoch 1713 : Loss 0.027612585574388504\n",
            "Epoch 1714 : Loss 0.027612578123807907\n",
            "Epoch 1715 : Loss 0.02761256881058216\n",
            "Epoch 1716 : Loss 0.027612561360001564\n",
            "Epoch 1717 : Loss 0.027612555772066116\n",
            "Epoch 1718 : Loss 0.02761254459619522\n",
            "Epoch 1719 : Loss 0.027612535282969475\n",
            "Epoch 1720 : Loss 0.027612529695034027\n",
            "Epoch 1721 : Loss 0.02761252224445343\n",
            "Epoch 1722 : Loss 0.027612516656517982\n",
            "Epoch 1723 : Loss 0.027612507343292236\n",
            "Epoch 1724 : Loss 0.02761249989271164\n",
            "Epoch 1725 : Loss 0.027612492442131042\n",
            "Epoch 1726 : Loss 0.027612483128905296\n",
            "Epoch 1727 : Loss 0.02761247381567955\n",
            "Epoch 1728 : Loss 0.027612466365098953\n",
            "Epoch 1729 : Loss 0.027612460777163506\n",
            "Epoch 1730 : Loss 0.02761245146393776\n",
            "Epoch 1731 : Loss 0.027612442150712013\n",
            "Epoch 1732 : Loss 0.027612438425421715\n",
            "Epoch 1733 : Loss 0.02761242724955082\n",
            "Epoch 1734 : Loss 0.02761242352426052\n",
            "Epoch 1735 : Loss 0.027612414211034775\n",
            "Epoch 1736 : Loss 0.027612406760454178\n",
            "Epoch 1737 : Loss 0.02761239744722843\n",
            "Epoch 1738 : Loss 0.027612389996647835\n",
            "Epoch 1739 : Loss 0.02761238068342209\n",
            "Epoch 1740 : Loss 0.02761237509548664\n",
            "Epoch 1741 : Loss 0.027612369507551193\n",
            "Epoch 1742 : Loss 0.027612360194325447\n",
            "Epoch 1743 : Loss 0.02761235274374485\n",
            "Epoch 1744 : Loss 0.027612347155809402\n",
            "Epoch 1745 : Loss 0.027612337842583656\n",
            "Epoch 1746 : Loss 0.02761233225464821\n",
            "Epoch 1747 : Loss 0.027612322941422462\n",
            "Epoch 1748 : Loss 0.027612315490841866\n",
            "Epoch 1749 : Loss 0.02761230804026127\n",
            "Epoch 1750 : Loss 0.02761230245232582\n",
            "Epoch 1751 : Loss 0.027612293139100075\n",
            "Epoch 1752 : Loss 0.027612287551164627\n",
            "Epoch 1753 : Loss 0.02761228010058403\n",
            "Epoch 1754 : Loss 0.027612272650003433\n",
            "Epoch 1755 : Loss 0.027612267062067986\n",
            "Epoch 1756 : Loss 0.02761225961148739\n",
            "Epoch 1757 : Loss 0.02761225402355194\n",
            "Epoch 1758 : Loss 0.027612244710326195\n",
            "Epoch 1759 : Loss 0.027612239122390747\n",
            "Epoch 1760 : Loss 0.02761223167181015\n",
            "Epoch 1761 : Loss 0.027612224221229553\n",
            "Epoch 1762 : Loss 0.027612216770648956\n",
            "Epoch 1763 : Loss 0.02761220932006836\n",
            "Epoch 1764 : Loss 0.02761220559477806\n",
            "Epoch 1765 : Loss 0.027612198144197464\n",
            "Epoch 1766 : Loss 0.027612190693616867\n",
            "Epoch 1767 : Loss 0.02761218696832657\n",
            "Epoch 1768 : Loss 0.027612175792455673\n",
            "Epoch 1769 : Loss 0.027612172067165375\n",
            "Epoch 1770 : Loss 0.02761216089129448\n",
            "Epoch 1771 : Loss 0.02761215716600418\n",
            "Epoch 1772 : Loss 0.027612147852778435\n",
            "Epoch 1773 : Loss 0.027612144127488136\n",
            "Epoch 1774 : Loss 0.02761213481426239\n",
            "Epoch 1775 : Loss 0.027612129226326942\n",
            "Epoch 1776 : Loss 0.027612121775746346\n",
            "Epoch 1777 : Loss 0.02761211432516575\n",
            "Epoch 1778 : Loss 0.0276121124625206\n",
            "Epoch 1779 : Loss 0.027612105011940002\n",
            "Epoch 1780 : Loss 0.027612097561359406\n",
            "Epoch 1781 : Loss 0.027612091973423958\n",
            "Epoch 1782 : Loss 0.02761208266019821\n",
            "Epoch 1783 : Loss 0.027612075209617615\n",
            "Epoch 1784 : Loss 0.027612071484327316\n",
            "Epoch 1785 : Loss 0.02761206403374672\n",
            "Epoch 1786 : Loss 0.02761206030845642\n",
            "Epoch 1787 : Loss 0.027612052857875824\n",
            "Epoch 1788 : Loss 0.027612045407295227\n",
            "Epoch 1789 : Loss 0.02761204168200493\n",
            "Epoch 1790 : Loss 0.02761203423142433\n",
            "Epoch 1791 : Loss 0.027612028643488884\n",
            "Epoch 1792 : Loss 0.027612023055553436\n",
            "Epoch 1793 : Loss 0.027612021192908287\n",
            "Epoch 1794 : Loss 0.027612008154392242\n",
            "Epoch 1795 : Loss 0.027612000703811646\n",
            "Epoch 1796 : Loss 0.027611996978521347\n",
            "Epoch 1797 : Loss 0.0276119913905859\n",
            "Epoch 1798 : Loss 0.02761198580265045\n",
            "Epoch 1799 : Loss 0.027611980214715004\n",
            "Epoch 1800 : Loss 0.027611972764134407\n",
            "Epoch 1801 : Loss 0.02761196531355381\n",
            "Epoch 1802 : Loss 0.02761196158826351\n",
            "Epoch 1803 : Loss 0.027611954137682915\n",
            "Epoch 1804 : Loss 0.027611946687102318\n",
            "Epoch 1805 : Loss 0.02761194296181202\n",
            "Epoch 1806 : Loss 0.02761193923652172\n",
            "Epoch 1807 : Loss 0.027611929923295975\n",
            "Epoch 1808 : Loss 0.027611924335360527\n",
            "Epoch 1809 : Loss 0.02761191874742508\n",
            "Epoch 1810 : Loss 0.02761191502213478\n",
            "Epoch 1811 : Loss 0.027611909434199333\n",
            "Epoch 1812 : Loss 0.027611901983618736\n",
            "Epoch 1813 : Loss 0.027611898258328438\n",
            "Epoch 1814 : Loss 0.02761188894510269\n",
            "Epoch 1815 : Loss 0.027611885219812393\n",
            "Epoch 1816 : Loss 0.027611877769231796\n",
            "Epoch 1817 : Loss 0.027611874043941498\n",
            "Epoch 1818 : Loss 0.02761186845600605\n",
            "Epoch 1819 : Loss 0.02761186473071575\n",
            "Epoch 1820 : Loss 0.027611859142780304\n",
            "Epoch 1821 : Loss 0.027611855417490005\n",
            "Epoch 1822 : Loss 0.02761184424161911\n",
            "Epoch 1823 : Loss 0.027611838653683662\n",
            "Epoch 1824 : Loss 0.027611833065748215\n",
            "Epoch 1825 : Loss 0.027611831203103065\n",
            "Epoch 1826 : Loss 0.027611825615167618\n",
            "Epoch 1827 : Loss 0.02761181630194187\n",
            "Epoch 1828 : Loss 0.027611812576651573\n",
            "Epoch 1829 : Loss 0.027611808851361275\n",
            "Epoch 1830 : Loss 0.027611803263425827\n",
            "Epoch 1831 : Loss 0.02761179581284523\n",
            "Epoch 1832 : Loss 0.027611790224909782\n",
            "Epoch 1833 : Loss 0.027611786499619484\n",
            "Epoch 1834 : Loss 0.027611780911684036\n",
            "Epoch 1835 : Loss 0.027611779049038887\n",
            "Epoch 1836 : Loss 0.02761176973581314\n",
            "Epoch 1837 : Loss 0.027611764147877693\n",
            "Epoch 1838 : Loss 0.027611758559942245\n",
            "Epoch 1839 : Loss 0.027611752972006798\n",
            "Epoch 1840 : Loss 0.02761174738407135\n",
            "Epoch 1841 : Loss 0.02761174365878105\n",
            "Epoch 1842 : Loss 0.027611739933490753\n",
            "Epoch 1843 : Loss 0.027611732482910156\n",
            "Epoch 1844 : Loss 0.027611728757619858\n",
            "Epoch 1845 : Loss 0.02761172503232956\n",
            "Epoch 1846 : Loss 0.02761171944439411\n",
            "Epoch 1847 : Loss 0.027611713856458664\n",
            "Epoch 1848 : Loss 0.027611710131168365\n",
            "Epoch 1849 : Loss 0.02761170268058777\n",
            "Epoch 1850 : Loss 0.02761169895529747\n",
            "Epoch 1851 : Loss 0.027611691504716873\n",
            "Epoch 1852 : Loss 0.027611685916781425\n",
            "Epoch 1853 : Loss 0.027611682191491127\n",
            "Epoch 1854 : Loss 0.02761167660355568\n",
            "Epoch 1855 : Loss 0.02761167101562023\n",
            "Epoch 1856 : Loss 0.027611665427684784\n",
            "Epoch 1857 : Loss 0.027611661702394485\n",
            "Epoch 1858 : Loss 0.027611657977104187\n",
            "Epoch 1859 : Loss 0.02761165052652359\n",
            "Epoch 1860 : Loss 0.02761164866387844\n",
            "Epoch 1861 : Loss 0.027611643075942993\n",
            "Epoch 1862 : Loss 0.027611639350652695\n",
            "Epoch 1863 : Loss 0.027611637488007545\n",
            "Epoch 1864 : Loss 0.0276116281747818\n",
            "Epoch 1865 : Loss 0.02761162631213665\n",
            "Epoch 1866 : Loss 0.027611620724201202\n",
            "Epoch 1867 : Loss 0.027611615136265755\n",
            "Epoch 1868 : Loss 0.027611611410975456\n",
            "Epoch 1869 : Loss 0.02761160209774971\n",
            "Epoch 1870 : Loss 0.02761160023510456\n",
            "Epoch 1871 : Loss 0.027611592784523964\n",
            "Epoch 1872 : Loss 0.027611590921878815\n",
            "Epoch 1873 : Loss 0.027611587196588516\n",
            "Epoch 1874 : Loss 0.02761157974600792\n",
            "Epoch 1875 : Loss 0.02761157602071762\n",
            "Epoch 1876 : Loss 0.027611572295427322\n",
            "Epoch 1877 : Loss 0.027611570432782173\n",
            "Epoch 1878 : Loss 0.027611562982201576\n",
            "Epoch 1879 : Loss 0.027611559256911278\n",
            "Epoch 1880 : Loss 0.02761155366897583\n",
            "Epoch 1881 : Loss 0.02761155180633068\n",
            "Epoch 1882 : Loss 0.027611546218395233\n",
            "Epoch 1883 : Loss 0.027611542493104935\n",
            "Epoch 1884 : Loss 0.027611536905169487\n",
            "Epoch 1885 : Loss 0.02761153131723404\n",
            "Epoch 1886 : Loss 0.02761152572929859\n",
            "Epoch 1887 : Loss 0.027611522004008293\n",
            "Epoch 1888 : Loss 0.027611518278717995\n",
            "Epoch 1889 : Loss 0.027611512690782547\n",
            "Epoch 1890 : Loss 0.02761150896549225\n",
            "Epoch 1891 : Loss 0.0276115033775568\n",
            "Epoch 1892 : Loss 0.02761150151491165\n",
            "Epoch 1893 : Loss 0.027611495926976204\n",
            "Epoch 1894 : Loss 0.027611492201685905\n",
            "Epoch 1895 : Loss 0.027611488476395607\n",
            "Epoch 1896 : Loss 0.02761148475110531\n",
            "Epoch 1897 : Loss 0.02761147916316986\n",
            "Epoch 1898 : Loss 0.027611475437879562\n",
            "Epoch 1899 : Loss 0.027611469849944115\n",
            "Epoch 1900 : Loss 0.027611466124653816\n",
            "Epoch 1901 : Loss 0.027611462399363518\n",
            "Epoch 1902 : Loss 0.02761145867407322\n",
            "Epoch 1903 : Loss 0.02761145308613777\n",
            "Epoch 1904 : Loss 0.027611449360847473\n",
            "Epoch 1905 : Loss 0.027611445635557175\n",
            "Epoch 1906 : Loss 0.027611441910266876\n",
            "Epoch 1907 : Loss 0.02761143632233143\n",
            "Epoch 1908 : Loss 0.02761143445968628\n",
            "Epoch 1909 : Loss 0.02761143073439598\n",
            "Epoch 1910 : Loss 0.027611427009105682\n",
            "Epoch 1911 : Loss 0.027611421421170235\n",
            "Epoch 1912 : Loss 0.027611417695879936\n",
            "Epoch 1913 : Loss 0.027611413970589638\n",
            "Epoch 1914 : Loss 0.02761140838265419\n",
            "Epoch 1915 : Loss 0.02761140465736389\n",
            "Epoch 1916 : Loss 0.027611399069428444\n",
            "Epoch 1917 : Loss 0.027611397206783295\n",
            "Epoch 1918 : Loss 0.027611393481492996\n",
            "Epoch 1919 : Loss 0.02761138789355755\n",
            "Epoch 1920 : Loss 0.0276113860309124\n",
            "Epoch 1921 : Loss 0.0276113823056221\n",
            "Epoch 1922 : Loss 0.027611378580331802\n",
            "Epoch 1923 : Loss 0.027611372992396355\n",
            "Epoch 1924 : Loss 0.027611367404460907\n",
            "Epoch 1925 : Loss 0.027611365541815758\n",
            "Epoch 1926 : Loss 0.02761136367917061\n",
            "Epoch 1927 : Loss 0.02761135809123516\n",
            "Epoch 1928 : Loss 0.027611354365944862\n",
            "Epoch 1929 : Loss 0.027611348778009415\n",
            "Epoch 1930 : Loss 0.027611345052719116\n",
            "Epoch 1931 : Loss 0.027611341327428818\n",
            "Epoch 1932 : Loss 0.02761133946478367\n",
            "Epoch 1933 : Loss 0.02761133387684822\n",
            "Epoch 1934 : Loss 0.027611330151557922\n",
            "Epoch 1935 : Loss 0.027611326426267624\n",
            "Epoch 1936 : Loss 0.027611324563622475\n",
            "Epoch 1937 : Loss 0.027611318975687027\n",
            "Epoch 1938 : Loss 0.027611317113041878\n",
            "Epoch 1939 : Loss 0.02761131525039673\n",
            "Epoch 1940 : Loss 0.02761130966246128\n",
            "Epoch 1941 : Loss 0.02761130966246128\n",
            "Epoch 1942 : Loss 0.027611302211880684\n",
            "Epoch 1943 : Loss 0.027611298486590385\n",
            "Epoch 1944 : Loss 0.027611296623945236\n",
            "Epoch 1945 : Loss 0.02761129103600979\n",
            "Epoch 1946 : Loss 0.02761128731071949\n",
            "Epoch 1947 : Loss 0.027611281722784042\n",
            "Epoch 1948 : Loss 0.027611277997493744\n",
            "Epoch 1949 : Loss 0.027611277997493744\n",
            "Epoch 1950 : Loss 0.027611274272203445\n",
            "Epoch 1951 : Loss 0.02761126682162285\n",
            "Epoch 1952 : Loss 0.02761126682162285\n",
            "Epoch 1953 : Loss 0.02761126309633255\n",
            "Epoch 1954 : Loss 0.02761125937104225\n",
            "Epoch 1955 : Loss 0.027611255645751953\n",
            "Epoch 1956 : Loss 0.027611251920461655\n",
            "Epoch 1957 : Loss 0.027611250057816505\n",
            "Epoch 1958 : Loss 0.027611246332526207\n",
            "Epoch 1959 : Loss 0.027611244469881058\n",
            "Epoch 1960 : Loss 0.02761124074459076\n",
            "Epoch 1961 : Loss 0.02761123701930046\n",
            "Epoch 1962 : Loss 0.027611233294010162\n",
            "Epoch 1963 : Loss 0.027611225843429565\n",
            "Epoch 1964 : Loss 0.027611227706074715\n",
            "Epoch 1965 : Loss 0.027611223980784416\n",
            "Epoch 1966 : Loss 0.02761121839284897\n",
            "Epoch 1967 : Loss 0.02761121466755867\n",
            "Epoch 1968 : Loss 0.027611209079623222\n",
            "Epoch 1969 : Loss 0.027611209079623222\n",
            "Epoch 1970 : Loss 0.027611203491687775\n",
            "Epoch 1971 : Loss 0.027611199766397476\n",
            "Epoch 1972 : Loss 0.027611197903752327\n",
            "Epoch 1973 : Loss 0.027611196041107178\n",
            "Epoch 1974 : Loss 0.02761119231581688\n",
            "Epoch 1975 : Loss 0.02761118859052658\n",
            "Epoch 1976 : Loss 0.027611184865236282\n",
            "Epoch 1977 : Loss 0.027611183002591133\n",
            "Epoch 1978 : Loss 0.027611177414655685\n",
            "Epoch 1979 : Loss 0.027611179277300835\n",
            "Epoch 1980 : Loss 0.027611175552010536\n",
            "Epoch 1981 : Loss 0.02761116810142994\n",
            "Epoch 1982 : Loss 0.02761116996407509\n",
            "Epoch 1983 : Loss 0.02761116437613964\n",
            "Epoch 1984 : Loss 0.02761116437613964\n",
            "Epoch 1985 : Loss 0.027611156925559044\n",
            "Epoch 1986 : Loss 0.027611153200268745\n",
            "Epoch 1987 : Loss 0.027611153200268745\n",
            "Epoch 1988 : Loss 0.027611149474978447\n",
            "Epoch 1989 : Loss 0.027611143887043\n",
            "Epoch 1990 : Loss 0.02761114202439785\n",
            "Epoch 1991 : Loss 0.0276111401617527\n",
            "Epoch 1992 : Loss 0.027611134573817253\n",
            "Epoch 1993 : Loss 0.027611130848526955\n",
            "Epoch 1994 : Loss 0.027611128985881805\n",
            "Epoch 1995 : Loss 0.027611123397946358\n",
            "Epoch 1996 : Loss 0.027611125260591507\n",
            "Epoch 1997 : Loss 0.02761111967265606\n",
            "Epoch 1998 : Loss 0.02761112153530121\n",
            "Epoch 1999 : Loss 0.027611112222075462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB4pxLvQxbqt",
        "outputId": "baede576-c735-4794-e3a0-29579f64999e"
      },
      "source": [
        "\n",
        "def generate_data(n=2000):\n",
        "    x = np.random.uniform(-math.pi,math.pi, n)\n",
        "    noise = np.random.normal(0, 0.15, n)\n",
        "    y = np.sin(x) + noise\n",
        "    return x.astype(np.float32), y.astype(np.float32)\n",
        "\n",
        "x, y = generate_data()\n",
        "\n",
        "x = torch.from_numpy(x.reshape(-1, 1))\n",
        "y = torch.from_numpy(y.reshape(-1, 1))\n",
        "\n",
        "\n",
        "def squared_error(y_pred, y_true):\n",
        "    return torch.mean(torch.square(y_pred - y_true))\n",
        "\n",
        "\n",
        "torch_model = LinearRegressionPyTorch()\n",
        "\n",
        "criterion = torch.nn.MSELoss(reduction='mean')\n",
        "optimizer = torch.optim.SGD(torch_model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(2000):\n",
        "    y_pred = torch_model(x)\n",
        "    loss = squared_error(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "      print(f\"Epoch {epoch} : Loss {loss.data}\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 : Loss 15.971563339233398\n",
            "Epoch 20 : Loss 0.7981100678443909\n",
            "Epoch 40 : Loss 0.35374152660369873\n",
            "Epoch 60 : Loss 0.3150010406970978\n",
            "Epoch 80 : Loss 0.293123334646225\n",
            "Epoch 100 : Loss 0.27340078353881836\n",
            "Epoch 120 : Loss 0.25516727566719055\n",
            "Epoch 140 : Loss 0.23829202353954315\n",
            "Epoch 160 : Loss 0.22267252206802368\n",
            "Epoch 180 : Loss 0.20821437239646912\n",
            "Epoch 200 : Loss 0.19483056664466858\n",
            "Epoch 220 : Loss 0.1824406385421753\n",
            "Epoch 240 : Loss 0.17097017168998718\n",
            "Epoch 260 : Loss 0.16035035252571106\n",
            "Epoch 280 : Loss 0.15051761269569397\n",
            "Epoch 300 : Loss 0.1414131373167038\n",
            "Epoch 320 : Loss 0.13298246264457703\n",
            "Epoch 340 : Loss 0.12517531216144562\n",
            "Epoch 360 : Loss 0.11794523894786835\n",
            "Epoch 380 : Loss 0.11124922335147858\n",
            "Epoch 400 : Loss 0.10504744201898575\n",
            "Epoch 420 : Loss 0.09930315613746643\n",
            "Epoch 440 : Loss 0.09398232400417328\n",
            "Epoch 460 : Loss 0.0890534520149231\n",
            "Epoch 480 : Loss 0.08448739349842072\n",
            "Epoch 500 : Loss 0.08025719970464706\n",
            "Epoch 520 : Loss 0.0763380229473114\n",
            "Epoch 540 : Loss 0.07270678877830505\n",
            "Epoch 560 : Loss 0.06934207677841187\n",
            "Epoch 580 : Loss 0.06622426211833954\n",
            "Epoch 600 : Loss 0.06333502382040024\n",
            "Epoch 620 : Loss 0.060657452791929245\n",
            "Epoch 640 : Loss 0.058175940066576004\n",
            "Epoch 660 : Loss 0.05587593838572502\n",
            "Epoch 680 : Loss 0.0537441112101078\n",
            "Epoch 700 : Loss 0.05176803097128868\n",
            "Epoch 720 : Loss 0.04993623495101929\n",
            "Epoch 740 : Loss 0.04823807626962662\n",
            "Epoch 760 : Loss 0.046663738787174225\n",
            "Epoch 780 : Loss 0.04520411789417267\n",
            "Epoch 800 : Loss 0.043850772082805634\n",
            "Epoch 820 : Loss 0.04259589686989784\n",
            "Epoch 840 : Loss 0.04143225774168968\n",
            "Epoch 860 : Loss 0.04035316780209541\n",
            "Epoch 880 : Loss 0.039352431893348694\n",
            "Epoch 900 : Loss 0.038424305617809296\n",
            "Epoch 920 : Loss 0.037563469260931015\n",
            "Epoch 940 : Loss 0.036765001714229584\n",
            "Epoch 960 : Loss 0.036024369299411774\n",
            "Epoch 980 : Loss 0.035337306559085846\n",
            "Epoch 1000 : Loss 0.0346999354660511\n",
            "Epoch 1020 : Loss 0.03410862013697624\n",
            "Epoch 1040 : Loss 0.03355999290943146\n",
            "Epoch 1060 : Loss 0.03305096551775932\n",
            "Epoch 1080 : Loss 0.032578643411397934\n",
            "Epoch 1100 : Loss 0.03214035555720329\n",
            "Epoch 1120 : Loss 0.031733639538288116\n",
            "Epoch 1140 : Loss 0.03135617449879646\n",
            "Epoch 1160 : Loss 0.0310058556497097\n",
            "Epoch 1180 : Loss 0.030680708587169647\n",
            "Epoch 1200 : Loss 0.0303789172321558\n",
            "Epoch 1220 : Loss 0.03009878471493721\n",
            "Epoch 1240 : Loss 0.029838740825653076\n",
            "Epoch 1260 : Loss 0.029597345739603043\n",
            "Epoch 1280 : Loss 0.029373224824666977\n",
            "Epoch 1300 : Loss 0.029165145009756088\n",
            "Epoch 1320 : Loss 0.028971955180168152\n",
            "Epoch 1340 : Loss 0.028792571276426315\n",
            "Epoch 1360 : Loss 0.02862599864602089\n",
            "Epoch 1380 : Loss 0.028471320867538452\n",
            "Epoch 1400 : Loss 0.02832767367362976\n",
            "Epoch 1420 : Loss 0.02819426730275154\n",
            "Epoch 1440 : Loss 0.028070366010069847\n",
            "Epoch 1460 : Loss 0.02795528620481491\n",
            "Epoch 1480 : Loss 0.027848388999700546\n",
            "Epoch 1500 : Loss 0.027749095112085342\n",
            "Epoch 1520 : Loss 0.027656856924295425\n",
            "Epoch 1540 : Loss 0.027571167796850204\n",
            "Epoch 1560 : Loss 0.027491556480526924\n",
            "Epoch 1580 : Loss 0.02741759642958641\n",
            "Epoch 1600 : Loss 0.027348872274160385\n",
            "Epoch 1620 : Loss 0.02728501707315445\n",
            "Epoch 1640 : Loss 0.027225684374570847\n",
            "Epoch 1660 : Loss 0.02717054821550846\n",
            "Epoch 1680 : Loss 0.027119306847453117\n",
            "Epoch 1700 : Loss 0.02707168459892273\n",
            "Epoch 1720 : Loss 0.027027428150177002\n",
            "Epoch 1740 : Loss 0.026986291632056236\n",
            "Epoch 1760 : Loss 0.026948057115077972\n",
            "Epoch 1780 : Loss 0.026912517845630646\n",
            "Epoch 1800 : Loss 0.026879480108618736\n",
            "Epoch 1820 : Loss 0.026848770678043365\n",
            "Epoch 1840 : Loss 0.026820218190550804\n",
            "Epoch 1860 : Loss 0.026793671771883965\n",
            "Epoch 1880 : Loss 0.026768995448946953\n",
            "Epoch 1900 : Loss 0.026746045798063278\n",
            "Epoch 1920 : Loss 0.026724711060523987\n",
            "Epoch 1940 : Loss 0.02670486830174923\n",
            "Epoch 1960 : Loss 0.026686420664191246\n",
            "Epoch 1980 : Loss 0.02666926570236683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwUEZD2s3EVR",
        "outputId": "b57c0f2f-cd54-4713-f433-6f304627ea9c"
      },
      "source": [
        "class LinearRegressionPyTorch(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegressionPyTorch, self).__init__()\n",
        "        self.linear = torch.nn.Linear(1, 1)  \n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "def generate_data(n=2000):\n",
        "    x = np.random.uniform(-math.pi,math.pi, n)\n",
        "    noise = np.random.normal(0, 0.15, n)\n",
        "    y = np.sin(x) + noise\n",
        "    return x.astype(np.float32), y.astype(np.float32)\n",
        "\n",
        "x, y = generate_data()\n",
        "\n",
        "x = torch.from_numpy(x.reshape(-1, 1))\n",
        "y = torch.from_numpy(y.reshape(-1, 1))\n",
        "\n",
        "\n",
        "def squared_error(y_pred, y_true):\n",
        "    return torch.mean(torch.square(y_pred - y_true))\n",
        "\n",
        "\n",
        "torch_model = LinearRegressionPyTorch()\n",
        "\n",
        "criterion = torch.nn.MSELoss(reduction='mean')\n",
        "optimizer = torch.optim.SGD(torch_model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(20000):\n",
        "    y_pred = torch_model(x)\n",
        "    loss = squared_error(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "      print(f\"Epoch {epoch} : Loss {loss.data}\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 : Loss 4.552675724029541\n",
            "Epoch 20 : Loss 2.8511154651641846\n",
            "Epoch 40 : Loss 1.8346728086471558\n",
            "Epoch 60 : Loss 1.224702000617981\n",
            "Epoch 80 : Loss 0.856306254863739\n",
            "Epoch 100 : Loss 0.6318390369415283\n",
            "Epoch 120 : Loss 0.49342530965805054\n",
            "Epoch 140 : Loss 0.406716912984848\n",
            "Epoch 160 : Loss 0.351290225982666\n",
            "Epoch 180 : Loss 0.31496885418891907\n",
            "Epoch 200 : Loss 0.2904655933380127\n",
            "Epoch 220 : Loss 0.27339619398117065\n",
            "Epoch 240 : Loss 0.26110297441482544\n",
            "Epoch 260 : Loss 0.2519589364528656\n",
            "Epoch 280 : Loss 0.24495406448841095\n",
            "Epoch 300 : Loss 0.23945049941539764\n",
            "Epoch 320 : Loss 0.23503604531288147\n",
            "Epoch 340 : Loss 0.23143728077411652\n",
            "Epoch 360 : Loss 0.2284671515226364\n",
            "Epoch 380 : Loss 0.22599340975284576\n",
            "Epoch 400 : Loss 0.22391940653324127\n",
            "Epoch 420 : Loss 0.22217227518558502\n",
            "Epoch 440 : Loss 0.22069552540779114\n",
            "Epoch 460 : Loss 0.21944433450698853\n",
            "Epoch 480 : Loss 0.21838250756263733\n",
            "Epoch 500 : Loss 0.21748031675815582\n",
            "Epoch 520 : Loss 0.21671311557292938\n",
            "Epoch 540 : Loss 0.21606040000915527\n",
            "Epoch 560 : Loss 0.21550481021404266\n",
            "Epoch 580 : Loss 0.21503180265426636\n",
            "Epoch 600 : Loss 0.21462899446487427\n",
            "Epoch 620 : Loss 0.2142859548330307\n",
            "Epoch 640 : Loss 0.21399374306201935\n",
            "Epoch 660 : Loss 0.2137448638677597\n",
            "Epoch 680 : Loss 0.21353283524513245\n",
            "Epoch 700 : Loss 0.213352233171463\n",
            "Epoch 720 : Loss 0.21319836378097534\n",
            "Epoch 740 : Loss 0.21306729316711426\n",
            "Epoch 760 : Loss 0.21295562386512756\n",
            "Epoch 780 : Loss 0.21286052465438843\n",
            "Epoch 800 : Loss 0.2127794772386551\n",
            "Epoch 820 : Loss 0.2127104550600052\n",
            "Epoch 840 : Loss 0.21265162527561188\n",
            "Epoch 860 : Loss 0.21260152757167816\n",
            "Epoch 880 : Loss 0.21255885064601898\n",
            "Epoch 900 : Loss 0.212522491812706\n",
            "Epoch 920 : Loss 0.2124914824962616\n",
            "Epoch 940 : Loss 0.2124650925397873\n",
            "Epoch 960 : Loss 0.21244262158870697\n",
            "Epoch 980 : Loss 0.21242345869541168\n",
            "Epoch 1000 : Loss 0.2124071568250656\n",
            "Epoch 1020 : Loss 0.21239325404167175\n",
            "Epoch 1040 : Loss 0.21238142251968384\n",
            "Epoch 1060 : Loss 0.2123713195323944\n",
            "Epoch 1080 : Loss 0.21236272156238556\n",
            "Epoch 1100 : Loss 0.21235540509223938\n",
            "Epoch 1120 : Loss 0.21234917640686035\n",
            "Epoch 1140 : Loss 0.21234382688999176\n",
            "Epoch 1160 : Loss 0.21233932673931122\n",
            "Epoch 1180 : Loss 0.21233545243740082\n",
            "Epoch 1200 : Loss 0.21233217418193817\n",
            "Epoch 1220 : Loss 0.21232937276363373\n",
            "Epoch 1240 : Loss 0.21232697367668152\n",
            "Epoch 1260 : Loss 0.21232496201992035\n",
            "Epoch 1280 : Loss 0.21232321858406067\n",
            "Epoch 1300 : Loss 0.21232175827026367\n",
            "Epoch 1320 : Loss 0.2123204916715622\n",
            "Epoch 1340 : Loss 0.21231941878795624\n",
            "Epoch 1360 : Loss 0.2123185098171234\n",
            "Epoch 1380 : Loss 0.21231773495674133\n",
            "Epoch 1400 : Loss 0.21231709420681\n",
            "Epoch 1420 : Loss 0.21231649816036224\n",
            "Epoch 1440 : Loss 0.21231602132320404\n",
            "Epoch 1460 : Loss 0.212315633893013\n",
            "Epoch 1480 : Loss 0.21231526136398315\n",
            "Epoch 1500 : Loss 0.21231499314308167\n",
            "Epoch 1520 : Loss 0.21231472492218018\n",
            "Epoch 1540 : Loss 0.21231451630592346\n",
            "Epoch 1560 : Loss 0.21231433749198914\n",
            "Epoch 1580 : Loss 0.212314173579216\n",
            "Epoch 1600 : Loss 0.21231402456760406\n",
            "Epoch 1620 : Loss 0.2123139202594757\n",
            "Epoch 1640 : Loss 0.21231381595134735\n",
            "Epoch 1660 : Loss 0.21231375634670258\n",
            "Epoch 1680 : Loss 0.2123136818408966\n",
            "Epoch 1700 : Loss 0.21231360733509064\n",
            "Epoch 1720 : Loss 0.21231356263160706\n",
            "Epoch 1740 : Loss 0.21231350302696228\n",
            "Epoch 1760 : Loss 0.2123134881258011\n",
            "Epoch 1780 : Loss 0.2123134583234787\n",
            "Epoch 1800 : Loss 0.2123134434223175\n",
            "Epoch 1820 : Loss 0.21231338381767273\n",
            "Epoch 1840 : Loss 0.21231338381767273\n",
            "Epoch 1860 : Loss 0.21231335401535034\n",
            "Epoch 1880 : Loss 0.21231333911418915\n",
            "Epoch 1900 : Loss 0.21231333911418915\n",
            "Epoch 1920 : Loss 0.21231332421302795\n",
            "Epoch 1940 : Loss 0.21231330931186676\n",
            "Epoch 1960 : Loss 0.21231332421302795\n",
            "Epoch 1980 : Loss 0.21231330931186676\n",
            "Epoch 2000 : Loss 0.21231329441070557\n",
            "Epoch 2020 : Loss 0.21231332421302795\n",
            "Epoch 2040 : Loss 0.21231329441070557\n",
            "Epoch 2060 : Loss 0.21231327950954437\n",
            "Epoch 2080 : Loss 0.21231330931186676\n",
            "Epoch 2100 : Loss 0.21231327950954437\n",
            "Epoch 2120 : Loss 0.21231327950954437\n",
            "Epoch 2140 : Loss 0.21231326460838318\n",
            "Epoch 2160 : Loss 0.21231329441070557\n",
            "Epoch 2180 : Loss 0.21231326460838318\n",
            "Epoch 2200 : Loss 0.21231329441070557\n",
            "Epoch 2220 : Loss 0.21231326460838318\n",
            "Epoch 2240 : Loss 0.21231326460838318\n",
            "Epoch 2260 : Loss 0.21231326460838318\n",
            "Epoch 2280 : Loss 0.21231327950954437\n",
            "Epoch 2300 : Loss 0.21231327950954437\n",
            "Epoch 2320 : Loss 0.21231327950954437\n",
            "Epoch 2340 : Loss 0.21231326460838318\n",
            "Epoch 2360 : Loss 0.21231327950954437\n",
            "Epoch 2380 : Loss 0.21231326460838318\n",
            "Epoch 2400 : Loss 0.21231327950954437\n",
            "Epoch 2420 : Loss 0.21231326460838318\n",
            "Epoch 2440 : Loss 0.21231326460838318\n",
            "Epoch 2460 : Loss 0.21231326460838318\n",
            "Epoch 2480 : Loss 0.21231327950954437\n",
            "Epoch 2500 : Loss 0.21231324970722198\n",
            "Epoch 2520 : Loss 0.21231326460838318\n",
            "Epoch 2540 : Loss 0.21231327950954437\n",
            "Epoch 2560 : Loss 0.21231324970722198\n",
            "Epoch 2580 : Loss 0.21231324970722198\n",
            "Epoch 2600 : Loss 0.21231326460838318\n",
            "Epoch 2620 : Loss 0.21231326460838318\n",
            "Epoch 2640 : Loss 0.21231326460838318\n",
            "Epoch 2660 : Loss 0.21231326460838318\n",
            "Epoch 2680 : Loss 0.21231327950954437\n",
            "Epoch 2700 : Loss 0.21231326460838318\n",
            "Epoch 2720 : Loss 0.21231326460838318\n",
            "Epoch 2740 : Loss 0.21231326460838318\n",
            "Epoch 2760 : Loss 0.21231327950954437\n",
            "Epoch 2780 : Loss 0.21231327950954437\n",
            "Epoch 2800 : Loss 0.21231327950954437\n",
            "Epoch 2820 : Loss 0.21231326460838318\n",
            "Epoch 2840 : Loss 0.21231324970722198\n",
            "Epoch 2860 : Loss 0.21231326460838318\n",
            "Epoch 2880 : Loss 0.21231326460838318\n",
            "Epoch 2900 : Loss 0.21231326460838318\n",
            "Epoch 2920 : Loss 0.21231326460838318\n",
            "Epoch 2940 : Loss 0.21231326460838318\n",
            "Epoch 2960 : Loss 0.21231327950954437\n",
            "Epoch 2980 : Loss 0.21231327950954437\n",
            "Epoch 3000 : Loss 0.21231327950954437\n",
            "Epoch 3020 : Loss 0.21231327950954437\n",
            "Epoch 3040 : Loss 0.21231327950954437\n",
            "Epoch 3060 : Loss 0.21231326460838318\n",
            "Epoch 3080 : Loss 0.21231326460838318\n",
            "Epoch 3100 : Loss 0.21231326460838318\n",
            "Epoch 3120 : Loss 0.21231326460838318\n",
            "Epoch 3140 : Loss 0.21231326460838318\n",
            "Epoch 3160 : Loss 0.21231326460838318\n",
            "Epoch 3180 : Loss 0.21231326460838318\n",
            "Epoch 3200 : Loss 0.21231324970722198\n",
            "Epoch 3220 : Loss 0.21231324970722198\n",
            "Epoch 3240 : Loss 0.21231326460838318\n",
            "Epoch 3260 : Loss 0.21231326460838318\n",
            "Epoch 3280 : Loss 0.21231326460838318\n",
            "Epoch 3300 : Loss 0.21231326460838318\n",
            "Epoch 3320 : Loss 0.21231326460838318\n",
            "Epoch 3340 : Loss 0.21231324970722198\n",
            "Epoch 3360 : Loss 0.21231324970722198\n",
            "Epoch 3380 : Loss 0.21231327950954437\n",
            "Epoch 3400 : Loss 0.21231324970722198\n",
            "Epoch 3420 : Loss 0.21231327950954437\n",
            "Epoch 3440 : Loss 0.21231327950954437\n",
            "Epoch 3460 : Loss 0.21231327950954437\n",
            "Epoch 3480 : Loss 0.21231327950954437\n",
            "Epoch 3500 : Loss 0.21231327950954437\n",
            "Epoch 3520 : Loss 0.21231327950954437\n",
            "Epoch 3540 : Loss 0.21231327950954437\n",
            "Epoch 3560 : Loss 0.21231327950954437\n",
            "Epoch 3580 : Loss 0.21231327950954437\n",
            "Epoch 3600 : Loss 0.21231327950954437\n",
            "Epoch 3620 : Loss 0.21231327950954437\n",
            "Epoch 3640 : Loss 0.21231327950954437\n",
            "Epoch 3660 : Loss 0.21231327950954437\n",
            "Epoch 3680 : Loss 0.21231327950954437\n",
            "Epoch 3700 : Loss 0.21231327950954437\n",
            "Epoch 3720 : Loss 0.21231327950954437\n",
            "Epoch 3740 : Loss 0.21231327950954437\n",
            "Epoch 3760 : Loss 0.21231327950954437\n",
            "Epoch 3780 : Loss 0.21231326460838318\n",
            "Epoch 3800 : Loss 0.21231327950954437\n",
            "Epoch 3820 : Loss 0.21231327950954437\n",
            "Epoch 3840 : Loss 0.21231327950954437\n",
            "Epoch 3860 : Loss 0.21231327950954437\n",
            "Epoch 3880 : Loss 0.21231327950954437\n",
            "Epoch 3900 : Loss 0.21231327950954437\n",
            "Epoch 3920 : Loss 0.21231327950954437\n",
            "Epoch 3940 : Loss 0.21231327950954437\n",
            "Epoch 3960 : Loss 0.21231327950954437\n",
            "Epoch 3980 : Loss 0.21231327950954437\n",
            "Epoch 4000 : Loss 0.21231327950954437\n",
            "Epoch 4020 : Loss 0.21231327950954437\n",
            "Epoch 4040 : Loss 0.21231327950954437\n",
            "Epoch 4060 : Loss 0.21231327950954437\n",
            "Epoch 4080 : Loss 0.21231327950954437\n",
            "Epoch 4100 : Loss 0.21231327950954437\n",
            "Epoch 4120 : Loss 0.21231327950954437\n",
            "Epoch 4140 : Loss 0.21231327950954437\n",
            "Epoch 4160 : Loss 0.21231327950954437\n",
            "Epoch 4180 : Loss 0.21231327950954437\n",
            "Epoch 4200 : Loss 0.21231327950954437\n",
            "Epoch 4220 : Loss 0.21231327950954437\n",
            "Epoch 4240 : Loss 0.21231327950954437\n",
            "Epoch 4260 : Loss 0.21231327950954437\n",
            "Epoch 4280 : Loss 0.21231327950954437\n",
            "Epoch 4300 : Loss 0.21231327950954437\n",
            "Epoch 4320 : Loss 0.21231327950954437\n",
            "Epoch 4340 : Loss 0.21231327950954437\n",
            "Epoch 4360 : Loss 0.21231327950954437\n",
            "Epoch 4380 : Loss 0.21231327950954437\n",
            "Epoch 4400 : Loss 0.21231327950954437\n",
            "Epoch 4420 : Loss 0.21231327950954437\n",
            "Epoch 4440 : Loss 0.21231327950954437\n",
            "Epoch 4460 : Loss 0.21231327950954437\n",
            "Epoch 4480 : Loss 0.21231327950954437\n",
            "Epoch 4500 : Loss 0.21231327950954437\n",
            "Epoch 4520 : Loss 0.21231327950954437\n",
            "Epoch 4540 : Loss 0.21231327950954437\n",
            "Epoch 4560 : Loss 0.21231327950954437\n",
            "Epoch 4580 : Loss 0.21231327950954437\n",
            "Epoch 4600 : Loss 0.21231327950954437\n",
            "Epoch 4620 : Loss 0.21231327950954437\n",
            "Epoch 4640 : Loss 0.21231327950954437\n",
            "Epoch 4660 : Loss 0.21231327950954437\n",
            "Epoch 4680 : Loss 0.21231327950954437\n",
            "Epoch 4700 : Loss 0.21231327950954437\n",
            "Epoch 4720 : Loss 0.21231327950954437\n",
            "Epoch 4740 : Loss 0.21231327950954437\n",
            "Epoch 4760 : Loss 0.21231327950954437\n",
            "Epoch 4780 : Loss 0.21231327950954437\n",
            "Epoch 4800 : Loss 0.21231327950954437\n",
            "Epoch 4820 : Loss 0.21231327950954437\n",
            "Epoch 4840 : Loss 0.21231327950954437\n",
            "Epoch 4860 : Loss 0.21231327950954437\n",
            "Epoch 4880 : Loss 0.21231327950954437\n",
            "Epoch 4900 : Loss 0.21231327950954437\n",
            "Epoch 4920 : Loss 0.21231327950954437\n",
            "Epoch 4940 : Loss 0.21231327950954437\n",
            "Epoch 4960 : Loss 0.21231327950954437\n",
            "Epoch 4980 : Loss 0.21231327950954437\n",
            "Epoch 5000 : Loss 0.21231327950954437\n",
            "Epoch 5020 : Loss 0.21231327950954437\n",
            "Epoch 5040 : Loss 0.21231327950954437\n",
            "Epoch 5060 : Loss 0.21231327950954437\n",
            "Epoch 5080 : Loss 0.21231327950954437\n",
            "Epoch 5100 : Loss 0.21231327950954437\n",
            "Epoch 5120 : Loss 0.21231327950954437\n",
            "Epoch 5140 : Loss 0.21231327950954437\n",
            "Epoch 5160 : Loss 0.21231327950954437\n",
            "Epoch 5180 : Loss 0.21231327950954437\n",
            "Epoch 5200 : Loss 0.21231327950954437\n",
            "Epoch 5220 : Loss 0.21231327950954437\n",
            "Epoch 5240 : Loss 0.21231327950954437\n",
            "Epoch 5260 : Loss 0.21231327950954437\n",
            "Epoch 5280 : Loss 0.21231327950954437\n",
            "Epoch 5300 : Loss 0.21231327950954437\n",
            "Epoch 5320 : Loss 0.21231327950954437\n",
            "Epoch 5340 : Loss 0.21231327950954437\n",
            "Epoch 5360 : Loss 0.21231327950954437\n",
            "Epoch 5380 : Loss 0.21231327950954437\n",
            "Epoch 5400 : Loss 0.21231327950954437\n",
            "Epoch 5420 : Loss 0.21231327950954437\n",
            "Epoch 5440 : Loss 0.21231327950954437\n",
            "Epoch 5460 : Loss 0.21231327950954437\n",
            "Epoch 5480 : Loss 0.21231327950954437\n",
            "Epoch 5500 : Loss 0.21231327950954437\n",
            "Epoch 5520 : Loss 0.21231327950954437\n",
            "Epoch 5540 : Loss 0.21231327950954437\n",
            "Epoch 5560 : Loss 0.21231327950954437\n",
            "Epoch 5580 : Loss 0.21231327950954437\n",
            "Epoch 5600 : Loss 0.21231327950954437\n",
            "Epoch 5620 : Loss 0.21231327950954437\n",
            "Epoch 5640 : Loss 0.21231327950954437\n",
            "Epoch 5660 : Loss 0.21231327950954437\n",
            "Epoch 5680 : Loss 0.21231327950954437\n",
            "Epoch 5700 : Loss 0.21231327950954437\n",
            "Epoch 5720 : Loss 0.21231327950954437\n",
            "Epoch 5740 : Loss 0.21231327950954437\n",
            "Epoch 5760 : Loss 0.21231327950954437\n",
            "Epoch 5780 : Loss 0.21231327950954437\n",
            "Epoch 5800 : Loss 0.21231327950954437\n",
            "Epoch 5820 : Loss 0.21231327950954437\n",
            "Epoch 5840 : Loss 0.21231327950954437\n",
            "Epoch 5860 : Loss 0.21231327950954437\n",
            "Epoch 5880 : Loss 0.21231327950954437\n",
            "Epoch 5900 : Loss 0.21231327950954437\n",
            "Epoch 5920 : Loss 0.21231327950954437\n",
            "Epoch 5940 : Loss 0.21231327950954437\n",
            "Epoch 5960 : Loss 0.21231327950954437\n",
            "Epoch 5980 : Loss 0.21231327950954437\n",
            "Epoch 6000 : Loss 0.21231327950954437\n",
            "Epoch 6020 : Loss 0.21231327950954437\n",
            "Epoch 6040 : Loss 0.21231327950954437\n",
            "Epoch 6060 : Loss 0.21231327950954437\n",
            "Epoch 6080 : Loss 0.21231327950954437\n",
            "Epoch 6100 : Loss 0.21231327950954437\n",
            "Epoch 6120 : Loss 0.21231327950954437\n",
            "Epoch 6140 : Loss 0.21231327950954437\n",
            "Epoch 6160 : Loss 0.21231327950954437\n",
            "Epoch 6180 : Loss 0.21231327950954437\n",
            "Epoch 6200 : Loss 0.21231327950954437\n",
            "Epoch 6220 : Loss 0.21231327950954437\n",
            "Epoch 6240 : Loss 0.21231327950954437\n",
            "Epoch 6260 : Loss 0.21231327950954437\n",
            "Epoch 6280 : Loss 0.21231327950954437\n",
            "Epoch 6300 : Loss 0.21231327950954437\n",
            "Epoch 6320 : Loss 0.21231327950954437\n",
            "Epoch 6340 : Loss 0.21231327950954437\n",
            "Epoch 6360 : Loss 0.21231327950954437\n",
            "Epoch 6380 : Loss 0.21231327950954437\n",
            "Epoch 6400 : Loss 0.21231327950954437\n",
            "Epoch 6420 : Loss 0.21231327950954437\n",
            "Epoch 6440 : Loss 0.21231327950954437\n",
            "Epoch 6460 : Loss 0.21231327950954437\n",
            "Epoch 6480 : Loss 0.21231327950954437\n",
            "Epoch 6500 : Loss 0.21231327950954437\n",
            "Epoch 6520 : Loss 0.21231327950954437\n",
            "Epoch 6540 : Loss 0.21231327950954437\n",
            "Epoch 6560 : Loss 0.21231327950954437\n",
            "Epoch 6580 : Loss 0.21231327950954437\n",
            "Epoch 6600 : Loss 0.21231327950954437\n",
            "Epoch 6620 : Loss 0.21231327950954437\n",
            "Epoch 6640 : Loss 0.21231327950954437\n",
            "Epoch 6660 : Loss 0.21231327950954437\n",
            "Epoch 6680 : Loss 0.21231327950954437\n",
            "Epoch 6700 : Loss 0.21231327950954437\n",
            "Epoch 6720 : Loss 0.21231327950954437\n",
            "Epoch 6740 : Loss 0.21231327950954437\n",
            "Epoch 6760 : Loss 0.21231327950954437\n",
            "Epoch 6780 : Loss 0.21231327950954437\n",
            "Epoch 6800 : Loss 0.21231327950954437\n",
            "Epoch 6820 : Loss 0.21231327950954437\n",
            "Epoch 6840 : Loss 0.21231327950954437\n",
            "Epoch 6860 : Loss 0.21231327950954437\n",
            "Epoch 6880 : Loss 0.21231327950954437\n",
            "Epoch 6900 : Loss 0.21231327950954437\n",
            "Epoch 6920 : Loss 0.21231327950954437\n",
            "Epoch 6940 : Loss 0.21231327950954437\n",
            "Epoch 6960 : Loss 0.21231327950954437\n",
            "Epoch 6980 : Loss 0.21231327950954437\n",
            "Epoch 7000 : Loss 0.21231327950954437\n",
            "Epoch 7020 : Loss 0.21231327950954437\n",
            "Epoch 7040 : Loss 0.21231327950954437\n",
            "Epoch 7060 : Loss 0.21231327950954437\n",
            "Epoch 7080 : Loss 0.21231327950954437\n",
            "Epoch 7100 : Loss 0.21231327950954437\n",
            "Epoch 7120 : Loss 0.21231327950954437\n",
            "Epoch 7140 : Loss 0.21231327950954437\n",
            "Epoch 7160 : Loss 0.21231327950954437\n",
            "Epoch 7180 : Loss 0.21231327950954437\n",
            "Epoch 7200 : Loss 0.21231327950954437\n",
            "Epoch 7220 : Loss 0.21231327950954437\n",
            "Epoch 7240 : Loss 0.21231327950954437\n",
            "Epoch 7260 : Loss 0.21231327950954437\n",
            "Epoch 7280 : Loss 0.21231327950954437\n",
            "Epoch 7300 : Loss 0.21231327950954437\n",
            "Epoch 7320 : Loss 0.21231327950954437\n",
            "Epoch 7340 : Loss 0.21231327950954437\n",
            "Epoch 7360 : Loss 0.21231327950954437\n",
            "Epoch 7380 : Loss 0.21231327950954437\n",
            "Epoch 7400 : Loss 0.21231327950954437\n",
            "Epoch 7420 : Loss 0.21231327950954437\n",
            "Epoch 7440 : Loss 0.21231327950954437\n",
            "Epoch 7460 : Loss 0.21231327950954437\n",
            "Epoch 7480 : Loss 0.21231327950954437\n",
            "Epoch 7500 : Loss 0.21231327950954437\n",
            "Epoch 7520 : Loss 0.21231327950954437\n",
            "Epoch 7540 : Loss 0.21231327950954437\n",
            "Epoch 7560 : Loss 0.21231327950954437\n",
            "Epoch 7580 : Loss 0.21231327950954437\n",
            "Epoch 7600 : Loss 0.21231327950954437\n",
            "Epoch 7620 : Loss 0.21231327950954437\n",
            "Epoch 7640 : Loss 0.21231327950954437\n",
            "Epoch 7660 : Loss 0.21231327950954437\n",
            "Epoch 7680 : Loss 0.21231327950954437\n",
            "Epoch 7700 : Loss 0.21231327950954437\n",
            "Epoch 7720 : Loss 0.21231327950954437\n",
            "Epoch 7740 : Loss 0.21231327950954437\n",
            "Epoch 7760 : Loss 0.21231327950954437\n",
            "Epoch 7780 : Loss 0.21231327950954437\n",
            "Epoch 7800 : Loss 0.21231327950954437\n",
            "Epoch 7820 : Loss 0.21231327950954437\n",
            "Epoch 7840 : Loss 0.21231327950954437\n",
            "Epoch 7860 : Loss 0.21231327950954437\n",
            "Epoch 7880 : Loss 0.21231327950954437\n",
            "Epoch 7900 : Loss 0.21231327950954437\n",
            "Epoch 7920 : Loss 0.21231327950954437\n",
            "Epoch 7940 : Loss 0.21231327950954437\n",
            "Epoch 7960 : Loss 0.21231327950954437\n",
            "Epoch 7980 : Loss 0.21231327950954437\n",
            "Epoch 8000 : Loss 0.21231327950954437\n",
            "Epoch 8020 : Loss 0.21231327950954437\n",
            "Epoch 8040 : Loss 0.21231327950954437\n",
            "Epoch 8060 : Loss 0.21231327950954437\n",
            "Epoch 8080 : Loss 0.21231327950954437\n",
            "Epoch 8100 : Loss 0.21231327950954437\n",
            "Epoch 8120 : Loss 0.21231327950954437\n",
            "Epoch 8140 : Loss 0.21231327950954437\n",
            "Epoch 8160 : Loss 0.21231327950954437\n",
            "Epoch 8180 : Loss 0.21231327950954437\n",
            "Epoch 8200 : Loss 0.21231327950954437\n",
            "Epoch 8220 : Loss 0.21231327950954437\n",
            "Epoch 8240 : Loss 0.21231327950954437\n",
            "Epoch 8260 : Loss 0.21231327950954437\n",
            "Epoch 8280 : Loss 0.21231327950954437\n",
            "Epoch 8300 : Loss 0.21231327950954437\n",
            "Epoch 8320 : Loss 0.21231327950954437\n",
            "Epoch 8340 : Loss 0.21231327950954437\n",
            "Epoch 8360 : Loss 0.21231327950954437\n",
            "Epoch 8380 : Loss 0.21231327950954437\n",
            "Epoch 8400 : Loss 0.21231327950954437\n",
            "Epoch 8420 : Loss 0.21231327950954437\n",
            "Epoch 8440 : Loss 0.21231327950954437\n",
            "Epoch 8460 : Loss 0.21231327950954437\n",
            "Epoch 8480 : Loss 0.21231327950954437\n",
            "Epoch 8500 : Loss 0.21231327950954437\n",
            "Epoch 8520 : Loss 0.21231327950954437\n",
            "Epoch 8540 : Loss 0.21231327950954437\n",
            "Epoch 8560 : Loss 0.21231327950954437\n",
            "Epoch 8580 : Loss 0.21231327950954437\n",
            "Epoch 8600 : Loss 0.21231327950954437\n",
            "Epoch 8620 : Loss 0.21231327950954437\n",
            "Epoch 8640 : Loss 0.21231327950954437\n",
            "Epoch 8660 : Loss 0.21231327950954437\n",
            "Epoch 8680 : Loss 0.21231327950954437\n",
            "Epoch 8700 : Loss 0.21231327950954437\n",
            "Epoch 8720 : Loss 0.21231327950954437\n",
            "Epoch 8740 : Loss 0.21231327950954437\n",
            "Epoch 8760 : Loss 0.21231327950954437\n",
            "Epoch 8780 : Loss 0.21231327950954437\n",
            "Epoch 8800 : Loss 0.21231327950954437\n",
            "Epoch 8820 : Loss 0.21231327950954437\n",
            "Epoch 8840 : Loss 0.21231327950954437\n",
            "Epoch 8860 : Loss 0.21231327950954437\n",
            "Epoch 8880 : Loss 0.21231327950954437\n",
            "Epoch 8900 : Loss 0.21231327950954437\n",
            "Epoch 8920 : Loss 0.21231327950954437\n",
            "Epoch 8940 : Loss 0.21231327950954437\n",
            "Epoch 8960 : Loss 0.21231327950954437\n",
            "Epoch 8980 : Loss 0.21231327950954437\n",
            "Epoch 9000 : Loss 0.21231327950954437\n",
            "Epoch 9020 : Loss 0.21231327950954437\n",
            "Epoch 9040 : Loss 0.21231327950954437\n",
            "Epoch 9060 : Loss 0.21231327950954437\n",
            "Epoch 9080 : Loss 0.21231327950954437\n",
            "Epoch 9100 : Loss 0.21231327950954437\n",
            "Epoch 9120 : Loss 0.21231327950954437\n",
            "Epoch 9140 : Loss 0.21231327950954437\n",
            "Epoch 9160 : Loss 0.21231327950954437\n",
            "Epoch 9180 : Loss 0.21231327950954437\n",
            "Epoch 9200 : Loss 0.21231327950954437\n",
            "Epoch 9220 : Loss 0.21231327950954437\n",
            "Epoch 9240 : Loss 0.21231327950954437\n",
            "Epoch 9260 : Loss 0.21231327950954437\n",
            "Epoch 9280 : Loss 0.21231327950954437\n",
            "Epoch 9300 : Loss 0.21231327950954437\n",
            "Epoch 9320 : Loss 0.21231327950954437\n",
            "Epoch 9340 : Loss 0.21231327950954437\n",
            "Epoch 9360 : Loss 0.21231327950954437\n",
            "Epoch 9380 : Loss 0.21231327950954437\n",
            "Epoch 9400 : Loss 0.21231327950954437\n",
            "Epoch 9420 : Loss 0.21231327950954437\n",
            "Epoch 9440 : Loss 0.21231327950954437\n",
            "Epoch 9460 : Loss 0.21231327950954437\n",
            "Epoch 9480 : Loss 0.21231327950954437\n",
            "Epoch 9500 : Loss 0.21231327950954437\n",
            "Epoch 9520 : Loss 0.21231327950954437\n",
            "Epoch 9540 : Loss 0.21231327950954437\n",
            "Epoch 9560 : Loss 0.21231327950954437\n",
            "Epoch 9580 : Loss 0.21231327950954437\n",
            "Epoch 9600 : Loss 0.21231327950954437\n",
            "Epoch 9620 : Loss 0.21231327950954437\n",
            "Epoch 9640 : Loss 0.21231327950954437\n",
            "Epoch 9660 : Loss 0.21231327950954437\n",
            "Epoch 9680 : Loss 0.21231327950954437\n",
            "Epoch 9700 : Loss 0.21231327950954437\n",
            "Epoch 9720 : Loss 0.21231327950954437\n",
            "Epoch 9740 : Loss 0.21231327950954437\n",
            "Epoch 9760 : Loss 0.21231327950954437\n",
            "Epoch 9780 : Loss 0.21231327950954437\n",
            "Epoch 9800 : Loss 0.21231327950954437\n",
            "Epoch 9820 : Loss 0.21231327950954437\n",
            "Epoch 9840 : Loss 0.21231327950954437\n",
            "Epoch 9860 : Loss 0.21231327950954437\n",
            "Epoch 9880 : Loss 0.21231327950954437\n",
            "Epoch 9900 : Loss 0.21231327950954437\n",
            "Epoch 9920 : Loss 0.21231327950954437\n",
            "Epoch 9940 : Loss 0.21231327950954437\n",
            "Epoch 9960 : Loss 0.21231327950954437\n",
            "Epoch 9980 : Loss 0.21231327950954437\n",
            "Epoch 10000 : Loss 0.21231327950954437\n",
            "Epoch 10020 : Loss 0.21231327950954437\n",
            "Epoch 10040 : Loss 0.21231327950954437\n",
            "Epoch 10060 : Loss 0.21231327950954437\n",
            "Epoch 10080 : Loss 0.21231327950954437\n",
            "Epoch 10100 : Loss 0.21231327950954437\n",
            "Epoch 10120 : Loss 0.21231327950954437\n",
            "Epoch 10140 : Loss 0.21231327950954437\n",
            "Epoch 10160 : Loss 0.21231327950954437\n",
            "Epoch 10180 : Loss 0.21231327950954437\n",
            "Epoch 10200 : Loss 0.21231327950954437\n",
            "Epoch 10220 : Loss 0.21231327950954437\n",
            "Epoch 10240 : Loss 0.21231327950954437\n",
            "Epoch 10260 : Loss 0.21231327950954437\n",
            "Epoch 10280 : Loss 0.21231327950954437\n",
            "Epoch 10300 : Loss 0.21231327950954437\n",
            "Epoch 10320 : Loss 0.21231327950954437\n",
            "Epoch 10340 : Loss 0.21231327950954437\n",
            "Epoch 10360 : Loss 0.21231327950954437\n",
            "Epoch 10380 : Loss 0.21231327950954437\n",
            "Epoch 10400 : Loss 0.21231327950954437\n",
            "Epoch 10420 : Loss 0.21231327950954437\n",
            "Epoch 10440 : Loss 0.21231327950954437\n",
            "Epoch 10460 : Loss 0.21231327950954437\n",
            "Epoch 10480 : Loss 0.21231327950954437\n",
            "Epoch 10500 : Loss 0.21231327950954437\n",
            "Epoch 10520 : Loss 0.21231327950954437\n",
            "Epoch 10540 : Loss 0.21231327950954437\n",
            "Epoch 10560 : Loss 0.21231327950954437\n",
            "Epoch 10580 : Loss 0.21231327950954437\n",
            "Epoch 10600 : Loss 0.21231327950954437\n",
            "Epoch 10620 : Loss 0.21231327950954437\n",
            "Epoch 10640 : Loss 0.21231327950954437\n",
            "Epoch 10660 : Loss 0.21231327950954437\n",
            "Epoch 10680 : Loss 0.21231327950954437\n",
            "Epoch 10700 : Loss 0.21231327950954437\n",
            "Epoch 10720 : Loss 0.21231327950954437\n",
            "Epoch 10740 : Loss 0.21231327950954437\n",
            "Epoch 10760 : Loss 0.21231327950954437\n",
            "Epoch 10780 : Loss 0.21231327950954437\n",
            "Epoch 10800 : Loss 0.21231327950954437\n",
            "Epoch 10820 : Loss 0.21231327950954437\n",
            "Epoch 10840 : Loss 0.21231327950954437\n",
            "Epoch 10860 : Loss 0.21231327950954437\n",
            "Epoch 10880 : Loss 0.21231327950954437\n",
            "Epoch 10900 : Loss 0.21231327950954437\n",
            "Epoch 10920 : Loss 0.21231327950954437\n",
            "Epoch 10940 : Loss 0.21231327950954437\n",
            "Epoch 10960 : Loss 0.21231327950954437\n",
            "Epoch 10980 : Loss 0.21231327950954437\n",
            "Epoch 11000 : Loss 0.21231327950954437\n",
            "Epoch 11020 : Loss 0.21231327950954437\n",
            "Epoch 11040 : Loss 0.21231327950954437\n",
            "Epoch 11060 : Loss 0.21231327950954437\n",
            "Epoch 11080 : Loss 0.21231327950954437\n",
            "Epoch 11100 : Loss 0.21231327950954437\n",
            "Epoch 11120 : Loss 0.21231327950954437\n",
            "Epoch 11140 : Loss 0.21231327950954437\n",
            "Epoch 11160 : Loss 0.21231327950954437\n",
            "Epoch 11180 : Loss 0.21231327950954437\n",
            "Epoch 11200 : Loss 0.21231327950954437\n",
            "Epoch 11220 : Loss 0.21231327950954437\n",
            "Epoch 11240 : Loss 0.21231327950954437\n",
            "Epoch 11260 : Loss 0.21231327950954437\n",
            "Epoch 11280 : Loss 0.21231327950954437\n",
            "Epoch 11300 : Loss 0.21231327950954437\n",
            "Epoch 11320 : Loss 0.21231327950954437\n",
            "Epoch 11340 : Loss 0.21231327950954437\n",
            "Epoch 11360 : Loss 0.21231327950954437\n",
            "Epoch 11380 : Loss 0.21231327950954437\n",
            "Epoch 11400 : Loss 0.21231327950954437\n",
            "Epoch 11420 : Loss 0.21231327950954437\n",
            "Epoch 11440 : Loss 0.21231327950954437\n",
            "Epoch 11460 : Loss 0.21231327950954437\n",
            "Epoch 11480 : Loss 0.21231327950954437\n",
            "Epoch 11500 : Loss 0.21231327950954437\n",
            "Epoch 11520 : Loss 0.21231327950954437\n",
            "Epoch 11540 : Loss 0.21231327950954437\n",
            "Epoch 11560 : Loss 0.21231327950954437\n",
            "Epoch 11580 : Loss 0.21231327950954437\n",
            "Epoch 11600 : Loss 0.21231327950954437\n",
            "Epoch 11620 : Loss 0.21231327950954437\n",
            "Epoch 11640 : Loss 0.21231327950954437\n",
            "Epoch 11660 : Loss 0.21231327950954437\n",
            "Epoch 11680 : Loss 0.21231327950954437\n",
            "Epoch 11700 : Loss 0.21231327950954437\n",
            "Epoch 11720 : Loss 0.21231327950954437\n",
            "Epoch 11740 : Loss 0.21231327950954437\n",
            "Epoch 11760 : Loss 0.21231327950954437\n",
            "Epoch 11780 : Loss 0.21231327950954437\n",
            "Epoch 11800 : Loss 0.21231327950954437\n",
            "Epoch 11820 : Loss 0.21231327950954437\n",
            "Epoch 11840 : Loss 0.21231327950954437\n",
            "Epoch 11860 : Loss 0.21231327950954437\n",
            "Epoch 11880 : Loss 0.21231327950954437\n",
            "Epoch 11900 : Loss 0.21231327950954437\n",
            "Epoch 11920 : Loss 0.21231327950954437\n",
            "Epoch 11940 : Loss 0.21231327950954437\n",
            "Epoch 11960 : Loss 0.21231327950954437\n",
            "Epoch 11980 : Loss 0.21231327950954437\n",
            "Epoch 12000 : Loss 0.21231327950954437\n",
            "Epoch 12020 : Loss 0.21231327950954437\n",
            "Epoch 12040 : Loss 0.21231327950954437\n",
            "Epoch 12060 : Loss 0.21231327950954437\n",
            "Epoch 12080 : Loss 0.21231327950954437\n",
            "Epoch 12100 : Loss 0.21231327950954437\n",
            "Epoch 12120 : Loss 0.21231327950954437\n",
            "Epoch 12140 : Loss 0.21231327950954437\n",
            "Epoch 12160 : Loss 0.21231327950954437\n",
            "Epoch 12180 : Loss 0.21231327950954437\n",
            "Epoch 12200 : Loss 0.21231327950954437\n",
            "Epoch 12220 : Loss 0.21231327950954437\n",
            "Epoch 12240 : Loss 0.21231327950954437\n",
            "Epoch 12260 : Loss 0.21231327950954437\n",
            "Epoch 12280 : Loss 0.21231327950954437\n",
            "Epoch 12300 : Loss 0.21231327950954437\n",
            "Epoch 12320 : Loss 0.21231327950954437\n",
            "Epoch 12340 : Loss 0.21231327950954437\n",
            "Epoch 12360 : Loss 0.21231327950954437\n",
            "Epoch 12380 : Loss 0.21231327950954437\n",
            "Epoch 12400 : Loss 0.21231327950954437\n",
            "Epoch 12420 : Loss 0.21231327950954437\n",
            "Epoch 12440 : Loss 0.21231327950954437\n",
            "Epoch 12460 : Loss 0.21231327950954437\n",
            "Epoch 12480 : Loss 0.21231327950954437\n",
            "Epoch 12500 : Loss 0.21231327950954437\n",
            "Epoch 12520 : Loss 0.21231327950954437\n",
            "Epoch 12540 : Loss 0.21231327950954437\n",
            "Epoch 12560 : Loss 0.21231327950954437\n",
            "Epoch 12580 : Loss 0.21231327950954437\n",
            "Epoch 12600 : Loss 0.21231327950954437\n",
            "Epoch 12620 : Loss 0.21231327950954437\n",
            "Epoch 12640 : Loss 0.21231327950954437\n",
            "Epoch 12660 : Loss 0.21231327950954437\n",
            "Epoch 12680 : Loss 0.21231327950954437\n",
            "Epoch 12700 : Loss 0.21231327950954437\n",
            "Epoch 12720 : Loss 0.21231327950954437\n",
            "Epoch 12740 : Loss 0.21231327950954437\n",
            "Epoch 12760 : Loss 0.21231327950954437\n",
            "Epoch 12780 : Loss 0.21231327950954437\n",
            "Epoch 12800 : Loss 0.21231327950954437\n",
            "Epoch 12820 : Loss 0.21231327950954437\n",
            "Epoch 12840 : Loss 0.21231327950954437\n",
            "Epoch 12860 : Loss 0.21231327950954437\n",
            "Epoch 12880 : Loss 0.21231327950954437\n",
            "Epoch 12900 : Loss 0.21231327950954437\n",
            "Epoch 12920 : Loss 0.21231327950954437\n",
            "Epoch 12940 : Loss 0.21231327950954437\n",
            "Epoch 12960 : Loss 0.21231327950954437\n",
            "Epoch 12980 : Loss 0.21231327950954437\n",
            "Epoch 13000 : Loss 0.21231327950954437\n",
            "Epoch 13020 : Loss 0.21231327950954437\n",
            "Epoch 13040 : Loss 0.21231327950954437\n",
            "Epoch 13060 : Loss 0.21231327950954437\n",
            "Epoch 13080 : Loss 0.21231327950954437\n",
            "Epoch 13100 : Loss 0.21231327950954437\n",
            "Epoch 13120 : Loss 0.21231327950954437\n",
            "Epoch 13140 : Loss 0.21231327950954437\n",
            "Epoch 13160 : Loss 0.21231327950954437\n",
            "Epoch 13180 : Loss 0.21231327950954437\n",
            "Epoch 13200 : Loss 0.21231327950954437\n",
            "Epoch 13220 : Loss 0.21231327950954437\n",
            "Epoch 13240 : Loss 0.21231327950954437\n",
            "Epoch 13260 : Loss 0.21231327950954437\n",
            "Epoch 13280 : Loss 0.21231327950954437\n",
            "Epoch 13300 : Loss 0.21231327950954437\n",
            "Epoch 13320 : Loss 0.21231327950954437\n",
            "Epoch 13340 : Loss 0.21231327950954437\n",
            "Epoch 13360 : Loss 0.21231327950954437\n",
            "Epoch 13380 : Loss 0.21231327950954437\n",
            "Epoch 13400 : Loss 0.21231327950954437\n",
            "Epoch 13420 : Loss 0.21231327950954437\n",
            "Epoch 13440 : Loss 0.21231327950954437\n",
            "Epoch 13460 : Loss 0.21231327950954437\n",
            "Epoch 13480 : Loss 0.21231327950954437\n",
            "Epoch 13500 : Loss 0.21231327950954437\n",
            "Epoch 13520 : Loss 0.21231327950954437\n",
            "Epoch 13540 : Loss 0.21231327950954437\n",
            "Epoch 13560 : Loss 0.21231327950954437\n",
            "Epoch 13580 : Loss 0.21231327950954437\n",
            "Epoch 13600 : Loss 0.21231327950954437\n",
            "Epoch 13620 : Loss 0.21231327950954437\n",
            "Epoch 13640 : Loss 0.21231327950954437\n",
            "Epoch 13660 : Loss 0.21231327950954437\n",
            "Epoch 13680 : Loss 0.21231327950954437\n",
            "Epoch 13700 : Loss 0.21231327950954437\n",
            "Epoch 13720 : Loss 0.21231327950954437\n",
            "Epoch 13740 : Loss 0.21231327950954437\n",
            "Epoch 13760 : Loss 0.21231327950954437\n",
            "Epoch 13780 : Loss 0.21231327950954437\n",
            "Epoch 13800 : Loss 0.21231327950954437\n",
            "Epoch 13820 : Loss 0.21231327950954437\n",
            "Epoch 13840 : Loss 0.21231327950954437\n",
            "Epoch 13860 : Loss 0.21231327950954437\n",
            "Epoch 13880 : Loss 0.21231327950954437\n",
            "Epoch 13900 : Loss 0.21231327950954437\n",
            "Epoch 13920 : Loss 0.21231327950954437\n",
            "Epoch 13940 : Loss 0.21231327950954437\n",
            "Epoch 13960 : Loss 0.21231327950954437\n",
            "Epoch 13980 : Loss 0.21231327950954437\n",
            "Epoch 14000 : Loss 0.21231327950954437\n",
            "Epoch 14020 : Loss 0.21231327950954437\n",
            "Epoch 14040 : Loss 0.21231327950954437\n",
            "Epoch 14060 : Loss 0.21231327950954437\n",
            "Epoch 14080 : Loss 0.21231327950954437\n",
            "Epoch 14100 : Loss 0.21231327950954437\n",
            "Epoch 14120 : Loss 0.21231327950954437\n",
            "Epoch 14140 : Loss 0.21231327950954437\n",
            "Epoch 14160 : Loss 0.21231327950954437\n",
            "Epoch 14180 : Loss 0.21231327950954437\n",
            "Epoch 14200 : Loss 0.21231327950954437\n",
            "Epoch 14220 : Loss 0.21231327950954437\n",
            "Epoch 14240 : Loss 0.21231327950954437\n",
            "Epoch 14260 : Loss 0.21231327950954437\n",
            "Epoch 14280 : Loss 0.21231327950954437\n",
            "Epoch 14300 : Loss 0.21231327950954437\n",
            "Epoch 14320 : Loss 0.21231327950954437\n",
            "Epoch 14340 : Loss 0.21231327950954437\n",
            "Epoch 14360 : Loss 0.21231327950954437\n",
            "Epoch 14380 : Loss 0.21231327950954437\n",
            "Epoch 14400 : Loss 0.21231327950954437\n",
            "Epoch 14420 : Loss 0.21231327950954437\n",
            "Epoch 14440 : Loss 0.21231327950954437\n",
            "Epoch 14460 : Loss 0.21231327950954437\n",
            "Epoch 14480 : Loss 0.21231327950954437\n",
            "Epoch 14500 : Loss 0.21231327950954437\n",
            "Epoch 14520 : Loss 0.21231327950954437\n",
            "Epoch 14540 : Loss 0.21231327950954437\n",
            "Epoch 14560 : Loss 0.21231327950954437\n",
            "Epoch 14580 : Loss 0.21231327950954437\n",
            "Epoch 14600 : Loss 0.21231327950954437\n",
            "Epoch 14620 : Loss 0.21231327950954437\n",
            "Epoch 14640 : Loss 0.21231327950954437\n",
            "Epoch 14660 : Loss 0.21231327950954437\n",
            "Epoch 14680 : Loss 0.21231327950954437\n",
            "Epoch 14700 : Loss 0.21231327950954437\n",
            "Epoch 14720 : Loss 0.21231327950954437\n",
            "Epoch 14740 : Loss 0.21231327950954437\n",
            "Epoch 14760 : Loss 0.21231327950954437\n",
            "Epoch 14780 : Loss 0.21231327950954437\n",
            "Epoch 14800 : Loss 0.21231327950954437\n",
            "Epoch 14820 : Loss 0.21231327950954437\n",
            "Epoch 14840 : Loss 0.21231327950954437\n",
            "Epoch 14860 : Loss 0.21231327950954437\n",
            "Epoch 14880 : Loss 0.21231327950954437\n",
            "Epoch 14900 : Loss 0.21231327950954437\n",
            "Epoch 14920 : Loss 0.21231327950954437\n",
            "Epoch 14940 : Loss 0.21231327950954437\n",
            "Epoch 14960 : Loss 0.21231327950954437\n",
            "Epoch 14980 : Loss 0.21231327950954437\n",
            "Epoch 15000 : Loss 0.21231327950954437\n",
            "Epoch 15020 : Loss 0.21231327950954437\n",
            "Epoch 15040 : Loss 0.21231327950954437\n",
            "Epoch 15060 : Loss 0.21231327950954437\n",
            "Epoch 15080 : Loss 0.21231327950954437\n",
            "Epoch 15100 : Loss 0.21231327950954437\n",
            "Epoch 15120 : Loss 0.21231327950954437\n",
            "Epoch 15140 : Loss 0.21231327950954437\n",
            "Epoch 15160 : Loss 0.21231327950954437\n",
            "Epoch 15180 : Loss 0.21231327950954437\n",
            "Epoch 15200 : Loss 0.21231327950954437\n",
            "Epoch 15220 : Loss 0.21231327950954437\n",
            "Epoch 15240 : Loss 0.21231327950954437\n",
            "Epoch 15260 : Loss 0.21231327950954437\n",
            "Epoch 15280 : Loss 0.21231327950954437\n",
            "Epoch 15300 : Loss 0.21231327950954437\n",
            "Epoch 15320 : Loss 0.21231327950954437\n",
            "Epoch 15340 : Loss 0.21231327950954437\n",
            "Epoch 15360 : Loss 0.21231327950954437\n",
            "Epoch 15380 : Loss 0.21231327950954437\n",
            "Epoch 15400 : Loss 0.21231327950954437\n",
            "Epoch 15420 : Loss 0.21231327950954437\n",
            "Epoch 15440 : Loss 0.21231327950954437\n",
            "Epoch 15460 : Loss 0.21231327950954437\n",
            "Epoch 15480 : Loss 0.21231327950954437\n",
            "Epoch 15500 : Loss 0.21231327950954437\n",
            "Epoch 15520 : Loss 0.21231327950954437\n",
            "Epoch 15540 : Loss 0.21231327950954437\n",
            "Epoch 15560 : Loss 0.21231327950954437\n",
            "Epoch 15580 : Loss 0.21231327950954437\n",
            "Epoch 15600 : Loss 0.21231327950954437\n",
            "Epoch 15620 : Loss 0.21231327950954437\n",
            "Epoch 15640 : Loss 0.21231327950954437\n",
            "Epoch 15660 : Loss 0.21231327950954437\n",
            "Epoch 15680 : Loss 0.21231327950954437\n",
            "Epoch 15700 : Loss 0.21231327950954437\n",
            "Epoch 15720 : Loss 0.21231327950954437\n",
            "Epoch 15740 : Loss 0.21231327950954437\n",
            "Epoch 15760 : Loss 0.21231327950954437\n",
            "Epoch 15780 : Loss 0.21231327950954437\n",
            "Epoch 15800 : Loss 0.21231327950954437\n",
            "Epoch 15820 : Loss 0.21231327950954437\n",
            "Epoch 15840 : Loss 0.21231327950954437\n",
            "Epoch 15860 : Loss 0.21231327950954437\n",
            "Epoch 15880 : Loss 0.21231327950954437\n",
            "Epoch 15900 : Loss 0.21231327950954437\n",
            "Epoch 15920 : Loss 0.21231327950954437\n",
            "Epoch 15940 : Loss 0.21231327950954437\n",
            "Epoch 15960 : Loss 0.21231327950954437\n",
            "Epoch 15980 : Loss 0.21231327950954437\n",
            "Epoch 16000 : Loss 0.21231327950954437\n",
            "Epoch 16020 : Loss 0.21231327950954437\n",
            "Epoch 16040 : Loss 0.21231327950954437\n",
            "Epoch 16060 : Loss 0.21231327950954437\n",
            "Epoch 16080 : Loss 0.21231327950954437\n",
            "Epoch 16100 : Loss 0.21231327950954437\n",
            "Epoch 16120 : Loss 0.21231327950954437\n",
            "Epoch 16140 : Loss 0.21231327950954437\n",
            "Epoch 16160 : Loss 0.21231327950954437\n",
            "Epoch 16180 : Loss 0.21231327950954437\n",
            "Epoch 16200 : Loss 0.21231327950954437\n",
            "Epoch 16220 : Loss 0.21231327950954437\n",
            "Epoch 16240 : Loss 0.21231327950954437\n",
            "Epoch 16260 : Loss 0.21231327950954437\n",
            "Epoch 16280 : Loss 0.21231327950954437\n",
            "Epoch 16300 : Loss 0.21231327950954437\n",
            "Epoch 16320 : Loss 0.21231327950954437\n",
            "Epoch 16340 : Loss 0.21231327950954437\n",
            "Epoch 16360 : Loss 0.21231327950954437\n",
            "Epoch 16380 : Loss 0.21231327950954437\n",
            "Epoch 16400 : Loss 0.21231327950954437\n",
            "Epoch 16420 : Loss 0.21231327950954437\n",
            "Epoch 16440 : Loss 0.21231327950954437\n",
            "Epoch 16460 : Loss 0.21231327950954437\n",
            "Epoch 16480 : Loss 0.21231327950954437\n",
            "Epoch 16500 : Loss 0.21231327950954437\n",
            "Epoch 16520 : Loss 0.21231327950954437\n",
            "Epoch 16540 : Loss 0.21231327950954437\n",
            "Epoch 16560 : Loss 0.21231327950954437\n",
            "Epoch 16580 : Loss 0.21231327950954437\n",
            "Epoch 16600 : Loss 0.21231327950954437\n",
            "Epoch 16620 : Loss 0.21231327950954437\n",
            "Epoch 16640 : Loss 0.21231327950954437\n",
            "Epoch 16660 : Loss 0.21231327950954437\n",
            "Epoch 16680 : Loss 0.21231327950954437\n",
            "Epoch 16700 : Loss 0.21231327950954437\n",
            "Epoch 16720 : Loss 0.21231327950954437\n",
            "Epoch 16740 : Loss 0.21231327950954437\n",
            "Epoch 16760 : Loss 0.21231327950954437\n",
            "Epoch 16780 : Loss 0.21231327950954437\n",
            "Epoch 16800 : Loss 0.21231327950954437\n",
            "Epoch 16820 : Loss 0.21231327950954437\n",
            "Epoch 16840 : Loss 0.21231327950954437\n",
            "Epoch 16860 : Loss 0.21231327950954437\n",
            "Epoch 16880 : Loss 0.21231327950954437\n",
            "Epoch 16900 : Loss 0.21231327950954437\n",
            "Epoch 16920 : Loss 0.21231327950954437\n",
            "Epoch 16940 : Loss 0.21231327950954437\n",
            "Epoch 16960 : Loss 0.21231327950954437\n",
            "Epoch 16980 : Loss 0.21231327950954437\n",
            "Epoch 17000 : Loss 0.21231327950954437\n",
            "Epoch 17020 : Loss 0.21231327950954437\n",
            "Epoch 17040 : Loss 0.21231327950954437\n",
            "Epoch 17060 : Loss 0.21231327950954437\n",
            "Epoch 17080 : Loss 0.21231327950954437\n",
            "Epoch 17100 : Loss 0.21231327950954437\n",
            "Epoch 17120 : Loss 0.21231327950954437\n",
            "Epoch 17140 : Loss 0.21231327950954437\n",
            "Epoch 17160 : Loss 0.21231327950954437\n",
            "Epoch 17180 : Loss 0.21231327950954437\n",
            "Epoch 17200 : Loss 0.21231327950954437\n",
            "Epoch 17220 : Loss 0.21231327950954437\n",
            "Epoch 17240 : Loss 0.21231327950954437\n",
            "Epoch 17260 : Loss 0.21231327950954437\n",
            "Epoch 17280 : Loss 0.21231327950954437\n",
            "Epoch 17300 : Loss 0.21231327950954437\n",
            "Epoch 17320 : Loss 0.21231327950954437\n",
            "Epoch 17340 : Loss 0.21231327950954437\n",
            "Epoch 17360 : Loss 0.21231327950954437\n",
            "Epoch 17380 : Loss 0.21231327950954437\n",
            "Epoch 17400 : Loss 0.21231327950954437\n",
            "Epoch 17420 : Loss 0.21231327950954437\n",
            "Epoch 17440 : Loss 0.21231327950954437\n",
            "Epoch 17460 : Loss 0.21231327950954437\n",
            "Epoch 17480 : Loss 0.21231327950954437\n",
            "Epoch 17500 : Loss 0.21231327950954437\n",
            "Epoch 17520 : Loss 0.21231327950954437\n",
            "Epoch 17540 : Loss 0.21231327950954437\n",
            "Epoch 17560 : Loss 0.21231327950954437\n",
            "Epoch 17580 : Loss 0.21231327950954437\n",
            "Epoch 17600 : Loss 0.21231327950954437\n",
            "Epoch 17620 : Loss 0.21231327950954437\n",
            "Epoch 17640 : Loss 0.21231327950954437\n",
            "Epoch 17660 : Loss 0.21231327950954437\n",
            "Epoch 17680 : Loss 0.21231327950954437\n",
            "Epoch 17700 : Loss 0.21231327950954437\n",
            "Epoch 17720 : Loss 0.21231327950954437\n",
            "Epoch 17740 : Loss 0.21231327950954437\n",
            "Epoch 17760 : Loss 0.21231327950954437\n",
            "Epoch 17780 : Loss 0.21231327950954437\n",
            "Epoch 17800 : Loss 0.21231327950954437\n",
            "Epoch 17820 : Loss 0.21231327950954437\n",
            "Epoch 17840 : Loss 0.21231327950954437\n",
            "Epoch 17860 : Loss 0.21231327950954437\n",
            "Epoch 17880 : Loss 0.21231327950954437\n",
            "Epoch 17900 : Loss 0.21231327950954437\n",
            "Epoch 17920 : Loss 0.21231327950954437\n",
            "Epoch 17940 : Loss 0.21231327950954437\n",
            "Epoch 17960 : Loss 0.21231327950954437\n",
            "Epoch 17980 : Loss 0.21231327950954437\n",
            "Epoch 18000 : Loss 0.21231327950954437\n",
            "Epoch 18020 : Loss 0.21231327950954437\n",
            "Epoch 18040 : Loss 0.21231327950954437\n",
            "Epoch 18060 : Loss 0.21231327950954437\n",
            "Epoch 18080 : Loss 0.21231327950954437\n",
            "Epoch 18100 : Loss 0.21231327950954437\n",
            "Epoch 18120 : Loss 0.21231327950954437\n",
            "Epoch 18140 : Loss 0.21231327950954437\n",
            "Epoch 18160 : Loss 0.21231327950954437\n",
            "Epoch 18180 : Loss 0.21231327950954437\n",
            "Epoch 18200 : Loss 0.21231327950954437\n",
            "Epoch 18220 : Loss 0.21231327950954437\n",
            "Epoch 18240 : Loss 0.21231327950954437\n",
            "Epoch 18260 : Loss 0.21231327950954437\n",
            "Epoch 18280 : Loss 0.21231327950954437\n",
            "Epoch 18300 : Loss 0.21231327950954437\n",
            "Epoch 18320 : Loss 0.21231327950954437\n",
            "Epoch 18340 : Loss 0.21231327950954437\n",
            "Epoch 18360 : Loss 0.21231327950954437\n",
            "Epoch 18380 : Loss 0.21231327950954437\n",
            "Epoch 18400 : Loss 0.21231327950954437\n",
            "Epoch 18420 : Loss 0.21231327950954437\n",
            "Epoch 18440 : Loss 0.21231327950954437\n",
            "Epoch 18460 : Loss 0.21231327950954437\n",
            "Epoch 18480 : Loss 0.21231327950954437\n",
            "Epoch 18500 : Loss 0.21231327950954437\n",
            "Epoch 18520 : Loss 0.21231327950954437\n",
            "Epoch 18540 : Loss 0.21231327950954437\n",
            "Epoch 18560 : Loss 0.21231327950954437\n",
            "Epoch 18580 : Loss 0.21231327950954437\n",
            "Epoch 18600 : Loss 0.21231327950954437\n",
            "Epoch 18620 : Loss 0.21231327950954437\n",
            "Epoch 18640 : Loss 0.21231327950954437\n",
            "Epoch 18660 : Loss 0.21231327950954437\n",
            "Epoch 18680 : Loss 0.21231327950954437\n",
            "Epoch 18700 : Loss 0.21231327950954437\n",
            "Epoch 18720 : Loss 0.21231327950954437\n",
            "Epoch 18740 : Loss 0.21231327950954437\n",
            "Epoch 18760 : Loss 0.21231327950954437\n",
            "Epoch 18780 : Loss 0.21231327950954437\n",
            "Epoch 18800 : Loss 0.21231327950954437\n",
            "Epoch 18820 : Loss 0.21231327950954437\n",
            "Epoch 18840 : Loss 0.21231327950954437\n",
            "Epoch 18860 : Loss 0.21231327950954437\n",
            "Epoch 18880 : Loss 0.21231327950954437\n",
            "Epoch 18900 : Loss 0.21231327950954437\n",
            "Epoch 18920 : Loss 0.21231327950954437\n",
            "Epoch 18940 : Loss 0.21231327950954437\n",
            "Epoch 18960 : Loss 0.21231327950954437\n",
            "Epoch 18980 : Loss 0.21231327950954437\n",
            "Epoch 19000 : Loss 0.21231327950954437\n",
            "Epoch 19020 : Loss 0.21231327950954437\n",
            "Epoch 19040 : Loss 0.21231327950954437\n",
            "Epoch 19060 : Loss 0.21231327950954437\n",
            "Epoch 19080 : Loss 0.21231327950954437\n",
            "Epoch 19100 : Loss 0.21231327950954437\n",
            "Epoch 19120 : Loss 0.21231327950954437\n",
            "Epoch 19140 : Loss 0.21231327950954437\n",
            "Epoch 19160 : Loss 0.21231327950954437\n",
            "Epoch 19180 : Loss 0.21231327950954437\n",
            "Epoch 19200 : Loss 0.21231327950954437\n",
            "Epoch 19220 : Loss 0.21231327950954437\n",
            "Epoch 19240 : Loss 0.21231327950954437\n",
            "Epoch 19260 : Loss 0.21231327950954437\n",
            "Epoch 19280 : Loss 0.21231327950954437\n",
            "Epoch 19300 : Loss 0.21231327950954437\n",
            "Epoch 19320 : Loss 0.21231327950954437\n",
            "Epoch 19340 : Loss 0.21231327950954437\n",
            "Epoch 19360 : Loss 0.21231327950954437\n",
            "Epoch 19380 : Loss 0.21231327950954437\n",
            "Epoch 19400 : Loss 0.21231327950954437\n",
            "Epoch 19420 : Loss 0.21231327950954437\n",
            "Epoch 19440 : Loss 0.21231327950954437\n",
            "Epoch 19460 : Loss 0.21231327950954437\n",
            "Epoch 19480 : Loss 0.21231327950954437\n",
            "Epoch 19500 : Loss 0.21231327950954437\n",
            "Epoch 19520 : Loss 0.21231327950954437\n",
            "Epoch 19540 : Loss 0.21231327950954437\n",
            "Epoch 19560 : Loss 0.21231327950954437\n",
            "Epoch 19580 : Loss 0.21231327950954437\n",
            "Epoch 19600 : Loss 0.21231327950954437\n",
            "Epoch 19620 : Loss 0.21231327950954437\n",
            "Epoch 19640 : Loss 0.21231327950954437\n",
            "Epoch 19660 : Loss 0.21231327950954437\n",
            "Epoch 19680 : Loss 0.21231327950954437\n",
            "Epoch 19700 : Loss 0.21231327950954437\n",
            "Epoch 19720 : Loss 0.21231327950954437\n",
            "Epoch 19740 : Loss 0.21231327950954437\n",
            "Epoch 19760 : Loss 0.21231327950954437\n",
            "Epoch 19780 : Loss 0.21231327950954437\n",
            "Epoch 19800 : Loss 0.21231327950954437\n",
            "Epoch 19820 : Loss 0.21231327950954437\n",
            "Epoch 19840 : Loss 0.21231327950954437\n",
            "Epoch 19860 : Loss 0.21231327950954437\n",
            "Epoch 19880 : Loss 0.21231327950954437\n",
            "Epoch 19900 : Loss 0.21231327950954437\n",
            "Epoch 19920 : Loss 0.21231327950954437\n",
            "Epoch 19940 : Loss 0.21231327950954437\n",
            "Epoch 19960 : Loss 0.21231327950954437\n",
            "Epoch 19980 : Loss 0.21231327950954437\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}